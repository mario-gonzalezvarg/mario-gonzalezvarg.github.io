<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 – Project 3 | Mario Gonzalez</title>

  <!-- Shared styles + fonts -->
  <link rel="stylesheet" href="../styles.css" />

  <!-- LaTeX rendering -->
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>

<body class="top-title">
  <!-- starfield background (driven by ../script.js) -->
  <canvas id="sky" aria-hidden="true"></canvas>

  <!-- Top nav: proj5-style header -->
  <header class="site-header">
    <div class="content">
      <nav class="top-nav" aria-label="Project navigation">
        <a href="../index.html" class="nav-logo">
          Home
        </a>
      </nav>
    </div>
  </header>

  <!-- Hero / title card -->
  <div class="content big-title">
    <h1 class="title">Image Warping &amp; Mosaicing</h1>
    <div class="project-switcher" aria-label="Jump to projects">
      <a href="../proj2/index.html" class="project-switcher__button">
        Project 2
      </a>
      <a href="index.html" class="project-switcher__button project-switcher__button--primary">
        Project 3
      </a>
    </div>
  </div>

  <!-- ========== A1 Set of Images to Manipulate ========== -->
  <section class="content gold-glass" id="a1">
    <h2 class="section-heading">A1 Set of Images to Manipulate</h2>

    <div class="writing-section">
      <p>
        Photographs were captured under a fixed center of projection while the camera was rotated about its optical
        center, producing pairs related predominantly by projective transformations. Frames were taken within a short
        time window to minimize illumination and scene changes, and with 40–70% field-of-view overlap to ensure
        sufficient common texture. This setup yields image pairs suitable for estimating a single planar homography
        between views and for constructing wide-field mosaics.
      </p>

      <div class="card">
        <div class="pair">
          <label>
            <strong>Pair:</strong>
            <select id="c-pair">
              <option value="Sequia National Park" selected>Sequia National Park</option>
              <option value="pair2">Pair 2</option>
            </select>
          </label>

          <label>
            <input type="radio" name="c-view" value="a_points" checked>
            Fixed Center of Projection
          </label>
          <label>
            <input type="radio" name="c-view" value="b_points">
            Rotation of Camera
          </label>
        </div>

        <figure class="media media--narrow">
          <img id="c-img" alt="correspondence">
          <figcaption id="c-cap"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ========== A2 Recovering Homographies ========== -->
  <section class="content gold-glass" id="p3-2">
    <h2 class="section-heading">A2 Recovering Homographies</h2>

    <div class="writing-section">
      <p>
        Point correspondences were manually annotated between each source–target pair and used to estimate a 3×3
        homography <code>H</code> that maps homogeneous coordinates <code>x = (x, y, 1)^{\mathsf{T}}</code> to
        <code>x′ ∼ Hx</code>. With the scale fixed by <code>H(3,3)=1</code>, the remaining eight unknowns were recovered
        by stacking two linear equations per correspondence into an overdetermined system <code>A h = b</code> and
        solving in the least-squares sense. Concretely, each match <code>(x, y) → (u, v)</code> contributes
        <code>[x&nbsp;y&nbsp;1&nbsp;0&nbsp;0&nbsp;0&nbsp;−u x&nbsp;−u y] h = u</code> and
        <code>[0&nbsp;0&nbsp;0&nbsp;x&nbsp;y&nbsp;1&nbsp;−v x&nbsp;−v y] h = v</code>. Using more than four
        correspondences improves numerical stability and reduces sensitivity to localization error. Visual overlays of
        the clicked pairs and the resulting warp provide qualitative validation; the recovered matrix <code>H</code> is
        additionally reported for quantitative inspection.
      </p>

      <div class="card">
        <div class="pair">
          <label>
            <strong>Pair:</strong>
            <select id="w-pair">
              <option value="mario_demo" selected>Sequia National Park</option>
              <option value="pair2">Pair 2</option>
            </select>
          </label>

          <label>
            <input type="radio" name="w-view" value="a_to_mean" checked>
            Feature Points
          </label>
          <label>
            <input type="radio" name="w-view" value="b_to_mean">
            Correspondences
          </label>
        </div>

        <figure class="media media--narrow">
          <img id="w-img" alt="warp viewer">
          <figcaption id="w-cap"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ========== A3 Warping of Images ========== -->
  <section class="content gold-glass" id="p3-3">
    <h2 class="section-heading">A3 Warping of Images</h2>

    <div class="writing-section">
      <p>
        Images were resampled by <em>inverse warping</em>: for each pixel on the output canvas, the pre-image was
        obtained via <code>x = H^{-1} p</code> and sampled in the source at <code>(x/w, y/w)</code>. Output bounds were
        predicted by projecting the four source corners through <code>H</code> to allocate a tight canvas. Two
        interpolation schemes were implemented from first principles. Nearest-neighbor rounds to the closest integer
        coordinate and is computationally efficient but introduces blocky edges and aliasing. Bilinear interpolation
        computes a convex combination of the four neighboring pixels, yielding smoother edges and fewer stair-step
        artifacts at a modest increase in cost. Rectification was demonstrated by mapping a planar quadrilateral (e.g.,
        a poster or tile) to a canonical rectangle, verifying that the estimated homography correctly removes perspective
        distortion.
      </p>

      <div class="card">
        <div class="pair">
          <label>
            <strong>Pair:</strong>
            <select id="m-pair">
              <option value="mario_demo" selected>Sequia National Park</option>
              <option value="pair2">Pair 2</option>
            </select>
          </label>

          <label>
            <input type="radio" name="m-view" value="mid" checked>
            Nearest Neighbor Interpolation
          </label>
          <label>
            <input type="radio" name="m-view" value="seq">
            Bilinear Interpolation
          </label>
        </div>

        <figure class="media media--narrow">
          <img id="m-img" alt="morph viewer">
          <figcaption id="m-cap"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ========== A4 Mosaic Blending ========== -->
  <section class="content gold-glass" id="p3-4">
    <h2 class="section-heading">A4 Mosaic Blending</h2>

    <div class="writing-section">
      <p>
        To compose a panorama, all images were mapped into a common coordinate system (reference frame chosen near the
        middle of the sequence). For each warped image, a binary validity mask was generated and then smoothed using a
        box filter implemented via an integral-image prefix sum. The final mosaic was produced by feathered averaging,
        <code>I(out) = (∑_k w_k(out) · I_k(out)) / (∑_k w_k(out))</code>, which attenuates seam visibility in overlaps
        while preserving detail away from boundaries. This weighted scheme mitigates hard transitions without invoking
        high-level libraries. Residual ghosting may persist where parallax or motion violates the single-homography
        assumption; nevertheless, the approach yields clean results on scenes consistent with planar or rotational
        camera motion.
      </p>

      <div class="card">
        <div class="pair">
          <label>
            <strong>Dataset:</strong>
            <select id="avg-ds">
              <option value="danes" selected>Sequia National Park</option>
              <option value="custom">Custom Cohort</option>
            </select>
          </label>

          <label>
            <input type="radio" name="avg-view" value="no_avg_weight" checked>
            Mosaic without Weighted Average
          </label>
          <label>
            <input type="radio" name="avg-view" value="subject_to_mean">
            Mosaic with Weighted Average
          </label>
        </div>

        <figure class="media media--narrow">
          <img id="avg-img" alt="no_avg_weight">
          <figcaption id="avg-cap"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ========== B1 Harris Corner Detection ========== -->
  <section class="content gold-glass" id="p3-5">
    <h2 class="section-heading">B1 Harris Corner Detection</h2>

    <div class="writing-section">
      <div class="card">
        <div class="pair">
          <label>
            <strong>Subject:</strong>
            <select id="b1">
              <option value="all" selected>Glass Art Sculpture</option>
            </select>
          </label>

          <label>
            <input type="radio" name="car-view" value="og_image" checked>
            Image
          </label>
          <label>
            <input type="radio" name="car-view" value="s_scale">
            Single Scale
          </label>
          <label>
            <input type="radio" name="car-view" value="ams">
            Adaptive Non-Maximal Suppression
          </label>
        </div>

        <figure class="media media--narrow">
          <img id="b1-img" alt="Harris viewer">
          <figcaption id="b1-cap"></figcaption>
        </figure>

        <div class="card">
          <!-- Implementation details (unchanged text) -->
          <h3>Implementation Details</h3>

          <p><strong>Corner response.</strong>
            For a grayscale image \(I\), we evaluate the structure tensor
            \(\mathbf{H}(x,y) = g_{\sigma_i} * [\nabla_{\sigma_d} I \,\nabla_{\sigma_d} I^{\!\top}]\),
            with derivative scale \(\sigma_d{=}1.0\) and integration scale \(\sigma_i{=}1.5\).
            The score is the harmonic-mean formulation used in MOPS,
            \[
              f_{\mathrm{HM}}(x,y) = \frac{\det \mathbf{H}(x,y)}{\operatorname{tr}\mathbf{H}(x,y)} =
              \frac{\lambda_1\lambda_2}{\lambda_1+\lambda_2}.
            \]
            In code (<code>_harris_response_and_orientation</code>) we compute \(I_x,I_y\) using Gaussian derivatives and
            form \(A{=}I_x^2,\ B{=}I_y^2,\ C{=}I_x I_y\), so that \(\det \mathbf{H}{=}AB{-}C^2\) and
            \(\operatorname{tr}\mathbf{H}{=}A{+}B\). A small \(\epsilon\) avoids division by zero. We keep 3×3 local maxima
            above a threshold \(t\). Because our images are normalized to \([0,1]\) but MOPS uses \(t{=}10\) on 8-bit
            intensities, we scale the threshold to \(t'=10/255^2\approx 1.54\times 10^{-4}\).
          </p>

          <p><strong>Orientation field.</strong>
            We optionally compute an orientation \(\theta\) from a heavily smoothed gradient
            \(\nabla_{\sigma_o} I\) with \(\sigma_o{=}4.5\) (code: <code>theta = arctan2(G_y,G_x)</code>).
            Although B2 uses axis-aligned patches, this field is useful for diagnostics and matches the paper’s
            oriented-patch design.
          </p>

          <p><strong>Non-maximum suppression &amp; edges.</strong>
            <code>_local_maxima</code> performs 3×3 NMS. We then discard detections within an edge guard so B2’s
            \(40{\times}40\) footprint fits: with an \(8{\times}8\) descriptor sampled at spacing \(s{=}5\), the
            half-extent is \(\lceil \tfrac{8-1}{2}s\rceil{=}18\) px; points closer than 18 px to any border are removed.
          </p>

          <p><strong>Adaptive Non-Maximal Suppression (ANMS).</strong>
            To obtain a spatially uniform set, we implement the ANMS criterion. For each candidate \(i\) with strength
            \(f_i\), we define its suppression radius
            \[
              r_i = \min_{j:\, f_i < c_{\text{robust}}f_j} \|x_i - x_j\|_2,\quad c_{\text{robust}}{=}0.9.
            \]
            We keep the \(n\) points with largest \(r_i\), reproducing the ordered-list interpretation in the paper and
            yielding better spatial coverage than ranking by corner strength alone.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== B2 Feature Descriptor Extraction ========== -->
  <section class="content gold-glass" id="p3-b2">
    <h2 class="section-heading">B2 Feature Descriptor Extraction</h2>

    <div class="writing-section">
      <div class="card">
        <div class="pair">
          <label>
            <strong>Subject:</strong>
            <select id="b2-subj">
              <option value="mural1" selected>Mural 1</option>
              <option value="mural2">Mural 2</option>
            </select>
          </label>

          <label>
            <input type="radio" name="b2-view" value="pair" checked>
            Image
          </label>
          <label>
            <input type="radio" name="b2-view" value="desc">
            Descriptor Patches
          </label>
        </div>

        <figure class="media media--narrow">
          <div id="b2-pair" class="pair">
            <img id="b2-left" alt="original">
            <img id="b2-right" alt="descriptor patches">
          </div>
          <img id="b2-desc" alt="descriptor patches" style="display:none">
          <figcaption id="b2-cap"></figcaption>
        </figure>

        <div class="card">
          <h3>Implementation Details</h3>

          <p><strong>Sampling geometry.</strong>
            Around each ANMS keypoint \((y,x)\) we sample an \(8{\times}8\) grid at spacing \(s{=}5\) px from a
            \(40{\times}40\) window. The grid abscissae are
            \(o_k = (k - \tfrac{7}{2})s,\ k=0,\ldots,7\), so sample coordinates are \((y+o_i,\ x+o_j)\). Low-frequency
            sampling makes the descriptor stable to small localization errors.
          </p>

          <p><strong>Bilinear interpolation.</strong>
            We resample with first-order interpolation, avoiding aliasing and stair-stepping while keeping the descriptor
            linear in the input pixels.
          </p>

          <p><strong>Bias/gain normalization.</strong>
            Each \(8{\times}8\) patch \(P\) is standardized to \(\hat{P} = (P-\mu)/\sigma\) to remove affine intensity
            changes. Patches with \(\sigma<10^{-6}\) are dropped as uninformative, and the standardized patch is flattened
            to a 64-D vector.
          </p>

          <p><strong>Border handling.</strong>
            Keypoints are filtered with an 18 px guard band so the \(40{\times}40\) window lies fully inside the image,
            avoiding extrapolation artifacts.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== B3 Feature Matching ========== -->
  <section class="content gold-glass" id="p3-b3">
    <h2 class="section-heading">B3 Feature Matching</h2>

    <div class="writing-section">
      <div class="card">
        <div class="pair">
          <label>
            <strong>Subject:</strong>
            <select id="b3-subj">
              <option value="mural_pair" selected>Mural 1 ↔ Mural 2</option>
            </select>
          </label>

          <label>
            <input type="radio" name="b3-view" value="pair" checked>
            Image
          </label>
          <label>
            <input type="radio" name="b3-view" value="matches">
            Feature Matches
          </label>
        </div>

        <figure class="media media--narrow">
          <div id="b3-pair" class="pair">
            <img id="b3-left" alt="left image">
            <img id="b3-right" alt="right image">
          </div>
          <img id="b3-matches" alt="feature matches" style="display:none">
          <figcaption id="b3-cap"></figcaption>
        </figure>

        <div class="card">
          <h3>Implementation Details</h3>

          <p><strong>Distance metric.</strong>
            Given standardized descriptors \(D_1\) and \(D_2\), all pairwise squared Euclidean distances
            \(\|d_i - e_j\|_2^2\) are computed without square roots; squared distances preserve ordering and are numerically
            stable.
          </p>

          <p><strong>Lowe’s ratio test.</strong>
            For each descriptor we compute the 1-NN and 2-NN errors and accept matches where their ratio is below a
            threshold \(\tau\). This follows the MOPS / SIFT rationale that the ratio discriminates reliable matches
            better than absolute error.
          </p>

          <p><strong>Complexity and tuning.</strong>
            The all-pairs distance computation is \(O(N_1 N_2)\) but remains tractable after ANMS reduces the keypoints.
            Raising \(\tau\) increases recall at the cost of more outliers, which are later filtered by RANSAC.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- ========== B4 RANSAC & Auto Mosaicing ========== -->
  <section class="content gold-glass" id="p3-b4">
    <h2 class="section-heading">B4 RANSAC &amp; Auto Mosaicing</h2>

    <div class="writing-section">
      <div class="card">
        <div class="pair">
          <label>
            <strong>Subject:</strong>
            <select id="b4-subj">
              <option value="mural_pair" selected>Hawaii Mountains</option>
            </select>
          </label>

          <label>
            <input type="radio" name="b4-view" value="pair" checked>
            Image
          </label>
          <label>
            <input type="radio" name="b4-view" value="inliers">
            Inliers / Outliers
          </label>
          <label>
            <input type="radio" name="b4-view" value="mosaic">
            Mosaic
          </label>
        </div>

        <figure class="media media--narrow">
          <div id="b4-pair" class="pair">
            <img id="b4-left" alt="left input">
            <img id="b4-right" alt="right input">
          </div>
          <img id="b4-single" alt="b4 single" style="display:none">
          <figcaption id="b4-cap"></figcaption>
        </figure>

        <div class="card">
          <h3>Implementation Details</h3>

          <p><strong>Homography model and normalized DLT.</strong>
            A planar projective map \(\mathbf{x}' \sim \mathbf{H}\mathbf{x}\) is estimated from correspondences using
            normalized DLT. Points are centered and scaled so their mean distance is \(\sqrt{2}\), the homogeneous system
            \(\mathbf{A}\mathbf{h}=0\) is solved via SVD, and the result is denormalized to obtain \(\mathbf{H}\).
          </p>

          <p><strong>Consensus via 4-point RANSAC.</strong>
            At each iteration four matches are sampled, a candidate \(\mathbf{H}\) is estimated, and all matches are scored
            by symmetric transfer error. Inliers satisfy \(\varepsilon_i < \tau^2\). The iteration budget is updated using
            the standard success-probability formula with target probability \(p=0.99\).
          </p>

          <p><strong>Warping and feathered blending.</strong>
            Once a consensus homography is found, image corners are mapped to define a tight output canvas, and images are
            warped into this frame. Soft masks are built by smoothing validity maps and a weighted average
            \(I_{\text{mosaic}}(p)=\frac{\sum_k w_k(p)I_k(p)}{\sum_k w_k(p)}\) is used to suppress seams.
          </p>

          <p><strong>Failure modes and mitigation.</strong>
            Degenerate samples and poor overlap can lead to unstable homographies or gaps; these are mitigated by
            conditioning checks, ANMS-distributed features, and by restricting to scenes where the single-homography model
            is reasonable.
          </p>
        </div>
      </div>
    </div>
  </section>

  <!-- Shared JS helpers and viewers (unchanged) -->
  <script>
    (function () {
      const EXTS = ['png', 'jpg', 'jpeg', 'gif', 'JPG'];
      const $ = s => document.querySelector(s);
      function tryLoad(imgEl, paths, i = 0) {
        if (i >= paths.length) { imgEl.removeAttribute('src'); return; }
        imgEl.onerror = () => tryLoad(imgEl, paths, i + 1);
        imgEl.src = paths[i];
      }
      function onRadios(name, cb) {
        document.querySelectorAll(`input[name="${name}"]`).forEach(r => r.addEventListener('change', cb));
      }
      window.UI = { EXTS, $, tryLoad, onRadios };
    })();
  </script>

  <!-- Viewers (same logic as your original file) -->
  <script>
    (function () {
      const { EXTS, $, tryLoad, onRadios } = UI;

      // A1 viewer
      (function () {
        const img = $('#c-img'), cap = $('#c-cap');
        const FILES = {
          'Sequia National Park': {
            'a_points': 'DSCF4641',
            'b_points': 'DSCF4652'
          }
        };

        function update() {
          const pair = document.getElementById('c-pair').value;
          const view = (document.querySelector('input[name="c-view"]:checked') || {}).value;
          const stem = FILES[pair] && FILES[pair][view];
          if (!stem) { img.removeAttribute('src'); cap.textContent = ''; return; }

          cap.textContent = `${pair} — ${view === 'a_points' ? 'Fixed Center of Projection' : 'Rotation of Camera'}`;
          tryLoad(img, EXTS.map(ext => `media/a1/${stem}.${ext}`));
        }

        document.getElementById('c-pair').addEventListener('change', update);
        onRadios('c-view', update);
        update();
      })();

      // A2 viewer
      (function () {
        const img = $('#w-img'), cap = $('#w-cap');
        const STEM_BY_VIEW = {
          'a_to_mean': 'seq_corr',
          'b_to_mean': 'seq_homo'
        };

        function update() {
          const view = (document.querySelector('input[name="w-view"]:checked') || {}).value;
          const stem = STEM_BY_VIEW[view];
          if (!stem) { img.removeAttribute('src'); cap.textContent = ''; return; }

          cap.textContent = (view === 'a_to_mean') ? 'Feature Points' : 'Correspondences';
          tryLoad(img, EXTS.map(ext => `media/a2/${stem}.${ext}`));
        }

        document.getElementById('w-pair').addEventListener('change', update);
        onRadios('w-view', update);
        update();
      })();

      // A3 viewer
      (function () {
        const img = $('#m-img'), cap = $('#m-cap');
        const STEM_BY_VIEW = {
          'mid': 'sequoia_panorama_nn',
          'seq': 'sequoia_panorama_bl'
        };

        function update() {
          const view = (document.querySelector('input[name="m-view"]:checked') || {}).value;
          const stemNN = STEM_BY_VIEW['mid'];

          if (view === 'seq') {
            const testStem = STEM_BY_VIEW['seq'];
            const paths = EXTS.map(ext => `media/a3/${testStem}.${ext}`)
              .concat(EXTS.map(ext => `media/a3/${stemNN}.${ext}`));
            cap.textContent = 'Bilinear Interpolation (falls back to NN if missing)';
            tryLoad(img, paths);
            return;
          }

          cap.textContent = 'Nearest Neighbor Interpolation';
          tryLoad(img, EXTS.map(ext => `media/a3/${stemNN}.${ext}`));
        }

        document.getElementById('m-pair').addEventListener('change', update);
        onRadios('m-view', update);
        update();
      })();

      // A4 viewer
      (function () {
        const img = $('#avg-img'), cap = $('#avg-cap');
        const STEM_BY_VIEW = {
          'no_avg_weight': 'mosaic_no_weight',
          'subject_to_mean': 'mosaic_weighted'
        };

        function update() {
          const view = (document.querySelector('input[name="avg-view"]:checked') || {}).value;
          const stem = STEM_BY_VIEW[view];
          if (!stem) { img.removeAttribute('src'); cap.textContent = ''; return; }

          cap.textContent = (view === 'no_avg_weight')
            ? 'Mosaic without Weighted Average'
            : 'Mosaic with Weighted Average';
          tryLoad(img, EXTS.map(ext => `media/a4/${stem}.${ext}`));
        }

        document.getElementById('avg-ds').addEventListener('change', update);
        onRadios('avg-view', update);
        update();
      })();

      // B1, B2, B3, B4 viewers — unchanged logic from original file
      (function () {
        const img = $('#b1-img'), cap = $('#b1-cap');

        function update() {
          const mode = (document.querySelector('input[name="car-view"]:checked') || {}).value;
          if (mode === 'og_image') {
            cap.textContent = 'Original image (no corners)';
            tryLoad(img, EXTS.map(ext => `media/b1/g4.${ext}`));
            return;
          }
          const stem = (mode === 'ams') ? 'B1_harris_anms' : 'B1_harris_all';
          cap.textContent = (mode === 'ams')
            ? 'Harris corners after ANMS'
            : 'Harris corners (all detections)';
          tryLoad(img, EXTS.map(ext => `media/b1/${stem}.${ext}`));
        }

        onRadios('car-view', update);
        document.getElementById('b1').addEventListener('change', update);
        update();
      })();

      (function () {
        // B2 viewer logic (copied from original)
        const subjSel = document.getElementById('b2-subj');
        const pairWrap = document.getElementById('b2-pair');
        const leftImg = document.getElementById('b2-left');
        const rightImg = document.getElementById('b2-right');
        const descImg = document.getElementById('b2-desc');
        const cap = document.getElementById('b2-cap');

        const ORIGINAL = {
          mural1: 'media/b3/mural1',
          mural2: 'media/b3/mural2'
        };

        function patchPaths(subj) {
          const bases = [
            `media/b2/b2_${subj}_features`,
            `media/b2/${subj}_features`,
            `media/b2/b2_mural_features`
          ];
          const out = [];
          bases.forEach(b => EXTS.forEach(ext => out.push(`${b}.${ext}`)));
          return out;
        }
        function extPaths(base) { return EXTS.map(ext => `${base}.${ext}`); }

        function update() {
          const subj = subjSel.value;
          const view = (document.querySelector('input[name="b2-view"]:checked') || {}).value;

          if (view === 'pair') {
            pairWrap.style.display = 'flex';
            descImg.style.display = 'none';
            tryLoad(leftImg, extPaths(ORIGINAL[subj]));
            tryLoad(rightImg, patchPaths(subj));
            cap.textContent = 'Original (left) and descriptor patches (right)';
            return;
          }
          pairWrap.style.display = 'none';
          descImg.style.display = '';
          tryLoad(descImg, patchPaths(subj));
          cap.textContent = 'Descriptor patches';
        }

        subjSel.addEventListener('change', update);
        onRadios('b2-view', update);
        update();
      })();

      (function () {
        // B3 viewer logic (copied from original)
        const pairWrap = document.getElementById('b3-pair');
        const leftImg = document.getElementById('b3-left');
        const rightImg = document.getElementById('b3-right');
        const matchImg = document.getElementById('b3-matches');
        const cap = document.getElementById('b3-cap');

        const PAIRS = {
          mural_pair: {
            left: 'media/b3/mural1',
            right: 'media/b3/mural2',
            matches: 'media/b3/matches'
          }
        };

        function extPaths(base) { return EXTS.map(ext => `${base}.${ext}`); }

        function update() {
          const key = document.getElementById('b3-subj').value;
          const view = (document.querySelector('input[name="b3-view"]:checked') || {}).value;
          const p = PAIRS[key];

          if (view === 'pair') {
            pairWrap.style.display = 'flex';
            matchImg.style.display = 'none';
            tryLoad(leftImg, extPaths(p.left));
            tryLoad(rightImg, extPaths(p.right));
            cap.textContent = 'Original pair (left / right)';
            return;
          }

          pairWrap.style.display = 'none';
          matchImg.style.display = '';
          tryLoad(matchImg, extPaths(p.matches));
          cap.textContent = 'Feature matches between the pair';
        }

        document.getElementById('b3-subj').addEventListener('change', update);
        onRadios('b3-view', update);
        update();
      })();

      (function () {
        // B4 viewer logic (copied from original)
        const pairWrap = document.getElementById('b4-pair');
        const leftImg = document.getElementById('b4-left');
        const rightImg = document.getElementById('b4-right');
        const single = document.getElementById('b4-single');
        const cap = document.getElementById('b4-cap');

        const B4 = {
          mural_pair: {
            leftBases: ['media/b4/hm2'],
            rightBases: ['media/b4/hm3'],
            inliers: 'media/b4/B4_matches_inliers',
            mosaic: 'media/b4/B4_mosaic_auto'
          }
        };

        function pathsForBases(bases) {
          const out = [];
          bases.forEach(b => EXTS.forEach(ext => out.push(`${b}.${ext}`)));
          return out;
        }
        function extPaths(base) { return EXTS.map(ext => `${base}.${ext}`); }

        function update() {
          const key = document.getElementById('b4-subj').value;
          const view = (document.querySelector('input[name="b4-view"]:checked') || {}).value;
          const p = B4[key];

          if (view === 'pair') {
            pairWrap.style.display = 'flex';
            single.style.display = 'none';
            tryLoad(leftImg, pathsForBases(p.leftBases));
            tryLoad(rightImg, pathsForBases(p.rightBases));
            cap.textContent = 'Input pair for mosaicing (left / right)';
            return;
          }

          pairWrap.style.display = 'none';
          single.style.display = '';
          const base = (view === 'inliers') ? p.inliers : p.mosaic;
          tryLoad(single, extPaths(base));
          cap.textContent = (view === 'inliers')
            ? 'RANSAC inliers (green) and outliers (red)'
            : 'Final mosaic (automatic)';
        }

        document.getElementById('b4-subj').addEventListener('change', update);
        onRadios('b4-view', update);
        update();
      })();
    })();
  </script>

  <!-- background animation -->
  <script src="../script.js"></script>
</body>

</html>
