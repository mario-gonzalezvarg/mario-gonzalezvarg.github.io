<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Neural Fields</title>
  <meta name="description"
    content="CS180 Project 4 report with calibration, neural fields, NeRF training, results, analysis, and extras." />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Cormorant+Garamond:wght@400;600&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="../proj4/styles.css" />
  <script defer src="../proj4/script.js"></script>
</head>

<body>
  <!-- fixed starfield backdrop -->
  <canvas id="sky" aria-hidden="true"></canvas>

  <header class="site-header" role="banner">
    <div class="progress" aria-hidden="true"><span class="bar"></span></div>
    <a class="brand" href="#">CS180 • Project 4</a>
  </header>

  <!----------------------------------------------------- Title ----------------------------------------------------->
  <main id="main">
    <section class="hero">
      <h1 class="serif title" data-split="chars">Neural Fields </h1>
      <p class="lead">UC&nbsp;Berkeley • CS180 Computational Photography </p>

    </section>



    <!----------------------------------------------- Part 0 Camera Calibration and 3D Scanning ------------------------------------------------->
    <section id="3D Scan" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Camera Calibration and 3D Scanning</h1>
      </header>

      <article class="glass readable">
        The calibration stage establishes a consistent geometric description of the camera used for all subsequent
        experiments. A printed 8×11 ChArUco board is captured from many viewpoints in a dedicated sequence. For each
        image, the system detects the chessboard corners and embedded ArUco markers, refines their locations to
        subpixel accuracy, and associates them with known 3D coordinates on the board. These 2D–3D correspondences are
        passed to a standard calibration routine that jointly estimates the intrinsic matrix, lens distortion
        coefficients, and per-image extrinsic poses. Outlier views with large reprojection error are discarded, and the
        remaining set is used to compute a final set of intrinsics that closely match the physical camera.
      </article>


      <div class="pe-panels pe-panels-final">
        <div class="panel">
          <figure class="pe-card">
            <img src="media/viser/house_rays1.png" alt="View 1 — global layout of camera poses.">
            <figcaption>View 1 — global layout of camera poses.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/house.jpg" alt="3D scan of the ceramic house reconstructed from multi-view images.">
            <figcaption>Reconstructed object scan from the calibrated multi-view sequence.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/house_rays2.png" alt="View 2 — looking up from z-axis.">
            <figcaption>View 2 — looking up from the z-axis, highlighting coverage and elevation changes.</figcaption>
          </figure>
        </div>
      </div>

      <article class="glass readable">
        Once the camera model is fixed, the ChArUco board doubles as a world-coordinate reference for the 3D scanning
        sequence. Each photograph of the ceramic house on the board is undistorted with the recovered lens parameters,
        and the same corner and marker detections are used to solve for a rigid transform from camera space to board
        space. These transforms are then interpreted as camera-to-world matrices and stored alongside the images in a
        compact calibration file. Visualising the resulting frustums reveals a dense ring of cameras around the object
        with varying elevation and azimuth, providing good coverage for volumetric reconstruction and novel-view
        synthesis.
      </article>
    </section>



    <!------------------------------------------------ Part 1 Fit a Neural Field to a 2D Image ---------------------------------------------------->
    <section id="max_encoding" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Varying Encoding Frequency</h1>
      </header>



      <article class="glass readable">
        To visualise how positional encoding transforms image coordinates, each PE(u,v) vector is projected onto its top
        three PCA components while the maximum encoding frequency L is varied. For very low frequency (L = 1), the
        encoded PE(u,v) vectors occupy a single smooth, bowl-shaped surface in the top three principal components. The
        colour gradient from red to green along this surface shows that the first two principal components remain almost
        linear in u and v, so the encoding behaves like a gently curved embedding of the image plane with no folds:
        nearby pixels in image coordinates remain nearby in feature space. At this end of the spectrum, the positional
        encoding acts as a smooth reparameterisation of the image domain rather than introducing strong local
        distortions.

      </article>

      <article class="glass readable">
        At mid-range frequencies (L = 8 and L = 12), the PCA manifolds develop a clear multi-layered structure. The
        points no longer sit on a single simple bowl but instead trace out sheets that have been folded or partially
        rolled, with regions of the grid mapped to different heights in PC3 even when their PC1 and PC2 coordinates
        nearly coincide. The colour gradients remain ordered, indicating that the embedding still respects global
        position, but pixels that are adjacent along one coordinate can now separate along the third principal component
        whenever the corresponding sine and cosine terms shift phase. In effect, mid-frequency encodings preserve a
        coherent global parameterisation while deliberately stretching and shearing local neighbourhoods, which makes it
        easier for a finite-depth ReLU network to represent edges and moderate-frequency texture.

      </article>


      <div class="pe-tabs">
        <!-- radios -->
        <input type="radio" name="L" id="L1" checked>
        <input type="radio" name="L" id="L4">
        <input type="radio" name="L" id="L8">
        <input type="radio" name="L" id="L12">
        <input type="radio" name="L" id="L16">
        <input type="radio" name="L" id="L24">


        <div class="pe-panels" aria-live="polite">
          <!---------------------------- L = 1 ------------------------------------>
          <div class="panel" data-l="L1">
            <figure class="pe-card"><img src="media/pe/L1_rgb.png" alt="L1 – PCA of PE features (colored by RGB)">
              <figcaption>Layers: 256</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L1_uv.png" alt="L1 – PCA of PE features (colored by UV)">
              <figcaption>lr: 1e-2</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L1_penult_pca3_rgb.png"
                alt="L1 – PCA of penultimate features (RGB)">
              <figcaption>2500 iterations</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L1">
              <div class="belt">
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_00000.png" alt="L1 – iter 0">
                  <figcaption>iteration = 0</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_00500.png" alt="L1 – iter 500">
                  <figcaption>iteration = 500</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_01000.png" alt="L1 – iter 1000">
                  <figcaption>iteration = 1k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_01500.png" alt="L1 – iter 1500">
                  <figcaption>iteration = 1.5k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_02000.png" alt="L1 – iter 2000">
                  <figcaption>iteration = 2k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_02500.png" alt="L1 – iter 2500">
                  <figcaption>iteration = 2.5k</figcaption>
                </figure>

                <!-- loop copies for smooth scroll -->
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_00000.png" alt="L1 – iter 0">
                  <figcaption>iteration = 0</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_00500.png" alt="L1 – iter 500">
                  <figcaption>iteration = 500</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_01000.png" alt="L1 – iter 1000">
                  <figcaption>iteration = 1k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_01500.png" alt="L1 – iter 1500">
                  <figcaption>iteration = 1.5k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_02000.png" alt="L1 – iter 2000">
                  <figcaption>iteration = 2k</figcaption>
                </figure>
                <figure class="belt-frame">
                  <img src="media/render/freq/L1/render_02500.png" alt="L1 – iter 2500">
                  <figcaption>iteration = 2.5k</figcaption>
                </figure>
              </div>
            </div>
          </div>

          <!---------------------------- L = 4 ------------------------------------>
          <div class="panel" data-l="L4">
            <figure class="pe-card"><img src="media/pe/L4_rgb.png" alt="L4 – PCA of PE features (colored by RGB)">
              <figcaption>Layers: 256</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L4_uv.png" alt="L4 – PCA of PE features (colored by UV)">
              <figcaption>lr: 1e-2</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L4_penult_pca3_rgb.png"
                alt="L4 – PCA of penultimate features (RGB)">
              <figcaption>2500 iterations</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L4">
              <div class="belt">
                <img src="media/render/freq/L4/render_00000.png" alt="L4 render 1">
                <img src="media/render/freq/L4/render_00500.png" alt="L4 render 2">
                <img src="media/render/freq/L4/render_01000.png" alt="L4 render 3">
                <img src="media/render/freq/L4/render_01500.png" alt="L4 render 4">
                <img src="media/render/freq/L4/render_02000.png" alt="L4 render 5">
                <img src="media/render/freq/L4/render_02500.png" alt="L4 render 6">
                <!-- loop -->
                <img src="media/render/freq/L4/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 8 --------------------------------------->
          <div class="panel" data-l="L8">
            <figure class="pe-card"><img src="media/pe/L8_rgb.png" alt="L8 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L8_uv.png" alt="L8 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L8_penult_pca3_rgb.png"
                alt="L8 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L8">
              <div class="belt">
                <img src="media/render/freq/L8/render_00000.png" alt="L8 render 1">
                <img src="media/render/freq/L8/render_00500.png" alt="L8 render 2">
                <img src="media/render/freq/L8/render_01000.png" alt="L8 render 3">
                <img src="media/render/freq/L8/render_01500.png" alt="L8 render 4">
                <img src="media/render/freq/L8/render_02000.png" alt="L8 render 5">
                <img src="media/render/freq/L8/render_02500.png" alt="L8 render 6">
                <!-- loop -->
                <img src="media/render/freq/L8/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 12 --------------------------------------->

          <div class="panel" data-l="L12">
            <figure class="pe-card"><img src="media/pe/L12_rgb.png" alt="L12 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L12_uv.png" alt="L12 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L12_penult_pca3_rgb.png"
                alt="L12 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L12">
              <div class="belt">
                <img src="media/render/freq/L12/render_00000.png" alt="L12 render 1">
                <img src="media/render/freq/L12/render_00500.png" alt="L12 render 2">
                <img src="media/render/freq/L12/render_01000.png" alt="L12 render 3">
                <img src="media/render/freq/L12/render_01500.png" alt="L12 render 4">
                <img src="media/render/freq/L12/render_02000.png" alt="L12 render 5">
                <img src="media/render/freq/L12/render_02500.png" alt="L12 render 6">
                <!-- loop -->
                <img src="media/render/freq/L12/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 16 --------------------------------------->
          <div class="panel" data-l="L16">
            <figure class="pe-card"><img src="media/pe/L16_rgb.png" alt="L16 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L16_uv.png" alt="L16 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L16_penult_pca3_rgb.png"
                alt="L16 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L16">
              <div class="belt">
                <img src="media/render/freq/L16/render_00000.png" alt="L16 render 1">
                <img src="media/render/freq/L16/render_00500.png" alt="L16 render 2">
                <img src="media/render/freq/L16/render_01000.png" alt="L16 render 3">
                <img src="media/render/freq/L16/render_01500.png" alt="L16 render 4">
                <img src="media/render/freq/L16/render_02000.png" alt="L16 render 5">
                <img src="media/render/freq/L16/render_02500.png" alt="L16 render 6">
                <!-- loop -->
                <img src="media/render/freq/L16/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 24 --------------------------------------->
          <div class="panel" data-l="L24">
            <figure class="pe-card"><img src="media/pe/L24_rgb.png" alt="L24 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L24_uv.png" alt="L24 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L24_penult_pca3_rgb.png"
                alt="L24 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L24">
              <div class="belt">
                <img src="media/render/freq/L24/render_00000.png" alt="L24 render 1">
                <img src="media/render/freq/L24/render_00500.png" alt="L24 render 2">
                <img src="media/render/freq/L24/render_01000.png" alt="L24 render 3">
                <img src="media/render/freq/L24/render_01500.png" alt="L24 render 4">
                <img src="media/render/freq/L24/render_02000.png" alt="L24 render 5">
                <img src="media/render/freq/L24/render_02500.png" alt="L24 render 6">
                <!-- loop -->
                <img src="media/render/freq/L24/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>
        <div class="pe-tabbar" role="tablist" aria-label="L">
          <label for="L1" role="tab">L = 1</label>
          <label for="L4" role="tab">L = 4</label>
          <label for="L8" role="tab">L = 8</label>
          <label for="L12" role="tab">L = 12</label>
          <label for="L16" role="tab">L = 16</label>
          <label for="L24" role="tab">L = 24</label>
        </div>
      </div>


      <article class="glass readable">
        At high frequency (L = 16 and especially L = 24), the PCA geometry becomes highly oscillatory. Instead of a
        single surface or gently folded ribbon, the points fill a dense volume of overlapping bands and sheets that
        weave through one another. The UV-coloured plots reveal thin strands of similar colour that separate and rejoin
        throughout this space, indicating that many small regions of the original image are now mapped to almost
        orthogonal directions in the encoded feature space. Small changes in u or v trigger large swings in the
        sinusoids at high L, so neighbouring pixels cycle through different basis directions in rapid succession. This
        is precisely the regime positional encoding is designed to create: the MLP gains access to very fine spatial
        detail by decorrelating local neighbourhoods, at the cost of a tangled, high-dimensional manifold that is
        difficult to interpret visually but extremely expressive for function fitting.

      </article>
    </section>

    <section id="varying_width" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Varying Widths</h1>
      </header>


      <article class="glass readable">
        Changing the hidden width mainly affects the geometry of the learned feature space rather than the raw
        positional-encoding manifold. The PCA plots of PE(u,v) remain essentially unchanged between the narrow and wide
        networks, since both receive the same sinusoidal expansion of the image coordinates; the encoded points still
        occupy a dense, roughly cubic volume whose principal components are strongly aligned with u and v. The contrast
        appears in the PCA of the penultimate activations. With a smaller width, the distribution forms a relatively
        thick fan-shaped cloud in which luminance, colour, and spatial location remain partially entangled across
        several principal directions. Increasing the width produces a much more anisotropic embedding: most variance
        collapses onto a dominant one-dimensional arc, with secondary components only modulating fine local deviations.
        A wider network therefore spends its extra capacity organising features along a small number of semantically
        meaningful directions rather than expanding the raw PE manifold itself.



      </article>

      <div class="pe-tabs">
        <!-- independent radio group for width -->
        <input type="radio" name="W" id="W64" checked>
        <input type="radio" name="W" id="W256">

        <div class="pe-panels" aria-live="polite">
          <!-- Width = 64 panel -->
          <div class="panel" data-w="W64">
            <figure class="pe-card">
              <img src="media/fox/L64_rgb.png" alt="L = 64, width = 64 – PCA of PE features (RGB)">
              <figcaption>PE • RGB (lr = 1e-2)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_uv.png" alt="L = 64, width = 64 – PCA of PE features (UV)">
              <figcaption>PE • UV (layer depth = 8)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_penult_pca3_rgb.png" alt="L = 64, width = 64 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB (iterations = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L = 64, width = 64">
              <div class="belt">
                <img src="media/fox/width/64/render_00000.png" alt="W = 64, iter 0">
                <img src="media/fox/width/64/render_00500.png" alt="W = 64, iter 500">
                <img src="media/fox/width/64/render_01000.png" alt="W = 64, iter 1000">
                <img src="media/fox/width/64/render_01500.png" alt="W = 64, iter 1500">
                <img src="media/fox/width/64/render_02000.png" alt="W = 64, iter 2000">
                <img src="media/fox/width/64/render_02500.png" alt="W = 64, iter 2500">
                <!-- loop for smooth belt -->
                <img src="media/fox/width/64/render_00000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_00500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_01500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_02000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!-- Width = 256 panel -->
          <div class="panel" data-w="W256">
            <figure class="pe-card">
              <img src="media/fox/L64_rgb.png" alt="L = 64, width = 256 – PCA of PE features (RGB)">
              <figcaption>PE • RGB (width = 256)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_uv.png" alt="L = 64, width = 256 – PCA of PE features (UV)">
              <figcaption>PE • UV (width = 256)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L256_penult_pca3_rgb.png"
                alt="L = 64, width = 256 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB (width = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L = 64, width = 256">
              <div class="belt">
                <img src="media/fox/width/256/render_00000.png" alt="W = 256, iter 0">
                <img src="media/fox/width/256/render_00500.png" alt="W = 256, iter 500">
                <img src="media/fox/width/256/render_01000.png" alt="W = 256, iter 1000">
                <img src="media/fox/width/256/render_01500.png" alt="W = 256, iter 1500">
                <img src="media/fox/width/256/render_02000.png" alt="W = 256, iter 2000">
                <img src="media/fox/width/256/render_02500.png" alt="W = 256, iter 2500">
                <!-- loop -->
                <img src="media/fox/width/256/render_00000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_00500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_01500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_02000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>


        <div class="pe-tabbar" role="tablist" aria-label="Width">
          <label for="W64" role="tab">W = 64</label>
          <label for="W256" role="tab">W = 256</label>
        </div>
      </div>

      <article class="glass readable">
        The belts of intermediate fox reconstructions illustrate how these different embeddings translate into learning
        dynamics. Both widths rapidly recover the coarse outline and average colours of the image, but the narrow model
        retains visible banding and oversmoothed regions even after many iterations, while the wider model continues to
        refine shadows, whiskers, and background texture. This behaviour is consistent with the PCA observations: when
        the penultimate layer collapses most variance onto a single direction, optimisation can follow a relatively
        simple trajectory that first explains global structure and then walks along the arc to capture increasingly fine
        detail. The wider network therefore converges to sharper solutions under the same training schedule, not because
        the positional encoding changed, but because the final layers have more room to carve out an appearance-aligned
        feature space.

      </article>
    </section>

    <section id="final_result" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Final Reconstruction on Chosen Scene</h1>
      </header>

      <article class="glass readable">
        As a concrete example, the same 2D neural field architecture is trained on a single natural image of Jupiter
        using a maximum encoding frequency of L = 16 and a hidden width of 256. The PSNR curve below tracks full-image
        PSNR throughout optimisation, and the conveyor belt of renderings shows how the reconstruction evolves over
        time. Early iterations capture only coarse colour and band structure; mid-training snapshots then recover the
        major storms and cloud belts, and the final image closely matches the ground-truth photograph while still
        smoothing the tiniest turbulent eddies. This experiment serves as the designated “image of choice” for the 2D
        neural field and provides a reference point for interpreting the PCA plots and PSNR curves shown alongside.

      </article>



      <!-- Three static panels: UV, RGB, penultimate (no belt, always visible) -->
      <div class="pe-panels pe-panels-final">
        <div class="panel">
          <figure class="pe-card">
            <img src="media/jupiter/L16_rgb.png" alt="PCA of PE features colored by UV">
            <figcaption>PE • UV (top three principal components)</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/jupiter/L16_uv.png" alt="PCA of PE features colored by RGB">
            <figcaption>PE • RGB (top three principal components)</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/jupiter/L16_penult_pca3_rgb.png" alt="PCA of penultimate features colored by RGB">
            <figcaption>Penultimate • RGB (learned feature geometry)</figcaption>
          </figure>
        </div>
      </div>



      <!-- <article class="glass readable">
        The PSNR curves quantify how quickly this representation emerges over training.
        The batch PSNR rises from single-digit values to around 20 dB within a few hundred iterations, reflecting rapid
        fitting of the global brightness and broad banding patterns.
        The full-image PSNR curve shows a large jump between the initial and first checkpoint renders, then a slower,
        almost linear increase that asymptotically approaches a mid-teens or low-twenties value by the end of training.
        The corresponding renderings match this trajectory: the very first output is nearly uniform, early snapshots
        show
        only faint hints of the dominant bands and storms, and later snapshots progressively sharpen the cloud belts,
        vortices, and color gradients until the final image closely resembles the ground truth while still smoothing the
        finest turbulent eddies.
        Taken together, the PCA plots and PSNR curves demonstrate that the model begins from a purely coordinate-driven
        encoding, then gradually learns an appearance-driven feature space and uses it to reconstruct both the coarse
        spherical structure and much of the intricate atmospheric detail of the original Jupiter photograph.
      </article> -->

      <article class="glass readable">
        The PCA of the penultimate features tells a very different story.
        After passing through the MLP, the encoded points are no longer filling a symmetric three-sheet volume; instead,
        they collapse into a highly elongated plume concentrated near one side of PC space, with most variance lying
        along a single direction.
        Points corresponding to bright clouds, blue storms, and the dark background are separated along this main axis,
        while the secondary axes make only small corrections.
        This pattern indicates that the network has reorganized the high-dimensional PE basis into a much more compact,
        appearance-aligned representation in which luminance and large-scale color structure are encoded by one dominant
        feature dimension, and finer chromatic and textural differences are stored in orthogonal directions.
        In other words, the penultimate layer behaves like a learned color-space tailored to the Jupiter image rather
        than a direct reflection of the original (u,v) coordinates.
      </article>


      <!-- If you still want the final image + PSNR + belt, you can keep this or remove it -->
      <div class="pe-tabs">
        <input type="radio" name="R" id="RFINAL" checked>

        <div class="pe-panels" aria-live="polite">
          <div class="panel" data-r="RFINAL">
            <figure class="pe-card">
              <img src="media/jupiter/ground_truth.jpg" alt="Ground-truth image of the chosen scene">
              <figcaption>Ground-truth view (input photograph)</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/jupiter/psnr_curve_batch.png" alt="PSNR curve over training iterations">
              <figcaption>Batch PSNR over training iterations</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/jupiter/progression/render_05000.png" alt="Final NeRF reconstruction of the chosen view">
              <figcaption>Final NeRF reconstruction (e.g., 5k iters, L = 16, width = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Training progression for the chosen scene">
              <div class="belt">
                <img src="media/jupiter/progression/render_00000.png" alt="Iteration 0">
                <img src="media/jupiter/progression/render_01000.png" alt="Iteration 1000">
                <img src="media/jupiter/progression/render_02000.png" alt="Iteration 2000">
                <img src="media/jupiter/progression/render_03000.png" alt="Iteration 3000">
                <img src="media/jupiter/progression/render_04000.png" alt="Iteration 4000">
                <img src="media/jupiter/progression/render_05000.png" alt="Iteration 5000">
                <!-- loop copies for infinite scroll -->
                <img src="media/jupiter/progression/render_00000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_01000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_02000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_03000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_04000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_05000.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>

        <div class="pe-tabbar" role="tablist" aria-label="Final result">
          <label for="RFINAL" role="tab">Final Result</label>
        </div>
      </div>

      <!-- <article class="glass readable">
        The PCA of the penultimate features tells a very different story.
        After passing through the MLP, the encoded points are no longer filling a symmetric three-sheet volume; instead,
        they collapse into a highly elongated plume concentrated near one side of PC space, with most variance lying
        along a single direction.
        Points corresponding to bright clouds, blue storms, and the dark background are separated along this main axis,
        while the secondary axes make only small corrections.
        This pattern indicates that the network has reorganized the high-dimensional PE basis into a much more compact,
        appearance-aligned representation in which luminance and large-scale color structure are encoded by one dominant
        feature dimension, and finer chromatic and textural differences are stored in orthogonal directions.
        In other words, the penultimate layer behaves like a learned color-space tailored to the Jupiter image rather
        than a direct reflection of the original (u,v) coordinates.
      </article> -->

      <article class="glass readable">
        Taken together, the PCA plots and PSNR curves describe a consistent progression from coordinate-driven to
        appearance-driven representation. The PCA of PE features coloured by UV shows that the raw positional encodings
        still form a regular three-sheet manifold whose principal components remain aligned with approximate latitude
        and longitude on the sphere. When the same points are coloured by RGB instead of UV, the colours spread almost
        uniformly throughout this volume, confirming that the encoding at this stage is dominated by oscillatory
        coordinate structure rather than any semantic grouping by appearance. Only after passing through the MLP do the
        points collapse into the elongated plume seen in the penultimate PCA, where a single dominant direction
        separates bright clouds, blue storms, and dark background. The rising PSNR curve mirrors this reorganisation:
        rapid gains in the first iterations reflect the network discovering a compact, appearance-aligned feature axis,
        while the slower tail corresponds to fine adjustments along that axis that recover small-scale atmospheric
        detail.

      </article>

      <!-- <article class="glass readable">
        The PSNR curves quantify how quickly this representation emerges over training.
        The batch PSNR rises from single-digit values to around 20 dB within a few hundred iterations, reflecting rapid
        fitting of the global brightness and broad banding patterns.
        The full-image PSNR curve shows a large jump between the initial and first checkpoint renders, then a slower,
        almost linear increase that asymptotically approaches a mid-teens or low-twenties value by the end of training.
        The corresponding renderings match this trajectory: the very first output is nearly uniform, early snapshots
        show
        only faint hints of the dominant bands and storms, and later snapshots progressively sharpen the cloud belts,
        vortices, and color gradients until the final image closely resembles the ground truth while still smoothing the
        finest turbulent eddies.
        Taken together, the PCA plots and PSNR curves demonstrate that the model begins from a purely coordinate-driven
        encoding, then gradually learns an appearance-driven feature space and uses it to reconstruct both the coarse
        spherical structure and much of the intricate atmospheric detail of the original Jupiter photograph.
      </article> -->
    </section>

    <section id="pipeline" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>NeRF Pipeline</h1>
      </header>

      <article class="glass readable">
        The first stage of the pipeline translates image pixels into rays in 3D space.
        For each training step, a batch of pixel locations is drawn from the current set of images.
        Instead of treating each pixel in isolation, the implementation works entirely in batches so that thousands of
        rays can be computed in one vectorized pass on the GPU.
        For every pixel, its horizontal and vertical coordinates are first shifted so that they are measured relative to
        the center of the image; this ensures that a pixel exactly in the middle of the frame produces a ray pointing
        straight through the optical axis rather than being biased by the top-left origin of image coordinates.
        These centered coordinates are then divided by the focal length to convert them into directions in the camera’s
        local coordinate system, following the standard pinhole-camera model in which the focal length controls the
        spread of rays.
        Each camera in the training set is described by a rigid transform from camera space to world space; for every
        ray in the batch, the implementation looks up the corresponding camera’s rotation and translation and uses them
        to rotate the local direction into the global reference frame while placing the ray’s origin at the camera
        center.
        Finally, all directions are normalized to unit length so that subsequent sampling along the ray can be expressed
        purely in terms of distances from the camera.
        The result of this stage is a batch of ray origins and matching direction vectors that describe exactly which 3D
        lines will be probed in the volume.
      </article>

      <!-- Rays: three-panel visualization (always visible, no belt) -->
      <div class="pe-panels pe-rays" aria-live="polite">
        <div class="panel">
          <figure class="pe-card">
            <img src="media/viser/all_rays.png" alt="All cameras in the scene with visualized frustums">
            <figcaption>All calibrated camera frustums around the Lego scene.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/ray1.png" alt="Rays cast from a single training camera">
            <figcaption>Random training rays emitted from one camera in world space.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/ray2.png" alt="Sample locations along each ray">
            <figcaption>Stratified sample points along each ray, ready for NeRF evaluation.</figcaption>
          </figure>
        </div>
      </div>


      <article class="glass readable">
        Once the rays exist in world space, the next stage chooses where along each ray to query the neural field.
        The implementation uses a stratified scheme: it begins by placing a fixed number of sample depths between a near
        and a far bound that cover the region where the scene is expected to lie.
        Instead of always using the same depth values, each interval between two neighboring depths is randomly jittered
        on every training iteration.
        This produces slightly different sampling positions from step to step, which reduces aliasing artifacts and
        encourages the learned density field to be smooth rather than fitting to a rigid grid of points.
        For each ray, these scalar depths are then converted into 3D sample locations by adding the origin plus the
        direction vector scaled by each depth value.
        The outcome of this stage is a dense batch of points in space, all organized per ray, ready to be evaluated by
        the neural network.
      </article>

      <article class="glass readable">
        The Lego experiments use a standard NeRF-style multilayer perceptron that takes 3D positions and viewing
        directions as input and outputs a volume density and RGB colour for each queried point. Both inputs are first
        mapped through sinusoidal positional encodings—ten frequency bands for positions and four for directions—and
        then passed through an eight-layer fully connected network of width 256 with ReLU activations and a final
        linear output layer. Training uses the Adam optimiser with a learning rate of 5×10<sup>−4</sup>, drawing 64
        stratified samples along each ray for 10&nbsp;000 iterations. The PSNR curve and final train/validation views
        above report reconstruction quality on held-out views and show that the model converges to a sharp,
        view-consistent representation of the Lego scene.
      </article>


      <!-- Lego NeRF: three panels (PSNR + final train + final val) -->
      <div class="pe-panels pe-lego" aria-live="polite">
        <div class="panel">
          <!-- PSNR curve over training -->
          <figure class="pe-card">
            <img src="media/lego_scan/psnr_curve.png" alt="Lego scene: PSNR curve over training iterations">
            <figcaption>PSNR over training iterations (Lego 200×200)</figcaption>
          </figure>

          <!-- Final training view -->
          <figure class="pe-card">
            <img src="media/lego_scan/train_10000.png" alt="Lego scene: final NeRF reconstruction (training view)">
            <figcaption>Final NeRF reconstruction of a training view (iteration 10 000)</figcaption>
          </figure>

          <!-- Final validation view -->
          <figure class="pe-card">
            <img src="media/lego_scan/val_10000.png" alt="Lego scene: final NeRF reconstruction (validation view)">
            <figcaption>Final NeRF reconstruction of a held-out validation view</figcaption>
          </figure>
        </div>
      </div>

      <article class="glass readable">
        Feeding data into this process is handled by a streaming dataset tailored to NeRF’s requirements.
        When training begins, the dataset loader reads a compact file that contains the entire scene: a stack of RGB
        images, the corresponding camera-to-world transforms, and a shared focal length consistent with the resolution
        of those images.
        Rather than iterating over the images in a fixed order, the loader behaves like an infinite stream: each time
        the trainer asks for a new batch, it randomly chooses image indices and pixel coordinates, effectively sampling
        rays uniformly across all views and across the whole image plane.
        For every sampled triplet of (image index, horizontal pixel, vertical pixel), the loader immediately retrieves
        the true color at that pixel from the preloaded image tensor and retrieves the pose of the camera that observed
        it.
        It then passes these sampled image coordinates and camera transforms to the ray-generation stage, which produces
        the matching ray origins and directions.
        In this way, each training batch consists of a large set of randomly selected rays and their ground-truth RGB
        values, allowing the network to gradually see all viewpoints and all parts of the scene over the course of
        training without ever needing to materialize the entire ray bundle in memory at once.
      </article>

      <!-- Lego NeRF: stacked conveyor belts (train over validation) -->
      <div class="pe-panels pe-lego" aria-live="polite">
        <div class="panel">
          <div class="graph-belt lego-belt" aria-label="Lego reconstruction progression">
            <!-- Training progression -->
            <div class="belt">
              <figure class="belt-frame">
                <img src="media/lego_scan/train_01000.png" alt="Training view, iteration 1 000">
                <figcaption>Train 1k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_02000.png" alt="Training view, iteration 2 000">
                <figcaption>Train 2k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_03000.png" alt="Training view, iteration 3 000">
                <figcaption>Train 3k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_04000.png" alt="Training view, iteration 4 000">
                <figcaption>Train 4k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_05000.png" alt="Training view, iteration 5 000">
                <figcaption>Train 5k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_06000.png" alt="Training view, iteration 6 000">
                <figcaption>Train 6k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_07000.png" alt="Training view, iteration 7 000">
                <figcaption>Train 7k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_08000.png" alt="Training view, iteration 8 000">
                <figcaption>Train 8k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_09000.png" alt="Training view, iteration 9 000">
                <figcaption>Train 9k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_10000.png" alt="Training view, iteration 10 000">
                <figcaption>Train 10k</figcaption>
              </figure>

              <!-- loop copies for continuous scroll -->
              <figure class="belt-frame">
                <img src="media/lego_scan/train_01000.png" alt="Training view, iteration 1 000">
                <figcaption>Train 1k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_02000.png" alt="Training view, iteration 2 000">
                <figcaption>Train 2k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_03000.png" alt="Training view, iteration 3 000">
                <figcaption>Train 3k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_04000.png" alt="Training view, iteration 4 000">
                <figcaption>Train 4k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_05000.png" alt="Training view, iteration 5 000">
                <figcaption>Train 5k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_06000.png" alt="Training view, iteration 6 000">
                <figcaption>Train 6k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_07000.png" alt="Training view, iteration 7 000">
                <figcaption>Train 7k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_08000.png" alt="Training view, iteration 8 000">
                <figcaption>Train 8k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_09000.png" alt="Training view, iteration 9 000">
                <figcaption>Train 9k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/train_10000.png" alt="Training view, iteration 10 000">
                <figcaption>Train 10k</figcaption>
            </div>

            <!-- Validation progression -->
            <div class="belt">
              <figure class="belt-frame">
                <img src="media/lego_scan/val_01000.png" alt="Validation view, iteration 1 000">
                <figcaption>Validation 1k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_02000.png" alt="Validation view, iteration 2 000">
                <figcaption>Validation 2k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_03000.png" alt="Validation view, iteration 3 000">
                <figcaption>Validation 3k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_04000.png" alt="Validation view, iteration 4 000">
                <figcaption>Validation 4k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_05000.png" alt="Validation view, iteration 5 000">
                <figcaption>Validation 5k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_06000.png" alt="Validation view, iteration 6 000">
                <figcaption>Validation 6k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_07000.png" alt="Validation view, iteration 7 000">
                <figcaption>Validation 7k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_08000.png" alt="Validation view, iteration 8 000">
                <figcaption>Validation 8k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_09000.png" alt="Validation view, iteration 9 000">
                <figcaption>Validation 9k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_10000.png" alt="Validation view, iteration 10 000">
                <figcaption>Validation 10k</figcaption>
              </figure>

              <!-- loop copies -->
              figure class="belt-frame">
              <img src="media/lego_scan/val_01000.png" alt="Validation view, iteration 1 000">
              <figcaption>Validation 1k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_02000.png" alt="Validation view, iteration 2 000">
                <figcaption>Validation 2k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_03000.png" alt="Validation view, iteration 3 000">
                <figcaption>Validation 3k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_04000.png" alt="Validation view, iteration 4 000">
                <figcaption>Validation 4k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_05000.png" alt="Validation view, iteration 5 000">
                <figcaption>Validation 5k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_06000.png" alt="Validation view, iteration 6 000">
                <figcaption>Validation 6k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_07000.png" alt="Validation view, iteration 7 000">
                <figcaption>Validation 7k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_08000.png" alt="Validation view, iteration 8 000">
                <figcaption>Validation 8k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_09000.png" alt="Validation view, iteration 9 000">
                <figcaption>Validation 9k</figcaption>
              </figure>
              <figure class="belt-frame">
                <img src="media/lego_scan/val_10000.png" alt="Validation view, iteration 10 000">
                <figcaption>Validation 10k</figcaption>
              </figure>
            </div>
          </div>

        </div>
      </div>

      <!-- Orbit GIF at the end -->
      <div class="center-media">
        <figure>
          <img src="media/lego_scan/lego.gif" alt="NeRF reconstruction orbit of the scene">
          <figcaption>NeRF orbit of the reconstructed scene (10k iterations), illustrating the full pipeline in motion.
          </figcaption>
        </figure>
      </div>
    </section>

    <section id="my_scene" class="section alt">
      <header class="section-header">
        <h1 class="serif" style="margin-bottom:0" data-reveal-line>
          Training on a Real-World Scene
        </h1>
      </header>


      <article class="glass readable">
        To assess how the reconstruction pipeline behaves on real imagery, the target is a small ceramic
        house placed on an 8×11 ChArUco board and viewed from 91 handheld positions around the object. Camera intrinsics
        are estimated once using a dedicated calibration sequence; for the NeRF training set, each photograph is
        undistorted, its pose is recovered from the detected fiducial markers, and the resulting images are resampled to
        a resolution of 200×200 pixels. The calibrated camera poses are expressed as rigid transforms from camera to
        world coordinates and partitioned into 91 training views, 15 validation views, and a small set of test
        viewpoints reserved for novel-view evaluation. The radiance field is represented by a standard multi-layer
        perceptron of depth eight and width 256, with a skip connection that re-injects the input coordinates halfway
        through the network. Three-dimensional positions are encoded with a sinusoidal positional encoding using ten
        frequency bands, and viewing directions are encoded with four bands. Training proceeds by sampling thousands of
        rays per iteration uniformly over the training images and optimising the network with Adam, starting from a
        learning rate of 5×10<sup>−4</sup> and following a cosine decay schedule over 10&nbsp;000 iterations so that
        early updates correct coarse geometry while later stages focus on fine-scale appearance.
      </article>

      <!-- I WANT THE RAYS OF THE OBJECT HERE -->



      <!-- Training dynamics and quantitative results -->
      <article class="glass readable">
        Along each ray, a fixed number of points are drawn from a depth interval that brackets the physical extent of
        the house and calibration board (approximately 0.44 to 0.98 units in the calibrated frame). For each batch, the
        network predicts densities and view-dependent colours at these samples, which are then combined through
        volumetric integration to form final pixel intensities. The discrepancy between rendered and observed colours is
        measured with a mean-squared-error objective. Optimising for 10&nbsp;000 iterations produces a characteristic
        two-phase learning curve. PSNR jumps from roughly 5&nbsp;dB to around 18&nbsp;dB within the first thousand
        iterations as the model discovers the dominant colour distribution and coarse geometry, then increases more
        slowly, reaching about 22.5&nbsp;dB by 5&nbsp;000 iterations and stabilising near 23&nbsp;dB by the end of
        training. The corresponding loss curve decreases smoothly from roughly 0.32 to about 5×10<sup>−3</sup> without
        noticeable oscillation, indicating a stable optimisation process and no strong signs of over-fitting despite
        the modest number of views.
      </article>


      <!-- Tabs for different training runs (e.g. 5k vs 10k iterations) -->
      <div class="pe-tabs">
        <!-- independent radio group for runs -->
        <input type="radio" name="S" id="S5k">
        <input type="radio" name="S" id="S10k" checked>

        <div class="pe-panels pe-mydata" aria-live="polite">
          <!-- Run A: 5k iterations -->
          <div class="panel" data-s="S5k">
            <figure class="pe-card">
              <img src="media/house/5k/house_psnr_curve.png" alt="Custom scene – PSNR curve for 5k-iteration run">
              <figcaption>PSNR (5k iterations, lr = 5e-4, 64 samples/ray).</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/house/5k/house_loss_curve.png" alt="Loss curve for 5k iters">
              <figcaption>Loss Function (width = 256, depth = 8)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/house/5k/val_final.png" alt="Custom scene – validation view at 5k iterations">
              <figcaption>Held-out validation view (near = 0.35, far = 1.0).</figcaption>
            </figure>

            <!-- Optional: belt of intermediate renders for this run -->
            <div class="graph-belt" aria-label="Custom scene progression (5k run)">
              <div class="belt">
                <img src="media/house/5k/train_01000.png" alt="5k run – iter 1k">
                <img src="media/house/5k/train_02000.png" alt="5k run – iter 2k">
                <img src="media/house/5k/train_03000.png" alt="5k run – iter 3k">
                <img src="media/house/5k/train_04000.png" alt="5k run – iter 4k">
                <img src="media/house/5k/train_05000.png" alt="5k run – iter 5k">
                <!-- loop copies for smooth scroll -->
                <img src="media/house/5k/train_01000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/train_02000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/train_03000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/train_04000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/train_05000.png" alt="" aria-hidden="true">
              </div>

              <!-- Validation progression -->
              <div class="belt">
                <img src="media/house/5k/val_01000.png" alt="10k run – val iter 1k">
                <img src="media/house/5k/val_02000.png" alt="10k run – val iter 2k">
                <img src="media/house/5k/val_03000.png" alt="10k run – val iter 3k">
                <img src="media/house/5k/val_04000.png" alt="10k run – val iter 4k">
                <img src="media/house/5k/val_05000.png" alt="10k run – val iter 5k">
                <!-- loop copies for continuous scroll -->
                <img src="media/house/5k/val_01000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/val_02000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/val_03000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/val_04000.png" alt="" aria-hidden="true">
                <img src="media/house/5k/val_05000.png" alt="" aria-hidden="true">

              </div>
            </div>

          </div>



          <!-- Run B: 10k iterations -->
          <div class="panel" data-s="S10k">
            <figure class="pe-card">
              <img src="media/house/10k/house_psnr_curve.png" alt="Custom scene – PSNR curve for 10k-iteration run">
              <figcaption>PSNR curve (10k iterations, extended schedule on the same architecture).</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/house/10k/house_loss_curve.png" alt="Custom scene – loss curve for 10k-iteration run">
              <figcaption>Loss curve for the 10k-iteration run.</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/house/10k/val_10000.png" alt="Custom scene – validation view at 10k iterations">
              <figcaption>Held-out validation view at 10k iterations.</figcaption>
            </figure>

            <!-- Stacked belts (train + val), every 1k, similar to Lego layout -->
            <div class="graph-belt" aria-label="Custom scene progression (10k run)">
              <!-- Training progression -->
              <div class="belt">
                <img src="media/house/10k/train_01000.png" alt="10k run – train iter 1k">
                <img src="media/house/10k/train_02000.png" alt="10k run – train iter 2k">
                <img src="media/house/10k/train_03000.png" alt="10k run – train iter 3k">
                <img src="media/house/10k/train_04000.png" alt="10k run – train iter 4k">
                <img src="media/house/10k/train_05000.png" alt="10k run – train iter 5k">
                <img src="media/house/10k/train_06000.png" alt="10k run – train iter 6k">
                <img src="media/house/10k/train_07000.png" alt="10k run – train iter 7k">
                <img src="media/house/10k/train_08000.png" alt="10k run – train iter 8k">
                <img src="media/house/10k/train_09000.png" alt="10k run – train iter 9k">
                <img src="media/house/10k/train_10000.png" alt="10k run – train iter 10k">
                <!-- loop copies for smooth scroll -->
                <img src="media/house/10k/train_01000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_02000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_03000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_04000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_05000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_06000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_07000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_08000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_09000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/train_10000.png" alt="" aria-hidden="true">
              </div>

              <!-- Validation progression -->
              <div class="belt">
                <img src="media/house/10k/val_01000.png" alt="10k run – val iter 1k">
                <img src="media/house/10k/val_02000.png" alt="10k run – val iter 2k">
                <img src="media/house/10k/val_03000.png" alt="10k run – val iter 3k">
                <img src="media/house/10k/val_04000.png" alt="10k run – val iter 4k">
                <img src="media/house/10k/val_05000.png" alt="10k run – val iter 5k">
                <img src="media/house/10k/val_06000.png" alt="10k run – val iter 6k">
                <img src="media/house/10k/val_07000.png" alt="10k run – val iter 7k">
                <img src="media/house/10k/val_08000.png" alt="10k run – val iter 8k">
                <img src="media/house/10k/val_09000.png" alt="10k run – val iter 9k">
                <img src="media/house/10k/val_10000.png" alt="10k run – val iter 10k">
                <img src="media/house/10k/val_11000.png" alt="10k run – val iter 11k">
                <!-- loop copies for continuous scroll -->
                <img src="media/house/10k/val_01000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_02000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_03000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_04000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_05000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_06000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_07000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_08000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_09000.png" alt="" aria-hidden="true">
                <img src="media/house/10k/val_10000.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>
        <!-- Tab labels for runs -->
        <div class="pe-tabbar" role="tablist" aria-label="Training run">
          <label for="S5k" role="tab">5k iters</label>
          <label for="S10k" role="tab">10k iters</label>
        </div>
      </div>
      </div>


      <!-- Qualitative evolution and limitations -->
      <article class="glass readable">
        Early training snapshots of the ceramic house show a diffuse brown volume with only faint hints of structure; at
        this stage the model has captured an average colour and rough depth range but has not yet aligned the geometry.
        Between one and two thousand iterations the triangular roof, chimney, and square footprint become clearly
        identifiable, and the high-contrast calibration board sharpens from a blurred patch into a checker pattern.
        Subsequent iterations mainly refine edges, deepen shadows, and improve the separation between the house, board,
        and background, reducing low-frequency bias in the carpet texture. By the final validation frame the roof
        ridgeline is crisp, the board squares are well separated, and residual blur is confined to the finest details,
        which is consistent with the 200×200 resolution and the chosen network capacity.

      </article>

      <!-- Novel-view synthesis / orbit -->
      <article class="glass readable">
        To evaluate generalisation beyond the training views, a synthetic orbit is generated by placing virtual cameras
        on a circle whose radius matches the typical distance of the captured viewpoints. Each virtual camera is
        oriented so that its optical axis passes through a point near the centre of the house while its vertical axis is
        aligned with the scene’s up direction, producing a smooth sweep around the object at constant elevation. The
        resulting novel views emphasise how the learned radiance field interpolates between the original poses: parallax
        in the house silhouette and calibration board remains coherent, and specular highlights on the ceramic glaze
        move consistently with viewpoint. Comparing orbits from the 5k and 10k runs shows that the longer schedule does
        not alter the overall geometry but reduces shimmering artefacts and staircasing along high-contrast edges,
        yielding cleaner motion and slightly sharper frames under the same rendering setup.
      </article>





      <!-- Orbit GIF / video stays at the end -->
      <!-- Orbit GIF (switches with 5k / 10k buttons) -->
      <div class="center-media">
        <figure>
          <img id="my-scene-orbit" src="media/house/10k/house_10k.gif"
            alt="NeRF orbit of the custom scene (5k-iteration run)">
          <figcaption>
            Orbit of the trained NeRF scene!!
          </figcaption>
        </figure>
      </div>


      <article class="glass readable">
        <!-- The 10k-iteration run, trained with the same base learning rate but a cosine decay down to 5e-6 after 5k
        steps, behaves differently after the midpoint.
        Its PSNR curve closely tracks the 5k curve up to approximately iteration 5000, then continues to climb for
        several thousand more iterations, adding another one to two decibels of improvement before flattening. -->
        Qualitatively, the renders at 6k and 8k iterations show the triangular peak and its shadow sharpening, the
        edge between the board and the table becoming crisper, and the subtle grid pattern on the calibration board
        becoming easier to discern.
        By iteration 10k, the training view has noticeably fewer low-frequency artifacts and less noise in the
        background, and the validation view reveals cleaner lines along the object’s silhouette while preserving the
        same global appearance as in the shorter run.
        Together, these comparisons indicate that five thousand iterations are sufficient to capture the overall shape
        and color of the scene, while a longer schedule primarily refines small-scale structure and reduces residual
        blur, yielding smoother textures and slightly higher PSNR at the cost of additional compute.
      </article>
    </section>











    <!---------------------------------------- Part 2 Fit a Neural Radiance Field from Multi-view Images ----------------------------------------->
    <!-- <section id="nrl" class="section-alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line> Fitting Neural Radiance Field from Multi-view Images</h1>
      </header>
      <article glass data-reveal>
        <h2>
          Report your model architecture including number of layers, width, and learning rate. Feel free to add other
          details you think are important.
          Show training progression (images at different iterations, similar to the above reference) on both the
          provided test image and one of your own images.
          Show final results for 2 choices of max positional encoding frequency and 2 choices of width (a 2x2 grid of
          results). Try very low values for these hyperparameters to see how it affects the outputs.
          Show the PSNR curve for training on one image of your choice.
        </h2>
      </article>
    </section> -->


    <!-- END OF HTML -->
</body>

</html>