<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Neural Fields</title>
  <meta name="description"
    content="CS180 Project 4 report with calibration, neural fields, NeRF training, results, analysis, and extras." />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&family=Cormorant+Garamond:wght@400;600&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="../proj4/styles.css" />
  <script defer src="../proj4/script.js"></script>
</head>

<body>
  <!-- fixed starfield backdrop -->
  <canvas id="sky" aria-hidden="true"></canvas>

  <header class="site-header" role="banner">
    <div class="progress" aria-hidden="true"><span class="bar"></span></div>
    <a class="brand" href="#">CS180 • Project 4</a>
  </header>

  <!----------------------------------------------------- Title ----------------------------------------------------->
  <main id="main">
    <section class="hero">
      <h1 class="serif title" data-split="chars">Neural Fields </h1>
      <p class="lead">UC&nbsp;Berkeley • CS180 Computational Photography. </p>

    </section>


    <!----------------------------------------------- Part 0 Camera Calibration and 3D Scanning ------------------------------------------------->
    <section id="3D Scan" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Camera Calibration and 3D Scanning</h1>
      </header>

      <div class="grid-2">
        <figure class="figure">
          <img src="media/viser/frustums_view1.png" alt="Viser frustums view 1">
          <figcaption>View 1 — global layout of camera poses.</figcaption>
        </figure>

        <figure class="figure">
          <img src="media/viser/frustums_view2.png" alt="Viser frustums view 2">
          <figcaption>View 2 — closer look at pose cluster and field of view.</figcaption>
        </figure>
      </div>
    </section>


    <!------------------------------------------------ Part 1 Fit a Neural Field to a 2D Image ---------------------------------------------------->
    <section id="max_encoding" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Varying Encoding Frequency</h1>
      </header>

      <article class="glass readable">
        To visualize how positional encoding transforms image coordinates, each PE(u,v) vector is projected onto its top
        three PCA components while the maximum encoding frequency L is varied.
        The PCA plots reveal that positional encoding progressively twists the original two-dimensional coordinate grid
        into a higher-dimensional manifold as L increases.
        For very low frequency (L = 1), the encoded PE(u,v) vectors occupy a single smooth, bowl-shaped surface in the
        top three principal components.
        The gradient of colors from red to green along this surface indicates that the first two principal components
        are almost linear functions of u and v, so the encoding behaves like a gently curved embedding of the image
        plane with no folds: nearby pixels in image coordinates remain nearby in feature space.
        This behavior is typical for low-frequency positional encodings, which tend to produce a smooth two-dimensional
        sheet in feature space with only mild curvature from which the network can draw samples.
      </article>

      <article class="glass readable">
        At mid-range frequencies (L = 8 and L = 12), the PCA manifolds begin to exhibit clear multi-layered structure.
        The surfaces no longer form a single simple bowl but instead resemble sheets that have been folded or partially
        rolled, with regions of the grid mapped to different heights in PC3 even when their PC1 and PC2 coordinates
        almost overlap.
        The color gradients in these plots confirm that the embedding is still globally ordered by u and v, because red
        and green bands do not intersect randomly; however, pixels that are adjacent along one coordinate can now be
        separated along the third principal component whenever the corresponding sine and cosine terms switch phase.
        This behavior shows that mid-frequency encodings preserve global continuity but already introduce local
        non-linearity: the network receives a representation where local neighborhoods are stretched and sheared, making
        it easier to represent edges and moderate-frequency texture with a finite number of ReLU layers.
      </article>


      <div class="pe-tabs">
        <!-- radios -->
        <input type="radio" name="L" id="L1" checked>
        <input type="radio" name="L" id="L4">
        <input type="radio" name="L" id="L8">
        <input type="radio" name="L" id="L12">
        <input type="radio" name="L" id="L16">
        <input type="radio" name="L" id="L24">


        <div class="pe-panels" aria-live="polite">
          <!---------------------------- L = 1 ------------------------------------>
          <div class="panel" data-l="L1">
            <figure class="pe-card"><img src="media/pe/L1_rgb.png" alt="L1 – PCA of PE features (colored by RGB)">
              <figcaption>Layers: 256</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L1_uv.png" alt="L1 – PCA of PE features (colored by UV)">
              <figcaption>lr: 1e-2</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L1_penult_pca3_rgb.png"
                alt="L1 – PCA of penultimate features (RGB)">
              <figcaption>2500 iterations</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L1">
              <div class="belt">
                <img src="media/render/freq/L1/render_00000.png" alt="L1 render 1">
                <img src="media/render/freq/L1/render_00500.png" alt="L1 render 2">
                <img src="media/render/freq/L1/render_01000.png" alt="L1 render 3">
                <img src="media/render/freq/L1/render_01500.png" alt="L1 render 4">
                <img src="media/render/freq/L1/render_02000.png" alt="L1 render 5">
                <img src="media/render/freq/L1/render_02500.png" alt="L1 render 6">
                <!-- loop -->
                <img src="media/render/freq/L1/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L1/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L1/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L1/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L1/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 4 ------------------------------------>
          <div class="panel" data-l="L4">
            <figure class="pe-card"><img src="media/pe/L4_rgb.png" alt="L4 – PCA of PE features (colored by RGB)">
              <figcaption>Layers: 256</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L4_uv.png" alt="L4 – PCA of PE features (colored by UV)">
              <figcaption>lr: 1e-2</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L4_penult_pca3_rgb.png"
                alt="L4 – PCA of penultimate features (RGB)">
              <figcaption>2500 iterations</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L4">
              <div class="belt">
                <img src="media/render/freq/L4/render_00000.png" alt="L4 render 1">
                <img src="media/render/freq/L4/render_00500.png" alt="L4 render 2">
                <img src="media/render/freq/L4/render_01000.png" alt="L4 render 3">
                <img src="media/render/freq/L4/render_01500.png" alt="L4 render 4">
                <img src="media/render/freq/L4/render_02000.png" alt="L4 render 5">
                <img src="media/render/freq/L4/render_02500.png" alt="L4 render 6">
                <!-- loop -->
                <img src="media/render/freq/L4/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L4/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 8 --------------------------------------->
          <div class="panel" data-l="L8">
            <figure class="pe-card"><img src="media/pe/L8_rgb.png" alt="L8 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L8_uv.png" alt="L8 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L8_penult_pca3_rgb.png"
                alt="L8 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L8">
              <div class="belt">
                <img src="media/render/freq/L8/render_00000.png" alt="L8 render 1">
                <img src="media/render/freq/L8/render_00500.png" alt="L8 render 2">
                <img src="media/render/freq/L8/render_01000.png" alt="L8 render 3">
                <img src="media/render/freq/L8/render_01500.png" alt="L8 render 4">
                <img src="media/render/freq/L8/render_02000.png" alt="L8 render 5">
                <img src="media/render/freq/L8/render_02500.png" alt="L8 render 6">
                <!-- loop -->
                <img src="media/render/freq/L8/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L8/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 12 --------------------------------------->

          <div class="panel" data-l="L12">
            <figure class="pe-card"><img src="media/pe/L12_rgb.png" alt="L12 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L12_uv.png" alt="L12 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L12_penult_pca3_rgb.png"
                alt="L12 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L12">
              <div class="belt">
                <img src="media/render/freq/L12/render_00000.png" alt="L12 render 1">
                <img src="media/render/freq/L12/render_00500.png" alt="L12 render 2">
                <img src="media/render/freq/L12/render_01000.png" alt="L12 render 3">
                <img src="media/render/freq/L12/render_01500.png" alt="L12 render 4">
                <img src="media/render/freq/L12/render_02000.png" alt="L12 render 5">
                <img src="media/render/freq/L12/render_02500.png" alt="L12 render 6">
                <!-- loop -->
                <img src="media/render/freq/L12/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L12/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 16 --------------------------------------->
          <div class="panel" data-l="L16">
            <figure class="pe-card"><img src="media/pe/L16_rgb.png" alt="L16 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L16_uv.png" alt="L16 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L16_penult_pca3_rgb.png"
                alt="L16 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L16">
              <div class="belt">
                <img src="media/render/freq/L16/render_00000.png" alt="L16 render 1">
                <img src="media/render/freq/L16/render_00500.png" alt="L16 render 2">
                <img src="media/render/freq/L16/render_01000.png" alt="L16 render 3">
                <img src="media/render/freq/L16/render_01500.png" alt="L16 render 4">
                <img src="media/render/freq/L16/render_02000.png" alt="L16 render 5">
                <img src="media/render/freq/L16/render_02500.png" alt="L16 render 6">
                <!-- loop -->
                <img src="media/render/freq/L16/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L16/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!---------------------------- L = 24 --------------------------------------->
          <div class="panel" data-l="L24">
            <figure class="pe-card"><img src="media/pe/L24_rgb.png" alt="L24 – PCA of PE features (colored by RGB)">
              <figcaption>PE • RGB</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L24_uv.png" alt="L24 – PCA of PE features (colored by UV)">
              <figcaption>PE • UV</figcaption>
            </figure>
            <figure class="pe-card"><img src="media/pe/L24_penult_pca3_rgb.png"
                alt="L24 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L24">
              <div class="belt">
                <img src="media/render/freq/L24/render_00000.png" alt="L24 render 1">
                <img src="media/render/freq/L24/render_00500.png" alt="L24 render 2">
                <img src="media/render/freq/L24/render_01000.png" alt="L24 render 3">
                <img src="media/render/freq/L24/render_01500.png" alt="L24 render 4">
                <img src="media/render/freq/L24/render_02000.png" alt="L24 render 5">
                <img src="media/render/freq/L24/render_02500.png" alt="L24 render 6">
                <!-- loop -->
                <img src="media/render/freq/L24/render_00000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_00500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_01500.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_02000.png" alt="" aria-hidden="true">
                <img src="media/render/freq/L24/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>
        <div class="pe-tabbar" role="tablist" aria-label="L">
          <label for="L1" role="tab">L = 1</label>
          <label for="L4" role="tab">L = 4</label>
          <label for="L8" role="tab">L = 8</label>
          <label for="L12" role="tab">L = 12</label>
          <label for="L16" role="tab">L = 16</label>
          <label for="L24" role="tab">L = 24</label>
        </div>
      </div>


      <article class="glass readable">

        At high frequency (L = 16 and especially L = 24), the PCA geometry becomes highly oscillatory.
        Instead of a single surface or a gently folded ribbon, the points fill a dense volume made up of overlapping
        bands and sheets that weave through one another.
        The color pattern, which encodes the original UV coordinates, makes this structure easier to interpret: blocks
        of similar color form thin, separated strands in PC space, indicating that many disjoint regions of the original
        image are now mapped to very different directions in the encoded feature space.
        In other words, small changes in u or v trigger large swings in the sinusoids at high L, so nearby pixels
        oscillate through many nearly orthogonal basis vectors.
        This is precisely the effect positional encoding is designed to achieve: it gives the MLP access to very fine
        spatial detail by decorrelating local neighborhoods, at the expense of producing a tangled, highly folded
        manifold that is more challenging to visualize.
        Across the sweep, the PCA plots therefore illustrate a clear progression: low L preserves a simple, almost
        planar embedding; mid-range L produces a structured but still readable ribbon; and high L yields a volumetric,
        multi-sheet structure where the encoding has effectively sprinkled the image plane across a high-dimensional
        torus in feature space.
      </article>
    </section>

    <section id="varying_width" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Varying Widths</h1>
      </header>


      <article class="glass readable">
        Varying the hidden width changes the geometry of the learned feature space much more than it changes the raw
        positional-encoding manifold.
        The PCA plots of PE(u,v) look essentially identical for the narrow and wide models, since both networks receive
        the same sinusoidal expansion of the input image coordinates; the cloud of PE features remains a dense, roughly
        cubic volume whose principal components are strongly aligned with u and v and only weakly correlated with color.

        The difference emerges at the penultimate layer.
        With a smaller width, the PCA of the penultimate activations forms a relatively thick, fan-shaped cloud: the
        first
        principal component correlates strongly with luminance, but a large fraction of variance is still carried by the
        second component, and colors and spatial regions remain partially entangled.
        :contentReference[oaicite:1]{index=1}
        In contrast, increasing the width leads to a much more anisotropic embedding in feature space.
        The penultimate PCA collapses into a dominant one-dimensional arc that explains the majority of the variance,
        with
        most points lying along a smooth trajectory in PC1 while PC2 and PC3 only modulate local deviations.


      </article>

      <div class="pe-tabs">
        <!-- independent radio group for width -->
        <input type="radio" name="W" id="W64" checked>
        <input type="radio" name="W" id="W256">

        <div class="pe-panels" aria-live="polite">
          <!-- Width = 64 panel -->
          <div class="panel" data-w="W64">
            <figure class="pe-card">
              <img src="media/fox/L64_rgb.png" alt="L = 64, width = 64 – PCA of PE features (RGB)">
              <figcaption>PE • RGB (lr = 1e-2)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_uv.png" alt="L = 64, width = 64 – PCA of PE features (UV)">
              <figcaption>PE • UV (layer depth = 8)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_penult_pca3_rgb.png" alt="L = 64, width = 64 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB (iterations = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L = 64, width = 64">
              <div class="belt">
                <img src="media/fox/width/64/render_00000.png" alt="W = 64, iter 0">
                <img src="media/fox/width/64/render_00500.png" alt="W = 64, iter 500">
                <img src="media/fox/width/64/render_01000.png" alt="W = 64, iter 1000">
                <img src="media/fox/width/64/render_01500.png" alt="W = 64, iter 1500">
                <img src="media/fox/width/64/render_02000.png" alt="W = 64, iter 2000">
                <img src="media/fox/width/64/render_02500.png" alt="W = 64, iter 2500">
                <!-- loop for smooth belt -->
                <img src="media/fox/width/64/render_00000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_00500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_01500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_02000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/64/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>

          <!-- Width = 256 panel -->
          <div class="panel" data-w="W256">
            <figure class="pe-card">
              <img src="media/fox/L64_rgb.png" alt="L = 64, width = 256 – PCA of PE features (RGB)">
              <figcaption>PE • RGB (width = 256)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L64_uv.png" alt="L = 64, width = 256 – PCA of PE features (UV)">
              <figcaption>PE • UV (width = 256)</figcaption>
            </figure>
            <figure class="pe-card">
              <img src="media/fox/L256_penult_pca3_rgb.png"
                alt="L = 64, width = 256 – PCA of penultimate features (RGB)">
              <figcaption>Penultimate • RGB (width = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Renderings for L = 64, width = 256">
              <div class="belt">
                <img src="media/fox/width/256/render_00000.png" alt="W = 256, iter 0">
                <img src="media/fox/width/256/render_00500.png" alt="W = 256, iter 500">
                <img src="media/fox/width/256/render_01000.png" alt="W = 256, iter 1000">
                <img src="media/fox/width/256/render_01500.png" alt="W = 256, iter 1500">
                <img src="media/fox/width/256/render_02000.png" alt="W = 256, iter 2000">
                <img src="media/fox/width/256/render_02500.png" alt="W = 256, iter 2500">
                <!-- loop -->
                <img src="media/fox/width/256/render_00000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_00500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_01500.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_02000.png" alt="" aria-hidden="true">
                <img src="media/fox/width/256/render_02500.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>



        <div class="pe-tabbar" role="tablist" aria-label="Width">
          <label for="W64" role="tab">W = 64</label>
          <label for="W256" role="tab">W = 256</label>
        </div>
      </div>

      <article class="glass readable">
        Visually, this appears as a compact, curved sheet that peels away from the origin and then fades into a long,
        low-density tail.
        Pixels on the object and its immediate surroundings cluster tightly along one end of this arc, while background
        pixels and saturated regions occupy the extended tail, indicating that the wider network has learned a more
        organized representation where luminance and large-scale structure are encoded by a single dominant direction
        and
        finer variations are relegated to orthogonal subspaces.
        The PSNR curves reflect this difference: both widths reach similar overall reconstruction quality, but the wider
        model converges to slightly higher PSNR and exhibits a smoother, more monotonic improvement over training,
        consistent with its more structured internal feature manifold.
      </article>
    </section>

    <section id="final_result" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>Final Reconstruction on Chosen Scene</h1>
      </header>

      <article class="glass readable">
        The final Jupiter experiment can be interpreted by reading the PCA plots and PSNR curves together.
        The PCA of PE features (colored by UV) shows that the raw positional encodings still occupy a fairly regular
        three-sheet manifold in the top three principal components.
        The smooth transition from red to green across this structure indicates that the first principal components
        remain strongly aligned with the underlying latitude and longitude on the sphere, so even at higher frequency
        the encoding preserves a globally ordered map of spatial position.
        When the same PE features are colored by RGB instead of UV, the color pattern spreads almost uniformly through
        this volume, which confirms that the positional encoding itself does not yet reflect any semantic grouping by
        appearance; the geometry at this stage is dominated by coordinate-based oscillations rather than by the planet’s
        texture.
      </article>

      <!-- Three static panels: UV, RGB, penultimate (no belt, always visible) -->
      <div class="pe-panels pe-panels-final">
        <div class="panel">
          <figure class="pe-card">
            <img src="media/jupiter/L16_rgb.png" alt="PCA of PE features colored by UV">
            <figcaption>PE • UV (top three principal components)</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/jupiter/L16_uv.png" alt="PCA of PE features colored by RGB">
            <figcaption>PE • RGB (top three principal components)</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/jupiter/L16_penult_pca3_rgb.png" alt="PCA of penultimate features colored by RGB">
            <figcaption>Penultimate • RGB (learned feature geometry)</figcaption>
          </figure>
        </div>
      </div>

      <article class="glass readable">
        The PCA of the penultimate features tells a very different story.
        After passing through the MLP, the encoded points are no longer filling a symmetric three-sheet volume; instead,
        they collapse into a highly elongated plume concentrated near one side of PC space, with most variance lying
        along a single direction.
        Points corresponding to bright clouds, blue storms, and the dark background are separated along this main axis,
        while the secondary axes make only small corrections.
        This pattern indicates that the network has reorganized the high-dimensional PE basis into a much more compact,
        appearance-aligned representation in which luminance and large-scale color structure are encoded by one dominant
        feature dimension, and finer chromatic and textural differences are stored in orthogonal directions.
        In other words, the penultimate layer behaves like a learned color-space tailored to the Jupiter image rather
        than a direct reflection of the original (u,v) coordinates.
      </article>

      <!-- If you still want the final image + PSNR + belt, you can keep this or remove it -->
      <div class="pe-tabs">
        <input type="radio" name="R" id="RFINAL" checked>

        <div class="pe-panels" aria-live="polite">
          <div class="panel" data-r="RFINAL">
            <figure class="pe-card">
              <img src="media/jupiter/ground_truth.jpg" alt="Ground-truth image of the chosen scene">
              <figcaption>Ground-truth view (input photograph)</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/jupiter/psnr_curve_batch.png" alt="PSNR curve over training iterations">
              <figcaption>Batch PSNR over training iterations</figcaption>
            </figure>

            <figure class="pe-card">
              <img src="media/jupiter/progression/render_05000.png" alt="Final NeRF reconstruction of the chosen view">
              <figcaption>Final NeRF reconstruction (e.g., 5k iters, L = 16, width = 256)</figcaption>
            </figure>

            <div class="graph-belt" aria-label="Training progression for the chosen scene">
              <div class="belt">
                <img src="media/jupiter/progression/render_00000.png" alt="Iteration 0">
                <img src="media/jupiter/progression/render_01000.png" alt="Iteration 1000">
                <img src="media/jupiter/progression/render_02000.png" alt="Iteration 2000">
                <img src="media/jupiter/progression/render_03000.png" alt="Iteration 3000">
                <img src="media/jupiter/progression/render_04000.png" alt="Iteration 4000">
                <img src="media/jupiter/progression/render_05000.png" alt="Iteration 5000">
                <!-- loop copies for infinite scroll -->
                <img src="media/jupiter/progression/render_00000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_01000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_02000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_03000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_04000.png" alt="" aria-hidden="true">
                <img src="media/jupiter/progression/render_05000.png" alt="" aria-hidden="true">
              </div>
            </div>
          </div>
        </div>

        <div class="pe-tabbar" role="tablist" aria-label="Final result">
          <label for="RFINAL" role="tab">Final Result</label>
        </div>
      </div>

      <article class="glass readable">
        The PSNR curves quantify how quickly this representation emerges over training.
        The batch PSNR rises from single-digit values to around 20 dB within a few hundred iterations, reflecting rapid
        fitting of the global brightness and broad banding patterns.
        The full-image PSNR curve shows a large jump between the initial and first checkpoint renders, then a slower,
        almost linear increase that asymptotically approaches a mid-teens or low-twenties value by the end of training.
        The corresponding renderings match this trajectory: the very first output is nearly uniform, early snapshots
        show
        only faint hints of the dominant bands and storms, and later snapshots progressively sharpen the cloud belts,
        vortices, and color gradients until the final image closely resembles the ground truth while still smoothing the
        finest turbulent eddies.
        Taken together, the PCA plots and PSNR curves demonstrate that the model begins from a purely coordinate-driven
        encoding, then gradually learns an appearance-driven feature space and uses it to reconstruct both the coarse
        spherical structure and much of the intricate atmospheric detail of the original Jupiter photograph.
      </article>
    </section>

    <section id="pipeline" class="section alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line>NeRF Pipeline</h1>
      </header>

      <article class="glass readable">
        The first stage of the pipeline translates image pixels into rays in 3D space.
        For each training step, a batch of pixel locations is drawn from the current set of images.
        Instead of treating each pixel in isolation, the implementation works entirely in batches so that thousands of
        rays can be computed in one vectorized pass on the GPU.
        For every pixel, its horizontal and vertical coordinates are first shifted so that they are measured relative to
        the center of the image; this ensures that a pixel exactly in the middle of the frame produces a ray pointing
        straight through the optical axis rather than being biased by the top-left origin of image coordinates.
        These centered coordinates are then divided by the focal length to convert them into directions in the camera’s
        local coordinate system, following the standard pinhole-camera model in which the focal length controls the
        spread of rays.
        Each camera in the training set is described by a rigid transform from camera space to world space; for every
        ray in the batch, the implementation looks up the corresponding camera’s rotation and translation and uses them
        to rotate the local direction into the global reference frame while placing the ray’s origin at the camera
        center.
        Finally, all directions are normalized to unit length so that subsequent sampling along the ray can be expressed
        purely in terms of distances from the camera.
        The result of this stage is a batch of ray origins and matching direction vectors that describe exactly which 3D
        lines will be probed in the volume.
      </article>

      <!-- Rays: three-panel visualization (always visible, no belt) -->
      <div class="pe-panels pe-rays" aria-live="polite">
        <div class="panel">
          <figure class="pe-card">
            <img src="media/viser/all_rays.png" alt="All cameras in the scene with visualized frustums">
            <figcaption>All calibrated camera frustums around the Lego scene.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/ray1.png" alt="Rays cast from a single training camera">
            <figcaption>Random training rays emitted from one camera in world space.</figcaption>
          </figure>

          <figure class="pe-card">
            <img src="media/viser/ray2.png" alt="Sample locations along each ray">
            <figcaption>Stratified sample points along each ray, ready for NeRF evaluation.</figcaption>
          </figure>
        </div>
      </div>


      <article class="glass readable">
        Once the rays exist in world space, the next stage chooses where along each ray to query the neural field.
        The implementation uses a stratified scheme: it begins by placing a fixed number of sample depths between a near
        and a far bound that cover the region where the scene is expected to lie.
        Instead of always using the same depth values, each interval between two neighboring depths is randomly jittered
        on every training iteration.
        This produces slightly different sampling positions from step to step, which reduces aliasing artifacts and
        encourages the learned density field to be smooth rather than fitting to a rigid grid of points.
        For each ray, these scalar depths are then converted into 3D sample locations by adding the origin plus the
        direction vector scaled by each depth value.
        The outcome of this stage is a dense batch of points in space, all organized per ray, ready to be evaluated by
        the neural network.
      </article>

      <!-- Lego NeRF: three panels (PSNR + final train + final val) -->
      <div class="pe-panels pe-lego" aria-live="polite">
        <div class="panel">
          <!-- PSNR curve over training -->
          <figure class="pe-card">
            <img src="media/lego_scan/psnr_curve.png" alt="Lego scene: PSNR curve over training iterations">
            <figcaption>PSNR over training iterations (Lego 200×200)</figcaption>
          </figure>

          <!-- Final training view -->
          <figure class="pe-card">
            <img src="media/lego_scan/train_10000.png" alt="Lego scene: final NeRF reconstruction (training view)">
            <figcaption>Final NeRF reconstruction of a training view (iteration 10 000)</figcaption>
          </figure>

          <!-- Final validation view -->
          <figure class="pe-card">
            <img src="media/lego_scan/val_10000.png" alt="Lego scene: final NeRF reconstruction (validation view)">
            <figcaption>Final NeRF reconstruction of a held-out validation view</figcaption>
          </figure>
        </div>
      </div>

      <article class="glass readable">
        Feeding data into this process is handled by a streaming dataset tailored to NeRF’s requirements.
        When training begins, the dataset loader reads a compact file that contains the entire scene: a stack of RGB
        images, the corresponding camera-to-world transforms, and a shared focal length consistent with the resolution
        of those images.
        Rather than iterating over the images in a fixed order, the loader behaves like an infinite stream: each time
        the trainer asks for a new batch, it randomly chooses image indices and pixel coordinates, effectively sampling
        rays uniformly across all views and across the whole image plane.
        For every sampled triplet of (image index, horizontal pixel, vertical pixel), the loader immediately retrieves
        the true color at that pixel from the preloaded image tensor and retrieves the pose of the camera that observed
        it.
        It then passes these sampled image coordinates and camera transforms to the ray-generation stage, which produces
        the matching ray origins and directions.
        In this way, each training batch consists of a large set of randomly selected rays and their ground-truth RGB
        values, allowing the network to gradually see all viewpoints and all parts of the scene over the course of
        training without ever needing to materialize the entire ray bundle in memory at once.
      </article>

      <!-- Lego NeRF: stacked conveyor belts (train over validation) -->
      <div class="pe-panels pe-lego" aria-live="polite">
        <div class="panel">
          <div class="graph-belt lego-belt" aria-label="Lego reconstruction progression">
            <!-- Train progression -->
            <div class="belt">
              <img src="media/lego_scan/train_01000.png" alt="Training view, iteration 1 000">
              <img src="media/lego_scan/train_03000.png" alt="Training view, iteration 3 000">
              <img src="media/lego_scan/train_05000.png" alt="Training view, iteration 5 000">
              <img src="media/lego_scan/train_07000.png" alt="Training view, iteration 7 000">
              <img src="media/lego_scan/train_09000.png" alt="Training view, iteration 9 000">
              <img src="media/lego_scan/train_10000.png" alt="Training view, iteration 10 000">
              <!-- loop copies for continuous scroll -->
              <img src="media/lego_scan/train_01000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/train_03000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/train_05000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/train_07000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/train_09000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/train_10000.png" alt="" aria-hidden="true">
            </div>

            <!-- Validation progression -->
            <div class="belt">
              <img src="media/lego_scan/val_01000.png" alt="Validation view, iteration 1 000">
              <img src="media/lego_scan/val_03000.png" alt="Validation view, iteration 3 000">
              <img src="media/lego_scan/val_05000.png" alt="Validation view, iteration 5 000">
              <img src="media/lego_scan/val_07000.png" alt="Validation view, iteration 7 000">
              <img src="media/lego_scan/val_09000.png" alt="Validation view, iteration 9 000">
              <img src="media/lego_scan/val_10000.png" alt="Validation view, iteration 10 000">
              <!-- loop copies for continuous scroll -->
              <img src="media/lego_scan/val_01000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/val_03000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/val_05000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/val_07000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/val_09000.png" alt="" aria-hidden="true">
              <img src="media/lego_scan/val_10000.png" alt="" aria-hidden="true">
            </div>
          </div>
        </div>
      </div>

      <!-- Orbit GIF at the end -->
      <div class="center-media">
        <figure>
          <img src="media/lego_scan/lego.gif" alt="NeRF reconstruction orbit of the scene">
          <figcaption>NeRF orbit of the reconstructed scene (10k iterations), illustrating the full pipeline in motion.
          </figcaption>
        </figure>
      </div>
    </section>

    <section id="my_scene" class="section alt">
  <header class="section-header">
    <h1 class="serif" data-reveal-line>Training on My Own Dataset</h1>
  </header>

  <article class="glass readable">
    This experiment applies the same NeRF pipeline to a custom capture of a single object.
    The input consists of roughly 80 high-resolution RGB images taken on a hand-held camera, with the object placed on a
    table and the camera moved along a semi-circular path.
    The scene is calibrated once with a ChArUco board to recover a shared focal length and camera-to-world transforms,
    and the images are then undistorted and downscaled to 200×200 before being packed into an NPZ in the same format as
    the Lego example.
    Compared to the baseline configuration, the main hyperparameter changes are a slightly larger near/far range to
    cover the real-world scale of the object, a higher positional-encoding frequency (L = 16) to capture fine surface
    detail, and a longer training schedule (10 000 iterations) with a cosine learning-rate schedule that warms up over
    the first 500 steps and then decays from 5×10⁻⁴ to 5×10⁻⁶.
  </article>

  <!-- Three-panel summary: loss/PSNR, final training view, final validation view -->
  <div class="pe-panels pe-mydata" aria-live="polite">
    <div class="panel">
      <!-- Training loss / PSNR curve -->
      <figure class="pe-card">
        <img src="media/house/psnr_curve.png" alt="Custom scene: PSNR (or loss) curve over training iterations">
        <figcaption>Training loss / PSNR over iterations for the custom scene.</figcaption>
      </figure>

      <!-- Final training view -->
      <figure class="pe-card">
        <img src="media/house/train_05000.png" alt="Custom scene: final NeRF reconstruction from a training view">
        <figcaption>Final NeRF reconstruction of a training view (iteration 10 000).</figcaption>
      </figure>

      <!-- Final validation / novel view -->
      <figure class="pe-card">
        <img src="media/house/val_05000.png" alt="Custom scene: final NeRF reconstruction from a novel view">
        <figcaption>Final NeRF reconstruction of a held-out or novel view.</figcaption>
      </figure>
    </div>
  </div>

  <article class="glass readable">
    Several implementation details were adapted for this dataset.
    The near and far bounds were tuned to approximately [0.2 m, 2.0 m] based on the spread of the calibrated camera
    centers, which ensures that the sampling range fully covers the object and its supporting surface but does not waste
    samples far behind the scene.
    A cosine-annealed learning rate with a short warm-up improves stability compared to a fixed step size, especially
    in the early stages where the network must quickly learn a reasonable coarse shape from noisy gradients.
    In addition, a slightly longer training horizon (10 000 steps) and a moderate number of samples per ray (64) give
    the network enough capacity to capture small geometric features without exploding the compute budget.
  </article>

  <!-- Stacked belts: training and validation progression -->
  <div class="pe-panels pe-mydata" aria-live="polite">
    <div class="panel">
      <div class="graph-belt mydata-belt" aria-label="Custom scene reconstruction progression">
        <!-- Training progression -->
        <div class="belt">
          <img src="media/house/train_01000.png" alt="Training view, iteration 2 000">
          <img src="media/house/train_02000.png" alt="Training view, iteration 4 000">
          <img src="media/house/train_03000.png" alt="Training view, iteration 6 000">
          <img src="media/house/train_04000.png" alt="Training view, iteration 8 000">
          <img src="media/house/train_05000.png" alt="Training view, iteration 10 000">
          <!-- loop copies for smooth scroll -->
          <img src="media/house/train_01000.png" alt="" aria-hidden="true">
          <img src="media/house/train_02000.png" alt="" aria-hidden="true">
          <img src="media/house/train_03000.png" alt="" aria-hidden="true">
          <img src="media/house/train_04000.png" alt="" aria-hidden="true">
          <img src="media/house/train_05000.png" alt="" aria-hidden="true">
        </div>

        <!-- Validation / novel-view progression -->
        <div class="belt">
          <img src="media/house/val_01000.png" alt="Validation view, iteration 2 000">
          <img src="media/house/val_02000.png" alt="Validation view, iteration 4 000">
          <img src="media/house/val_03000.png" alt="Validation view, iteration 6 000">
          <img src="media/house/val_04000.png" alt="Validation view, iteration 8 000">
          <img src="media/house/val_05000.png" alt="Validation view, iteration 10 000">
          <!-- loop copies for smooth scroll -->
          <img src="media/house/val_01000.png" alt="" aria-hidden="true">
          <img src="media/house/val_02000.png" alt="" aria-hidden="true">
          <img src="media/house/val_03000.png" alt="" aria-hidden="true">
          <img src="media/house/val_04000.png" alt="" aria-hidden="true">
          <img src="media/house/val_05000.png" alt="" aria-hidden="true">
        </div>
      </div>
    </div>
  </div>

  <article class="glass readable">
    The stacked progression belts show how the reconstruction quality evolves across training.
    Early training outputs are heavily blurred and dominated by the global lighting and coarse silhouette of the object.
    As iterations increase, both the training and validation rows sharpen: major planar faces and edges become well
    aligned with the photographs, and the model begins to reproduce specular highlights and subtle shading variations.
    By the final iterations, the training views match the ground truth closely, while the validation views remain only
    slightly smoother, indicating that the network has learned a compact, generalizable representation of the scene
    rather than merely memorizing each input image.
  </article>

  <!-- Orbit GIF / video of novel views -->
  <div class="center-media">
    <figure>
      <img src="media/house/orbit.gif" alt="NeRF orbit of the custom scene">
      <figcaption>NeRF orbit of the custom scene, showing novel views synthesized from the trained model.</figcaption>
    </figure>
  </div>
</section>










    <!---------------------------------------- Part 2 Fit a Neural Radiance Field from Multi-view Images ----------------------------------------->
    <!-- <section id="nrl" class="section-alt">
      <header class="section-header">
        <h1 class="serif" data-reveal-line> Fitting Neural Radiance Field from Multi-view Images</h1>
      </header>
      <article glass data-reveal>
        <h2>
          Report your model architecture including number of layers, width, and learning rate. Feel free to add other
          details you think are important.
          Show training progression (images at different iterations, similar to the above reference) on both the
          provided test image and one of your own images.
          Show final results for 2 choices of max positional encoding frequency and 2 choices of width (a 2x2 grid of
          results). Try very low values for these hyperparameters to see how it affects the outputs.
          Show the PSNR curve for training on one image of your choice.
        </h2>
      </article>
    </section> -->


    <!-- END OF HTML -->
</body>

</html>