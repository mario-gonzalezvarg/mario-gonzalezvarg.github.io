<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Diffusion Models – Visualizations</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="../styles.css" />
</head>

<body class="top-title">

  <canvas id="sky" aria-hidden="true"></canvas>
  <header class="site-header">
    <div class="content">
      <nav class="top-nav" aria-label="Project navigation">
        <a href="../../index.html" class="nav-logo">
          Home
        </a>
      </nav>
    </div>
  </header>

  <div class="content big-title">
    <h1 class="title">Diffusion Models</h1>

    <div class="project-switcher" aria-label="Jump to project parts">
      <a href="../parta/proj5a.html" class="project-switcher__button project-switcher__button--primary">
        Part A
      </a>
      <a href="../partb/proj5b.html" class="project-switcher__button">
        Part B
      </a>
    </div>
  </div>

  <!--============================================= HuggingFace Interface Introduction ============================================ -->

  <section class="content gold-glass writing-section">
    <h2 class="section-heading">HuggingFace Model Interface</h2>
    <figure class="writing-section figure img">
      <img src="media/diagrams/pipeline.png" alt="High-level inference pipeline from raw text to predictions.">
    </figure>
    <p>
      The HuggingFace inference pipeline can be generalized as a sequence of clearly defined
      transformations. The process starts with <em>raw text</em>, a plain string such as “This course is
      amazing.” The <strong>tokenizer</strong> takes this string, splits it into subword units, and looks
      up each unit in a fixed vocabulary table. This step produces a sequence of integers called
      <em>input IDs</em>, which is the form the model can consume. The <strong>model</strong> then takes
      these input IDs and computes a real-valued score for each possible label; these scores are called
      <em>logits</em> and encode how compatible the text is with each class before any normalization.
      The final <strong>post-processing</strong> block converts logits into something usable: a softmax
      turns them into probabilities, and simple decision logic (such as taking the largest probability)
      chooses the predicted label, for example POSITIVE versus NEGATIVE sentiment.
    </p>
  </section>


  <section class="content gold-glass writing-section">
    <h2 class="section-heading">Transformer Architecture & DeepFloyd IF</h2>
    <p>
      The internal structure of the model can be decomposed into an embedding layer, a stack of
      transformer layers, and a classification head. First, an <strong>embedding layer</strong> maps each
      input ID to a dense vector that represents the token in a continuous space. A stack of
      <strong>transformer layers</strong> then processes the entire sequence: each layer applies
      self-attention, so every token can use information from every other token, followed by small
      feed-forward networks that refine these combined representations. After several such layers, the
      model extracts a single summary vector for the whole sequence (for example, by reading a special
      classification token or averaging all token vectors). A small <strong>classification head</strong>,
      typically one or two linear layers, takes this summary vector and produces the logits. These logits
      feed directly into the post-processing step from the first paragraph, completing the logical chain
      from raw text to final prediction.
    </p>

    <figure class="writing-section figure img">
      <img src="media/diagrams/transformer_and_head-dark.svg"
        alt="Transformer backbone and output head used in the HuggingFace model.">
    </figure>

    <p>
      DeepFloyd IF can be understood as coupling this text encoder to a three-stage cascaded diffusion
      model: a 64×64 base denoiser (stage 1) followed by two upsamplers that refine the image to higher
      resolutions (stages 2 and 3). For all experiments in this section, prompt embeddings produced by
      the transformer are used as conditioning signals at every denoising step, while the random seed is
      fixed to 12152000 so that differences in the outputs primarily reflect the prompts and sampling
      hyperparameters. Classifier-free guidance is applied with a relatively strong guidance scale in
      stage 1 (γ ≈ 9.0) and slightly lower guidance in the upsampling stages (γ ≈ 7.0), which stabilizes
      global structure while allowing the higher-resolution stages to sharpen details. This setup
      provides a controlled environment for the prompt-based images that follow, making it possible to
      interpret how changes in text descriptions translate into systematic changes in composition,
      lighting, and reflective structure.
    </p>
  </section>


  <!--============================================== 0 DeepFloyd Prompts =========================================================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows" aria-label="DeepFloyd prompts">
    <h2 class="section-heading">DeepFloyd Prompts</h2>

    <div class="iteration-belt__intro">
      <p>
        The prompt study evaluates how faithfully DeepFloyd IF translates
        language into images, rather than simply demonstrating that it can produce visually pleasing
        samples. A small bank of prompts is first encoded with the HuggingFace text encoder to obtain a
        fixed set of embeddings that are reused throughout the project. From this bank, several prompts
        are chosen as exemplars and are displayed side by side with their generated images, using a
        single random seed and multiple values of <em>num_inference_steps</em>.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">Pause</button>
    </div>

    <!-- Row 1: prompt outputs -->
    <div class="iteration-belt__row">
      <h4 class="iteration-belt__row-title">Prompt outputs</h4>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/lewis.png" alt="Lewis and Clark prompt output">
            <figcaption class="iteration-belt__caption">
              "a symbolist painting of Lewis and Clark reaching the Columbia River, soft edges"
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/market.png" alt="Crowded market prompt output">
            <figcaption class="iteration-belt__caption">
              "a baroque oil painting of a crowded market lit by torches and deep shadows"
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/mermaid.png" alt="Mermaid reflection prompt output">
            <figcaption class="iteration-belt__caption">
              "a romanticism oil painting of a mermaid seen only as a reflection in dark waves under moonlight"
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/glass_planes.png"
              alt="City square glass panes output">
            <figcaption class="iteration-belt__caption">
              "a renaissance-style painting of a city square reflected in many small glass panes"
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/hiroshima.png" alt="Hiroshima eye prompt output">
            <figcaption class="iteration-belt__caption">
              "an oil painting, close-up of a villager's eye with a distant mushroom cloud reflected in the iris"
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/windows.png" alt="Library windows prompt output">
            <figcaption class="iteration-belt__caption">
              "a realism painting of a library where each window opens onto a different sky"
            </figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 2: stage-1 num_inference_steps sweep -->
    <div class="iteration-belt__row">
      <h4 class="iteration-belt__row-title">Stage&nbsp;1 sampling steps</h4>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251206-233502.png"
              alt="Stage 1 sampling with 10 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 10 steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251205-020333.png"
              alt="Stage 1 sampling with 25 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 25 steps</figcaption>
          </figure>


          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251206-233653.png"
              alt="Stage 1 sampling with 75 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 75 steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251206-231738.png"
              alt="Stage 1 sampling with 100 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 100 steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251206-233954.png"
              alt="Stage 1 sampling with 100 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 125 steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/prompts/steps/20251206-232804.png"
              alt="Stage 1 sampling with 175 steps">
            <figcaption class="iteration-belt__caption">stage&nbsp;1: 175 steps</figcaption>
          </figure>
        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The first row shows that DeepFloyd IF consistently respects broad scene type and global
        composition: crowded interiors, reflective windows, and symbolic iris structures all align
        closely with their prompts, even when fine relational details are only partially enforced.
        The second row then isolates the effect of the number of sampling steps in the stage&nbsp;1
        base model. With only 10 steps, the iris image has roughly correct layout but incorrect anatomy of the eyelid
        and relatively coarse shading; at 25–50 steps, edges around the iris and eyelids sharpen and
        the reflected landscape stabilizes. Increasing to 75–125 steps yields smoother gradients and
        more precise highlights on the cornea, indicating that the sampler is projecting the sample
        closer to the natural image manifold. Around 150 steps there are only modest improvements, and
        once the step count is pushed beyond roughly 200, structure begins to break down: the iris and
        eyelids dissolve into over-textured patterns and, in the most extreme cases, stage&nbsp;1
        produces almost pure noise. At that point stages&nbsp;2 and&nbsp;3 simply upscale whatever is
        present, leading to hallucinated detail or noise at higher resolutions rather than recovering
        the intended eye.
      </p>
    </div>

  </section>


  <!-- ============================================ 1.1 Implementing the Forward Process =================================================  -->

  <section class="content gold-glass iteration-belt">
    <h2 class="section-heading">1.1 Forward Process</h2>
    <div class="iteration-belt__intro">
      <p>
        The forward diffusion process is implemented as a function <code>forward(im, t)</code> that maps a
        clean 64×64 Campanile image to a noisy version at timestep <code>t</code>. At each timestep, the
        function adds Gaussian noise with variance prescribed by the fixed noise schedule, so that larger
        values of <code>t</code> correspond to stronger corruption. This defines a monotonic path from the
        data distribution toward an isotropic Gaussian, which is the starting point for the reverse
        denoising process in later parts of the project.
      </p>
    </div>


    <div class="iteration-belt__header">
      <!-- <h3 class="iteration-belt__title">Renders</h3> -->
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">Pause</button>
    </div>

    <div class="iteration-belt__viewport">
      <h4 class="iteration-belt__row-title">Timesteps</h4>
      <div class="iteration-belt__track">
        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/forward_process/noisy_t_0.png"
            alt="Data visualization at iteration 0">
          <figcaption class="iteration-belt__caption">t = 0</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/forward_process/noisy_t_250.png"
            alt="Data visualization at iteration 250">
          <figcaption class="iteration-belt__caption">t = 250</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/forward_process/noisy_t_500.png"
            alt="Data visualization at iteration 500">
          <figcaption class="iteration-belt__caption">t = 500</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/forward_process/noisy_t_750.png"
            alt="Data visualization at iteration 750">
          <figcaption class="iteration-belt__caption">t = 750</figcaption>
        </figure>
      </div>
    </div>


    <div class="iteration-belt__outro">

      <p>
        To visualize this behavior, the Campanile is shown at several representative timesteps:
        <code>t = 0</code>, <code>250</code>, <code>500</code>, and <code>750</code>.
        At <code>t = 0</code>, the image is the original, noise-free photograph. By <code>t = 250</code>,
        moderate noise is visible, but the tower, trees, and sky remain clearly recognizable. At
        <code>t = 500</code>, the injected noise dominates fine detail: edges
        blur, colors fluctuate more erratically, and the Campanile is reduced to a faint silhouette. By
        <code>t = 750</code>, the sample is visually indistinguishable from pure noise, with only faint
        trace of the original structure.
      </p>
    </div>


  </section>

  <!-- ============================================ 1.2 Classical Denoising =============================================== -->
  <section class="content gold-glass iteration-belt">
    <h2 class="section-heading">1.2 Classical Denoising</h2>
    <div class="iteration-belt__intro">
      <p>
        Classical denoising here is instantiated by a simple Gaussian blur applied directly to the noisy
        Campanile images from the forward process. For each noise level (t = 0, 250, 500, 750), the noisy
        image is filtered with a fixed-radius Gaussian kernel, which suppresses high-frequency variations
        but does not use any knowledge of the underlying data distribution. This produces a purely
        low-pass baseline that can be compared against the diffusion-based denoisers in later parts of the
        project.
      </p>

    </div>


    <div class="iteration-belt__header">
      <!-- <h3 class="iteration-belt__title">Renders</h3> -->
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">Pause</button>
    </div>


    <div class="iteration-belt__viewport">
      <h4 class="iteration-belt__row-title">Timesteps</h4>
      <div class="iteration-belt__track">
        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/classical_denoising/noisy_t_0.png" alt="Noisy image t = 0">
          <figcaption class="iteration-belt__caption">t = 0</figcaption>
        </figure>


        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/classical_denoising/noisy_t_250.png" alt="Noisy image t = 250">
          <figcaption class="iteration-belt__caption">t = 250</figcaption>
        </figure>


        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/classical_denoising/noisy_t_500.png" alt="Noisy image t = 500">
          <figcaption class="iteration-belt__caption">t = 500</figcaption>
        </figure>


        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/classical_denoising/noisy_t_750.png" alt="Noisy image t = 750">
          <figcaption class="iteration-belt__caption">t = 750</figcaption>
        </figure>


      </div>
    </div>


    <div class="iteration-belt__outro">
      <p>
        The sequence of results highlights both the strengths and limitations of this approach. At low
        noise levels (t = 0 and t = 250), Gaussian denoising successfully reduces speckle in the sky and
        façade while preserving the overall silhouette of the tower and trees, although fine edges become
        noticeably softened. At higher noise levels (t = 500 and especially t = 750), the blur removes some
        of the colorful grain but also smears out important structure, leaving a hazy, almost watercolor
        version of the scene in which architectural details and tree textures are largely lost. This
        behavior illustrates why classical smoothing is a useful but ultimately insufficient baseline:
        it can attenuate noise, but without a learned prior it cannot reconstruct missing high-frequency
        detail once the forward process has heavily corrupted the image.
      </p>
    </div>


  </section>

  <!-- ============================================ 1.3 One-Step Denoising =============================================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows"
    aria-label="One-step denoising comparison">
    <h2 class="section-heading">1.3 One-Step Denoising</h2>

    <div class="iteration-belt__intro">
      <p>
        One-step denoising evaluates how much structure can be recovered from a noisy observation using
        a single reverse diffusion step. For each timestep <em>t</em> in {250, 500, 750}, the forward
        process is first used to corrupt the clean 64×64 Campanile image and obtain a noisy input. This
        noisy image is then passed through <code>stage_1.unet</code> to estimate the noise component,
        and a one-step reconstruction is formed by subtracting the predicted noise from the noisy input.
        The resulting estimate can be compared directly against the original image and the noisy
        observation to assess how well a single denoising step in the learned model inverts the forward
        process at different noise levels.
      </p>
    </div>

    <div class="iteration-belt__header">
      <!-- optional small title; can be commented out if you prefer only the Pause button -->
      <!-- <h3 class="iteration-belt__title">One-Step Denoising (Noisy vs Estimation)</h3> -->
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <!-- Row 1: noisy inputs -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Noisy input</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">
          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/noisy_t_0.png" alt="Noisy image at t = 0">
            <figcaption class="iteration-belt__caption">t = 0</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/noisy_t_250.png" alt="Noisy image at t = 250">
            <figcaption class="iteration-belt__caption">t = 250</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/noisy_t_500.png" alt="Noisy image at t = 500">
            <figcaption class="iteration-belt__caption">t = 500</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/noisy_t_750.png" alt="Noisy image at t = 750">
            <figcaption class="iteration-belt__caption">t = 750</figcaption>
          </figure>
        </div>
      </div>
    </div>

    <!-- Row 2: one-step denoised estimates -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">One-step denoised estimate</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">
          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/denoised_t_0.png"
              alt="One-step denoised image at t = 0">
            <figcaption class="iteration-belt__caption">t = 0</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/denoised_t_250.png"
              alt="One-step denoised image at t = 250">
            <figcaption class="iteration-belt__caption">t = 250</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/denoised_t_500.png"
              alt="One-step denoised image at t = 500">
            <figcaption class="iteration-belt__caption">t = 500</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/denoised_t_750.png"
              alt="One-step denoised image at t = 750">
            <figcaption class="iteration-belt__caption">t = 750</figcaption>
          </figure>
        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        As the noise level increases, the one-step reconstructions retain the coarse outline of the
        Campanile but lose fine detail and contrast, highlighting the limitations of a single reverse
        step and motivating the iterative denoising scheme developed in the next section.
      </p>
    </div>
  </section>


  <!-- ============================================ 1.4 Iterative Denoising =============================================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows"
    aria-label="Iterative denoising comparison">
    <h2 class="section-heading">1.4 Iterative Denoising</h2>

    <div class="iteration-belt__intro">
      <p>
        Iterative denoising generalizes the one-step procedure by applying the learned noise predictor
        across a full schedule of reverse diffusion steps. Starting from a heavily noised Campanile
        image at an initial index <code>i_start = 10</code>, a strided list of timesteps is constructed
        (from 990 down to 0 in steps of 30), and at each timestep the UNet estimates the noise and
        performs a small update toward the clean image. This produces a sequence of intermediate
        reconstructions that progressively recover large-scale structure and fine detail, rather than
        attempting to undo all of the corruption in a single jump.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <!-- Row 1: iterative denoising trajectory (GIFs every few steps) -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Iterative denoising trajectory</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start1.gif"
              alt="Iterative denoising from early timestep">
            <figcaption class="iteration-belt__caption">early steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start3.gif"
              alt="Iterative denoising after several updates">
            <figcaption class="iteration-belt__caption">midway (1)</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start5.gif"
              alt="Iterative denoising after more updates">
            <figcaption class="iteration-belt__caption">midway (2)</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start7.gif"
              alt="Iterative denoising near the end of the schedule">
            <figcaption class="iteration-belt__caption">late steps</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start10.gif"
              alt="Iterative denoising with more aggressive schedule">
            <figcaption class="iteration-belt__caption">aggressive schedule</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 2: final reconstructions compared -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Final reconstructions</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/orig.png" alt="Original image">
            <figcaption class="iteration-belt__caption">Original Campanile</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/iterative_denoising/i_start20.png"
              alt="Iterative denoised Campanile">
            <figcaption class="iteration-belt__caption">Iterative denoising</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/one_step/denoised_t_500.png"
              alt="One-step denoised Campanile">
            <figcaption class="iteration-belt__caption">One-step denoising</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/classical_denoising/gauss_t_500.png"
              alt="Gaussian blurred Campanile">
            <figcaption class="iteration-belt__caption">Gaussian baseline</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The GIFs in the first row show the Campanile image gradually emerging from near-pure noise:
        early frames retain little structure, mid-sequence frames recover the tower silhouette and sky
        gradient, and late frames sharpen edges and contrast. The second row compares the final
        iterative reconstruction against the original image, the one-step estimate, and the classical
        Gaussian baseline. Iterative denoising produces the closest match to the original: the tower
        and trees are well defined and textures are plausibly restored. The one-step estimate recovers
        only coarse shape and remains noticeably washed out, while the Gaussian result is over-smoothed
        and lacks architectural detail. It's evident that repeatedly applying the learned reverse step along
        a carefully chosen schedule is essential for high-quality reconstructions in diffusion models.
      </p>
    </div>
  </section>


  <!-- ============================================ 1.5 Diffusion Model Sampling =============================================== -->
  <section class="content gold-glass iteration-belt" aria-label="Diffusion model sampling">
    <h2 class="section-heading">1.5 Diffusion Model Sampling</h2>

    <div class="iteration-belt__intro">
      <p>
        Diffusion model sampling reverses the forward corruption process by starting from pure Gaussian
        noise and applying the learned denoising model along the full schedule of timesteps. For this
        part, the stage&nbsp;1 sampler is run five times with different random seeds
        (32168, 100570, 91798, 1215, 122607). Each run draws an independent noise image at the final
        timestep and then traverses the entire reverse chain, producing one synthesized 64×64 image per
        seed. Model weights, scheduler settings, and all hyperparameters are held fixed; only the
        initial noise realization changes.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Samples at timestep t = 0</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <!-- 5 sampled images -->
          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/diffusion_model_sampling/sample_32168.png"
              alt="Sampled landscape with flowers and a pier at sunrise">
            <figcaption class="iteration-belt__caption">
              Seed 32168
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/diffusion_model_sampling/sample_100570.png"
              alt="Grid of architectural and landscape thumbnails">
            <figcaption class="iteration-belt__caption">
              Seed 100570
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/diffusion_model_sampling/sample_91798.png"
              alt="Portrait of a person looking up in a storm of particles">
            <figcaption class="iteration-belt__caption">
              Seed 91798
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/diffusion_model_sampling/sample_1215.png"
              alt="Monochrome cityscape partially obscured by smoke">
            <figcaption class="iteration-belt__caption">
              Seed 1215
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/diffusion_model_sampling/sample_122607.png"
              alt="Figure walking along pastel rock formations at sunset">
            <figcaption class="iteration-belt__caption">
              Seed 122607
            </figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The five samples exhibit diverse scene types and compositions, ranging from landscapes
        to portraits despite being generated by the same model and schedule. This diversity arises solely from the
        different
        random seeds, which determine the initial noise pattern at the start of the reverse process.
        At the same time, all images share consistent photographic qualities such as coherent lighting,
        natural textures, and plausible perspective, indicating that the model has learned a strong
        prior over natural images rather than memorizing individual examples.
      </p>
    </div>
  </section>


  <!-- ============================================ 1.6 Classifier-Free Guidance (CFG) =============================================== -->
  <section class="content gold-glass iteration-belt" aria-label="CFG diffusion sampling">
    <h2 class="section-heading">1.6 Classifier-Free Guidance (CFG)</h2>

    <div class="iteration-belt__intro">
      <p>
        Classifier-free guidance modifies the sampling process by interpolating between unconditional
        and text-conditioned predictions from the UNet. At each reverse step, the model is run twice:
        once with the prompt dropped (unconditional) and once with the prompt “a high quality photo.”
        The final noise estimate is obtained by adding a scaled difference between these two outputs,
        controlled by a guidance scale <em>w</em>. Small values of <em>w</em> keep the samples close to
        the unconditional image distribution and emphasize diversity, whereas large values force the
        generation to adhere more strongly to the prompt, at the risk of oversharpening or introducing
        artifacts. In this section, five images are generated with a fixed random seed and guidance
        scales {2, 4, 5, 6, 8}.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Samples with varying CFG scales</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/cfg/s2.png" alt="Soft portrait sampled with low CFG scale">
            <figcaption class="iteration-belt__caption">
              CFG scale 2 – soft, low-contrast portrait
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/cfg/s4.png" alt="Landscape at dusk with strong reflections">
            <figcaption class="iteration-belt__caption">
              CFG scale 4 – high-contrast landscape at dusk
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/cfg/s5.png" alt="Close-up portrait with vivid colors">
            <figcaption class="iteration-belt__caption">
              CFG scale 5 – more defined monochrome portrait

            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/cfg/s6.png"
              alt="Monochrome portrait with stronger definition">
            <figcaption class="iteration-belt__caption">
              CFG scale 6 – vivid close-up portrait
            </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/cfg/s8.png">
            <figcaption class="iteration-belt__caption">
              CFG scale 8 – very sharp, strongly conditioned portrait
            </figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        As the CFG scale increases, the samples move from soft, low-contrast renderings toward images
        with sharper edges, stronger color saturation. At low guidance
        (e.g., scale 2), the model behaves similarly to the unconditional sampler: compositions are
        plausible but loosely tied to the prompt. Intermediate scales (around 4–6) balance fidelity and
        realism, producing images that read clearly as high-quality photographs without obvious
        artifacts. At the highest scale (8), the model adheres very strongly to the prompt, which
        enhances detail but can also exaggerate contrast and make textures look slightly artificial.
        This progression illustrates the core trade-off of classifier-free guidance: stronger guidance
        improves prompt alignment but gradually reduces diversity and can push samples away from the
        natural image manifold if set too high.
      </p>
    </div>
  </section>


  <!-- ============================================ 1.7 Image-to-image Translation (SDEdit) ===================================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows"
    aria-label="Image-to-image translation with SDEdit">
    <h2 class="section-heading">1.7 Image-to-image Translation (SDEdit)</h2>

    <div class="iteration-belt__intro">
      <p>
        Image-to-image translation in this part is implemented using the SDEdit procedure. Instead of
        sampling from pure noise, the algorithm begins from a real 64×64 photograph of the Campanile,
        runs the forward diffusion process up to a chosen noise index <em>i_start</em>, and then applies
        the usual reverse sampler conditioned on the prompt “a high quality photo.” For small values of
        <em>i_start</em>, the starting point is only mildly corrupted and the sampler behaves like a
        noise-removal-and-retouch operator; larger values push the image closer to pure noise before
        denoising, giving the model more freedom to reinterpret the scene while still being guided by
        the original structure.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <!-- Row 1: Campanile SDEdit -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Campanile: noise level sweep</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start1.gif" alt="Campanile SDEdit i_start = 1">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start3.gif" alt="Campanile SDEdit i_start = 3">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start5.gif" alt="Campanile SDEdit i_start = 5">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start7.gif" alt="Campanile SDEdit i_start = 7">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start10.gif" alt="Campanile SDEdit i_start = 10">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/i_start20.gif" alt="Campanile SDEdit i_start = 20">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/orig.png" alt="Original Campanile">
            <figcaption class="iteration-belt__caption">Original input</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 2: Glass Art example -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Glass Art: Chihuly-style sculpture</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start1.gif"
              alt="Glass sculpture SDEdit i_start = 1">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start3.gif"
              alt="Glass sculpture SDEdit i_start = 3">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start5.gif"
              alt="Glass sculpture SDEdit i_start = 5">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start7.gif"
              alt="Glass sculpture SDEdit i_start = 7">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start10.gif"
              alt="Glass sculpture SDEdit i_start = 10">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/i_start20.gif"
              alt="Glass sculpture SDEdit i_start = 20">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/a/orig.png" alt="Original glass sculpture">
            <figcaption class="iteration-belt__caption">Original input</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 3: Space Needle example -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">More Glass Art!!</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start1.gif" alt="Space Needle SDEdit i_start = 1">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start3.gif" alt="Space Needle SDEdit i_start = 3">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start5.gif" alt="Space Needle SDEdit i_start = 5">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start7.gif" alt="Space Needle SDEdit i_start = 7">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start10.gif"
              alt="Space Needle SDEdit i_start = 10">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/i_start20.gif"
              alt="Space Needle SDEdit i_start = 20">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/SDEdit/b/orig.png" alt="Original Space Needle photograph">
            <figcaption class="iteration-belt__caption">Original input</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        Across all three examples, the SDEdit trajectory shows a consistent pattern. For the Campanile,
        low noise levels preserve the tower and horizion line almost exactly, while higher levels introduce
        softer clouds, altered color grading, and occasionally new structural details. My first personal image is of a
        glass
        sculpture which begins as a dense cluster of orange spikes and, under increasing noise, is redrawn
        as more diffuse, branching forms that still respect the radial “explosion” motif but explore
        new lighting and background colors. The thrid sequence similarly moves from a faithful
        reconstruction of the original scultupre to more stylized versions where the artwwork, colors, and background
        are exaggerated or partially reimagined as flowers and landscapes. And so, SDEdit can either gently refine an
        existing photograph or drive it toward a more creative,
        prompt-driven reinterpretation, depending on how far along the forward diffusion trajectory
        the sampler chooses to re-enter.
      </p>
    </div>
  </section>

  <!-- ============================================ 1.7.1 Editing Web and Hand-Drawn Images ===================================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows"
    aria-label="Editing web and hand-drawn images with SDEdit">
    <h2 class="section-heading">1.7.1 Editing Web and Hand-Drawn Images</h2>
    <div class="iteration-belt__intro">
      <p>
        This section tests SDEdit on images that originate from outside sources varying the initial starting step. For
        each input, the forward process is run to noise levels <em>i_start</em> ∈ {1, 3, 5, 7, 10, 20},
        and the reverse sampler is then applied under the prompt “a high quality photo.” At low noise
        levels, the procedure behaves like a local enhancement operator that cleans and stylizes the
        input while preserving its structure; at high noise levels, the model is forced to hallucinate
        more content from its learned prior while still being anchored by the original image.
      </p>
      <p>
        One special image is the viral photograph of “The Dress,” perceived by some as white and gold (me)
        and by others as blue and black (surely lies). The other two inputs are hand-drawn doodles.
        The Dress row probes how the model resolves ambiguous
        illumination and just like us, the sampler flips between “warm background, white dress”
        and “cool background, blue dress,” and its choice depends on how much noise we inject before
        denoising.
      </p>
    </div>

    <!-- 
    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div> -->

    <!-- Row 1: Web image dress -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Web image: “The Dress” color illusion</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/dress.jpg"
              alt="Rescaled 64×64 Crab Nebula input image">
            <figcaption class="iteration-belt__caption">Input Image </figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start1.gif"
              alt="Crab Nebula SDEdit i_start = 1">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start3.gif"
              alt="Crab Nebula SDEdit i_start = 3">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start5.gif"
              alt="Crab Nebula SDEdit i_start = 5">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start7.gif"
              alt="Crab Nebula SDEdit i_start = 7">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start10.gif"
              alt="Crab Nebula SDEdit i_start = 10">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/hand_web/web/i_start20.gif"
              alt="Crab Nebula SDEdit i_start = 20">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        For The Dress, low <em>i_start</em> values mostly clean compression artifacts and keep a warm cast,
        so the dress reads as white–gold. As the noise level increases and the corrupted input loses
        reliable color cues, the reconstructions flip between warmer yellowish versions and cooler
        blue-toned ones. In the region where the dress itself lives, the sequence gradually leans toward a
        blue-and-black interpretation, while the background drifts toward brighter white and gold. This
        mirrors one popular explanation of the illusion!!!! Different assumptions about scene lighting lead to
        two equally stable color stories, and different re-entry points into the reverse diffusion chain
        simply pick different stories.
      </p>


      <div class="iteration-belt__header">
        <button type="button" class="iteration-belt__toggle" aria-pressed="false">
          Pause
        </button>
      </div>

      <!-- Row 2: Doodle 1 – The Blue Bandit seed = 20171341215, gamma = 11.0 -->
      <div class="iteration-belt__row">
        <h3 class="iteration-belt__row-title">Doodle 1: The Blue Bandit</h3>
        <div class="iteration-belt__viewport">
          <div class="iteration-belt__track">

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/orig.png"
                alt="Hand-drawn Blue Bandit input">
              <figcaption class="iteration-belt__caption">Rescaled input (64×64)</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start1.gif"
                alt="Blue Bandit SDEdit i_start = 1">
              <figcaption class="iteration-belt__caption">noise level 1</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start3.gif"
                alt="Blue Bandit SDEdit i_start = 3">
              <figcaption class="iteration-belt__caption">noise level 3</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start5.gif"
                alt="Blue Bandit SDEdit i_start = 5">
              <figcaption class="iteration-belt__caption">noise level 5</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start7.gif"
                alt="Blue Bandit SDEdit i_start = 7">
              <figcaption class="iteration-belt__caption">noise level 7</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start10.gif"
                alt="Blue Bandit SDEdit i_start = 10">
              <figcaption class="iteration-belt__caption">noise level 10</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle1/i_start20.gif"
                alt="Blue Bandit SDEdit i_start = 20">
              <figcaption class="iteration-belt__caption">noise level 20</figcaption>
            </figure>

          </div>
        </div>
      </div>

      <div class="iteration-belt__outro">
        <p>
          The doodles show the same mechanism at work when the geometry is also ambiguous. For The Blue
          Bandit, small <em>i_start</em> values keep the rough mask outline and pose while turning marker
          strokes into smooth skin, hair, and background shading; larger values redraw the figure with more
          realistic proportions and textures that still follow the original silhouette.</p>
      </div>

      <!-- Row 3: Doodle 2 – The Little Prince seed = 12152000, gamma = 9.0-->
      <div class="iteration-belt__row">
        <h3 class="iteration-belt__row-title">Doodle 2: Last Sunset</h3>
        <div class="iteration-belt__viewport">
          <div class="iteration-belt__track">

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/orig.jpg"
                alt="Hand-drawn Little Prince input">
              <figcaption class="iteration-belt__caption">Rescaled input (64×64)</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start1.gif"
                alt="Little Prince SDEdit i_start = 1">
              <figcaption class="iteration-belt__caption">noise level 1</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start3.gif"
                alt="Little Prince SDEdit i_start = 3">
              <figcaption class="iteration-belt__caption">noise level 3</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start5.gif"
                alt="Little Prince SDEdit i_start = 5">
              <figcaption class="iteration-belt__caption">noise level 5</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start7.gif"
                alt="Little Prince SDEdit i_start = 7">
              <figcaption class="iteration-belt__caption">noise level 7</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start10.gif"
                alt="Little Prince SDEdit i_start = 10">
              <figcaption class="iteration-belt__caption">noise level 10</figcaption>
            </figure>

            <figure class="iteration-belt__item">
              <img class="iteration-belt__image" src="media/hand_web/doodle2/i_start20.gif"
                alt="Little Prince SDEdit i_start = 20">
              <figcaption class="iteration-belt__caption">noise level 20</figcaption>
            </figure>

          </div>
        </div>
      </div>


      <div class="iteration-belt__outro">
        <p>
          In the last sketch, the
          horizontal bar and bright disk are repeatedly reused but assigned new semantic roles: a bench and
          two people at low noise, then a surfer on a wave, snow-covered rocks at sunrise, and finally a
          tightly cropped view of a striped dress. One trajectory even passes through a flat yellow sign that
          literally reads “HIGH QUALITY PHOTO,” because the sampler is conditioned on that exact phrase, and
          drawing the words is one very literal way to satisfy it. As <em>i_start</em> increases, control
          shifts from the original pixels to the model’s natural-image prior, so the edits move from cleaned-up
          versions of the inputs to qualitatively new photographs that only loosely preserve the original
          layout and color scheme.
        </p>
      </div>
  </section>


  <!-- ==================================================== 1.7.2 Inpainting ====================================================== -->
  <section class="content gold-glass iteration-belt" aria-label="Inpainting the Campanile">
    <h2 class="section-heading">1.7.2 Inpainting</h2>

    <div class="iteration-belt__intro">
      <p>
        Inpainting focuses on editing only a specified region of the image while preserving the
        surrounding context. The 64×64 Campanile photograph is paired with a binary mask that marks
        the section of the tower to be regenerated. Inside the mask, the image is diffused forward to
        noise levels <em>i_start</em> ∈ {1, 2, 3, 4, 5, 7}, while pixels outside the mask remain fixed.
        The reverse sampler, conditioned on “a high quality photo,” then reconstructs the masked region
        so that it blends seamlessly with the unchanged background. The images below show the input,
        mask, and inpainting trajectories for different noise entry points.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <div class="iteration-belt__viewport">
      <h3 class="iteration-belt__row-title">Inpainting at different noise levels</h3>
      <div class="iteration-belt__track">

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/orig.png" alt="Original Campanile image">
          <figcaption class="iteration-belt__caption">Original input</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/camp_double_mask.png"
            alt="Binary inpainting mask over the Campanile">
          <figcaption class="iteration-belt__caption">Mask (edited region)</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start1.gif"
            alt="Inpainting trajectory with i_start = 1">
          <figcaption class="iteration-belt__caption">noise level 1</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start2.gif"
            alt="Inpainting trajectory with i_start = 2">
          <figcaption class="iteration-belt__caption">noise level 2</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start3.gif"
            alt="Inpainting trajectory with i_start = 3">
          <figcaption class="iteration-belt__caption">noise level 3</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start4.gif"
            alt="Inpainting trajectory with i_start = 4">
          <figcaption class="iteration-belt__caption">noise level 4</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start5.gif"
            alt="Inpainting trajectory with i_start = 5">
          <figcaption class="iteration-belt__caption">noise level 5</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/i_start7.gif"
            alt="Inpainting trajectory with i_start = 7">
          <figcaption class="iteration-belt__caption">noise level 7</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpainting/campanile/inpaint_final.png"
            alt="Final inpainted Campanile image">
          <figcaption class="iteration-belt__caption">Final inpainted result</figcaption>
        </figure>

      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The original image and mask at the beginning of the belt clarify which portion of the tower is
        being regenerated. For the lowest noise levels, the inpainted region remains very close to the
        original structure: the tower edges align across the mask boundary, and only subtle texture and
        lighting changes appear. As <em>i_start</em> increases, the tower interior and base are redrawn
        with more variation, and the model begins to hallucinate new details while still matching the
        surrounding sky and trees in color and shading.
      </p>
    </div>


    <div class="iteration-belt__viewport">
      <h3 class="iteration-belt__row-title">Inpainting at different noise levels</h3>
      <div class="iteration-belt__track">

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/orig.jpg">
          <figcaption class="iteration-belt__caption">Original input</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/mask.png"
            alt="Binary inpainting mask over the Campanile">
          <figcaption class="iteration-belt__caption">Mask</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/i_start1.gif"
            alt="Inpainting trajectory with i_start = 1">
          <figcaption class="iteration-belt__caption">noise level 1</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/i_start2.gif"
            alt="Inpainting trajectory with i_start = 2">
          <figcaption class="iteration-belt__caption">noise level 2</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/i_start3.gif"
            alt="Inpainting trajectory with i_start = 3">
          <figcaption class="iteration-belt__caption">noise level 3</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/i_start4.gif"
            alt="Inpainting trajectory with i_start = 4">
          <figcaption class="iteration-belt__caption">noise level 4</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/a/i_start5.gif"
            alt="Inpainting trajectory with i_start = 5">
          <figcaption class="iteration-belt__caption">noise level 5</figcaption>
        </figure>

      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The end result demonstrates that
        the diffusion model can fill in a missing region with a plausible, high-quality reconstruction
        that respects both the global geometry of the scene and the local context provided by the
        unmasked pixels.
      </p>
    </div>

    <div class="iteration-belt__viewport">
      <h3 class="iteration-belt__row-title">Inpainting at different noise levels</h3>
      <div class="iteration-belt__track">

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/orig.jpg">
          <figcaption class="iteration-belt__caption">Original input</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/mask.png"
            alt="Binary inpainting mask over the Campanile">
          <figcaption class="iteration-belt__caption">Mask</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/i_start1.gif"
            alt="Inpainting trajectory with i_start = 1">
          <figcaption class="iteration-belt__caption">noise level 1</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/i_start2.gif"
            alt="Inpainting trajectory with i_start = 2 SEED = 20171341215">
          <figcaption class="iteration-belt__caption">noise level 2</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/i_start3.gif" alt="SEED = 1005197012152000">
          <figcaption class="iteration-belt__caption">noise level 3</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/i_start4.gif"
            alt="Inpainting trajectory with i_start = 4">
          <figcaption class="iteration-belt__caption">noise level 4</figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/inpaint/b/i_start5.gif"
            alt="Inpainting trajectory with i_start = 5">
          <figcaption class="iteration-belt__caption">noise level 5</figcaption>
        </figure>
      </div>
    </div>
  </section>


  <!-- ==================================================== 1.7.3 Text-Conditional Image-to-image Translation ===================== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows"
    aria-label="Text-conditional image-to-image translation">
    <h2 class="section-heading">1.7.3 Text-Conditional Image-to-image Translation</h2>

    <div class="iteration-belt__intro">
      <p>
        This part extends SDEdit by replacing the generic prompt “a high quality photo” with richer
        text descriptions. For each input image, the forward process is run to noise levels
        <em>i_start</em> ∈ {1, 3, 5, 7, 10, 20}, and the reverse sampler is guided by a specific prompt.
        The Campanile image is edited with the prompt “a rocketship launching into space,” while two
        additional images are edited with Renaissance-style prompts: “a Renaissance painting of a
        knight and a dragon” and “a Renaissance painting of a celestial choir of angels.”
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <!-- Row 1: Campanile with rocketship prompt -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">
        Campanile – prompt: “a rocketship launching into space”
      </h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/inpainting/campanile/orig.png"
              alt="Original Campanile image for text-conditional editing">
            <figcaption class="iteration-belt__caption">Original input (64×64)</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start1.gif">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start3.gif">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start5.gif">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start7.gif">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start10.gif">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/campanile/i_start20.gif">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 2: Web / photo image – knight and dragon prompt -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">
        Prompt: “a Renaissance painting of a knight and a dragon”
      </h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/orig.jpg"
              alt="Original image for knight and dragon prompt">
            <figcaption class="iteration-belt__caption">Original input (64×64)</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start1.gif">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start3.gif">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start5.gif">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start7.gif">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start10.gif">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>


          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/a/i_start20.gif">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 3: Web / photo image – celestial choir prompt -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">
        Prompt: “a Renaissance painting of a celestial choir of angels”
      </h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/orig.jpg"
              alt="Original image for celestial choir prompt">
            <figcaption class="iteration-belt__caption">Original input (64×64)</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start1.gif">
            <figcaption class="iteration-belt__caption">noise level 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start3.gif">
            <figcaption class="iteration-belt__caption">noise level 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start5.gif">
            <figcaption class="iteration-belt__caption">noise level 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start7.gif">
            <figcaption class="iteration-belt__caption">noise level 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start10.gif">
            <figcaption class="iteration-belt__caption">noise level 10</figcaption>
          </figure>

          <!-- <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start17.gif">
            <figcaption class="iteration-belt__caption">noise level 17</figcaption>
          </figure> -->

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/txtCond_img2img/b/i_start20.gif">
            <figcaption class="iteration-belt__caption">noise level 20</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        Increasing the noise level before denoising systematically trades fidelity to the original pixels
        for stronger alignment with the text prompt. For the Campanile, low noise levels simply add
        rocket-like exhaust and faint sky streaks to the existing tower, while higher levels let the model
        bend the silhouette and sky into a clear launch scene. Under the knight-and-dragon prompt, fine
        photographic detail is gradually overwritten by painterly armor, banners, and dragon forms, until
        at the highest noise levels the image reads almost entirely as a Renaissance illustration. The
        celestial-choir prompt shows a similar pattern: mild noise yields subtle halos and robes layered
        over the original figures, whereas strong noise produces densely populated, golden-toned scenes
        with increasingly distorted anatomy. Varying the noise-level parameter thus allows SDEdit to
        interpolate between gentle stylistic editing and full semantic reinterpretation while remaining
        anchored to the structure implied by the prompts.
      </p>
    </div>
  </section>

  <!-- ==================================================== 1.8 Visual Anagrams ====================================================== -->
  <section class="content gold-glass iteration-belt" aria-label="Visual anagrams with diffusion models">
    <h2 class="section-heading">1.8 Visual Anagrams</h2>

    <div class="iteration-belt__intro">
      <p>
        Visual anagrams are constructed by coupling the diffusion model with two different text prompts
        and a 180° flip operation. The procedure starts from a noisy 64×64 image and alternates between
        two denoising passes: one conditioned on the “upright” prompt and one conditioned on the
        “flipped” prompt, where the image is rotated by 180° before the second pass. The two predicted
        noise fields are rotated into a common orientation and averaged, and this averaged estimate is
        used for the reverse diffusion update. Repeating this through the whole schedule yields an
        image that is simultaneously compatible with both prompts, but with each one dominating in a
        different orientation.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <div class="iteration-belt__viewport">
      <h3 class="iteration-belt__row-title">Upright vs. flipped interpretations</h3>
      <div class="iteration-belt__track">

        <!-- Illusion 1: Campfire / Old Man -->
        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/anagram_upright.png"
            alt="Visual anagram upright: people around a campfire">
          <figcaption class="iteration-belt__caption">
            Upright: “an oil painting of people around a campfire”
          </figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/anagram_flipped.png"
            alt="Visual anagram flipped: old man">
          <figcaption class="iteration-belt__caption">
            Flipped: “an oil painting of an old man”
          </figcaption>
        </figure>

        <!-- Illusion 2: Cleopatra newborn / dying queen -->
        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/a/anagram_upright.png"
            alt="Upright Cleopatra visual anagram">
          <figcaption class="iteration-belt__caption">
            Upright: “a baroque painting of Cleopatra as a newborn princess
            in a tall palace hall”
          </figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/a/anagram_flipped.png"
            alt="Flipped Cleopatra visual anagram">
          <figcaption class="iteration-belt__caption">
            Flipped: “a baroque painting of Cleopatra as a dying queen in the same hall”
          </figcaption>
        </figure>

        <!-- Illusion 3: Bastille / Declaration of Independence -->
        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/b/anagram_flipped.png"
            alt="Visual anagram flipped: storming of the Bastille">
          <figcaption class="iteration-belt__caption">
            Flipped: “a romanticism painting of the storming of the Bastille”
          </figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/visual_anagrams/b/anagram_upright.png"
            alt="Visual anagram upright: signing of the U.S. Declaration of Independence">
          <figcaption class="iteration-belt__caption">
            Upright: “a neoclassical painting of the signing of the United States
            Declaration of Independence”
          </figcaption>
        </figure>

      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The Cleopatra anagram uses the symmetry of the palace architecture and drapery to encode two temporal states of
        the
        same character—birth and death—in a single canvas, with the vertical axes of the columns and
        stairs serving both compositions. The final pair blends two historical scenes into one:
        in one orientation, the flags, torches, and crowd read as the storming of the Bastille,
        whereas in the other orientation the same shapes align into the orderly assembly and banners
        of the U.S. Declaration’s signing. Diffusion models not only produce standalone images but
        can be steered to produce images that occupy the intersection of two distinct textual
        descriptions, with rotation acting as the switch that selects which interpretation dominates.
      </p>
    </div>
  </section>

  <!-- ==================================================== 1.9 Hybrid Images ====================================================== -->
  <section class="content gold-glass iteration-belt" aria-label="Hybrid images">
    <h2 class="section-heading">1.9 Hybrid Images</h2>

    <div class="iteration-belt__intro">
      <p>
        Hybrid images are constructed by combining the low-frequency content of one image with the
        high-frequency detail of another. In this part, two prompts are sampled separately, then split
        into “blurred” and “detail” components using Gaussian smoothing and a corresponding
        high-pass residual. The final hybrid is obtained by adding the low frequencies of the first
        image to the high frequencies of the second. When viewed up close, the eye is drawn to the
        high-frequency structure and the hybrid resembles the second prompt; when viewed from farther
        away or at a reduced resolution, the low-frequency structure dominates and the first prompt
        becomes more apparent.
      </p>
    </div>

    <div class="iteration-belt__header">
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">
        Pause
      </button>
    </div>

    <div class="iteration-belt__viewport">
      <h3 class="iteration-belt__row-title">Hybrids across spatial frequency scales</h3>
      <div class="iteration-belt__track">

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/hybrid/a/hybrid_steps.gif"
            alt="Hybrid between a skull and a waterfall">
          <figcaption class="iteration-belt__caption">
            “a lithograph of a skull” / “a lithograph of a waterfall” – up close the skull’s eye
            sockets and teeth dominate, while from a distance the smooth cascades and vertical bands
            read as a waterfall.
          </figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/hybrid/b/hybrid_steps.gif"
            alt="Hybrid between a king and a volcano">
          <figcaption class="iteration-belt__caption">
            “a lithograph of a king” / “a lithograph of a volcano” – at high resolution the crown,
            facial features, and cloak outlines identify the king; as the image is shrunk or viewed
            from afar, the same contours merge into the cone, crater, and plume of a volcanic scene.
          </figcaption>
        </figure>

        <figure class="iteration-belt__item">
          <img class="iteration-belt__image" src="media/hybrid/c/hybrid_steps.gif"
            alt="Hybrid between a woman reading and a gothic cathedral">
          <figcaption class="iteration-belt__caption">
            “a young woman reading near a candlelight” / “a gothic cathedral” – nearby, the hybrid
            looks like a softly lit portrait, with facial details and hair strands defined by the
            high-frequency component; at a distance, the arches, windows, and vertical buttresses of a
            cathedral emerge from the low-frequency structure.
          </figcaption>
        </figure>

      </div>
    </div>

    <div class="iteration-belt__outro">
      <p>
        Across all three examples, the GIFs make the frequency trade-off explicit. Early frames emphasize
        heavily blurred bases in which only coarse silhouettes from the first prompt are visible, while
        later frames sharpen edges, textures, and small-scale contrast contributed by the second prompt.
        The resulting static hybrids therefore encode two distinct descriptions in a single image, with
        the perceived interpretation shifting smoothly as the viewing distance or display scale changes.
      </p>
    </div>

  </section>


  <script src="../script.js" defer></script>
</body>

</html>