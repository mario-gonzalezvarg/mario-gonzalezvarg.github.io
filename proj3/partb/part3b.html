<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project 3B – Stitching Photo Mosaics</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;600;700&display=swap" rel="stylesheet" />

  <link rel="stylesheet" href="../../styles.css" />
</head>

<body class="top-title">
  <canvas id="sky" aria-hidden="true"></canvas>

  <header class="site-header">
    <div class="content">
      <nav class="top-nav" aria-label="Project navigation">
        <a href="../../index.html" class="nav-logo">Home</a>
      </nav>
    </div>
  </header>

  <div class="content big-title">
    <h1 class="title">Stitching Photo Mosaics</h1>

    <div class="project-switcher" aria-label="Jump to project parts">
      <a href="../parta/part3a.html" class="project-switcher__button">
        Part A
      </a>
      <a href="../partb/part3b.html" class="project-switcher__button project-switcher__button--primary">
        Part B
      </a>
    </div>
  </div>

  <!-- ========== B.1: Corner Detection (Harris + ANMS) ========== -->
  <section class="content gold-glass iteration-belt" id="b1">
    <h2 class="section-heading">B.1 Corner Detection</h2>

    <div class="iteration-belt__intro">
      <p>
        Corner detection can be decomposed into two judgments: where the image contains two-directional variation, and
        which
        of those locations should be retained as a stable basis for later matching. The Harris response supplies the
        first
        judgment by measuring whether local gradients provide evidence of structure in more than one direction; a high
        score
        is interpreted as a location whose appearance is locally informative rather than edge-like or flat. The Harris
        map, taken alone, does not enforce a useful distribution. Dense clusters occur whenever repeated texture
        generates many neighboring pixels with similar scores, so the raw output is often an over-complete description
        of a
        single region. Adaptive Non-Maximal Suppression (ANMS) supplies the second judgment by trading quantity for
        coverage:
        points are retained when they remain strong while also being far from stronger competitors, which spreads the
        set
        across the object and reduces redundancy.
      </p>

    </div>

    <!-- ---------------- Example: g2 (green glass) ---------------- -->
    <h3 class="iteration-belt__row-title" style="margin-top: 0.25rem;">Example 1 (g2 — green glass)</h3>

    <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group"
      aria-label="Harris vs ANMS corner distribution (g2)">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Harris (raw)</div>
        <img class="viz-pair__image" src="media/1_corner/g2/corners_harris.png"
          alt="Harris corners for g2 (raw detections)" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">ANMS (suppressed)</div>
        <img class="viz-pair__image" src="media/1_corner/g2/corners_anms.png"
          alt="ANMS-selected corners for g2 (spatially distributed subset)" loading="lazy">
      </figure>
    </div>

    <div class="iteration-belt__intro">
      <p>
        The two images in each pair serve as a diagnostic. The Harris visualization indicates the underlying “evidence
        field”
        (where the image claims to have corners), while the ANMS visualization indicates whether that evidence can be
        converted into a spatially balanced set that will not collapse downstream matching into a single textured patch.
      </p>
      
    </div>

    <div class="iteration-belt__outro">
      <p>
        The green glass sculpture is a difficult corner source because local appearance is less stable. Translucency and
        internal refraction generate view-dependent highlights and low-frequency intensity drift, and darker regions
        reduce
        signal-to-noise; both effects weaken the gradient evidence that Harris relies on. Increasing
        <code>max-harris</code>
        to 10000 preserves more marginal candidates so that ANMS can still extract a reasonably distributed set of 450
        points
        without collapsing onto a few bright highlight boundaries.
      </p>
    </div>

    <!-- ---------------- Example: r1 (red glass) ---------------- -->
    <h3 class="iteration-belt__row-title" style="margin-top: 1.75rem;">Example 2 (r1 — red glass)</h3>

    <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group"
      aria-label="Harris vs ANMS corner distribution (r1)">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Harris (raw)</div>
        <img class="viz-pair__image" src="media/1_corner/r1/corners_harris.png"
          alt="Harris corners for r1 (raw detections)" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">ANMS (suppressed)</div>
        <img class="viz-pair__image" src="media/1_corner/r1/corners_anms.png"
          alt="ANMS-selected corners for r1 (spatially distributed subset)" loading="lazy">
      </figure>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The red glass sculpture provides stronger, more repeatable corner evidence because the dominant cues are stable
        surface boundaries and consistent shading transitions. The Harris field therefore contains more clearly
        separated
        maxima, so fewer raw candidates (<code>max-harris</code> = 6000) are sufficient, and ANMS can retain a smaller
        set
        (350) while still maintaining broad coverage across the structure.
      </p>
      <p>
        Failures concentrate where the premise of “corner stability” is violated. Specular highlights can create corners
        that move with viewpoint rather than with geometry; repeated micro-texture can produce many near-duplicates that
        remain locally strong but do not add new information; and low-texture regions can leave ANMS with little
        evidence to
        distribute. Success is most reliable when the selected points lie on rigid, high-contrast geometry whose
        gradient
        structure persists under small viewpoint changes.
      </p>
    </div>
  </section>



 <!-- ========== B.2: Feature Descriptors ========== -->
<section class="content gold-glass iteration-belt" id="b2">
  <h2 class="section-heading">B.2 Feature Descriptors</h2>

  <div class="iteration-belt__intro">
    <p>
      Descriptor extraction can be reduced to three operations: sampling a neighborhood around each retained corner,
      canonicalizing that neighborhood into a fixed-dimensional representation, and comparing representations by a
      distance rule. The purpose of canonicalization is not aesthetic compression, but invariance: a match should be
      driven by local structure that persists across views rather than by absolute exposure or global tone.
    </p>
  </div>

  <div class="code-snippets" aria-label="Descriptor construction summary">
    <div class="code-snippets__title">Descriptor construction</div>
    <details class="code-snippet" open>
      <summary>patch → vector</summary>
      <div class="code-snippet__body">
        <pre class="code-block"><code>1) Extract a square patch around each keypoint (grayscale).
2) Apply mild smoothing (stabilizes against pixel noise / aliasing).
3) Downsample to a small canonical grid (e.g., 8×8) to form a compact template.
4) Normalize per patch (zero-mean, unit-variance) to reduce exposure sensitivity.
5) Flatten to a descriptor vector; compare descriptors by L2 distance.</code></pre>
      </div>
    </details>
  </div>

  <div class="iteration-belt__intro">
    <p>
      Two diagnostic visualizations are used to judge whether the descriptor is behaving as intended. The <em>descriptor
      points</em> image shows coverage, whether samples span the object and the overlap region instead of collapsing into a
      single cluster. The <em>descriptor patches</em> grid shows discriminability, whether the encoded neighborhoods contain
      stable edges/corners or instead devolve into flat, noisy, or highlight-dominated templates that cannot support
      reliable matching.
    </p>
  </div>

  <h3 class="iteration-belt__row-title" style="margin-top: 0.25rem;">Example 1 (g2 — green glass)</h3>
  <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group"
       aria-label="Descriptor points and patches (green glass)">
    <figure class="viz-pair__panel">
      <div class="viz-pair__title">Descriptor points</div>
      <img class="viz-pair__image" src="media/2_descriptor/g2/descriptor_points.png"
           alt="Keypoints where descriptors are extracted on the green glass sculpture" loading="lazy">
    </figure>

    <figure class="viz-pair__panel">
      <div class="viz-pair__title">Descriptor patches</div>
      <img class="viz-pair__image" src="media/2_descriptor/g2/descriptor_patches.png"
           alt="Grid of normalized descriptor patches extracted from the green glass sculpture" loading="lazy">
    </figure>
  </div>

  <div class="iteration-belt__outro">
    <p>
      Again, we emphasize how the green glass case is systematically harder because the local evidence is less repeatable. Translucency introduces
      view-dependent highlights and internal refraction, so a patch centered at the “same” geometric location can change its
      intensity layout between views. Dark regions additionally reduce signal-to-noise; after per-patch normalization, small
      sensor noise can be scaled into meaningful-looking contrast, which makes some templates appear distinctive while not
      being stable.
    </p>
    <!-- <p>
      The red glass case is comparatively cooperative because a larger fraction of the neighborhood structure is anchored
      to stable surface boundaries and consistent gradient patterns. The patch grid therefore contains more repeatable
      edge/corner configurations, and the point distribution more often yields keypoints whose descriptors remain coherent
      across viewpoint changes.
    </p>
    <p>
      Descriptor failure concentrates in (1) low-texture neighborhoods that collapse to noise after normalization,
      (2) repeated micro-structure where many patches are genuinely similar and therefore ambiguous, and
      (3) specular/refractive regions where appearance is not attached to the surface. Descriptor success is most reliable
      when the neighborhood contains rigid, high-contrast geometry that preserves its gradient structure across views.
    </p> -->
  </div>

  <h3 class="iteration-belt__row-title" style="margin-top: 1.75rem;">Example 2 (r1 — red glass)</h3>
  <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group"
       aria-label="Descriptor points and patches (red glass)">
    <figure class="viz-pair__panel">
      <div class="viz-pair__title">Descriptor points</div>
      <img class="viz-pair__image" src="media/2_descriptor/r1/descriptor_points.png"
           alt="Keypoints where descriptors are extracted on the red glass sculpture" loading="lazy">
    </figure>

    <figure class="viz-pair__panel">
      <div class="viz-pair__title">Descriptor patches</div>
      <img class="viz-pair__image" src="media/2_descriptor/r1/descriptor_patches.png"
           alt="Grid of normalized descriptor patches extracted from the red glass sculpture" loading="lazy">
    </figure>
  </div>

  <div class="iteration-belt__outro">
    <!-- <p>
      Again, we emphasize how the green glass case is systematically harder because the local evidence is less repeatable. Translucency introduces
      view-dependent highlights and internal refraction, so a patch centered at the “same” geometric location can change its
      intensity layout between views. Dark regions additionally reduce signal-to-noise; after per-patch normalization, small
      sensor noise can be scaled into meaningful-looking contrast, which makes some templates appear distinctive while not
      being stable.
    </p> -->
    <p>
      The red glass case is comparatively cooperative because a larger fraction of the neighborhood structure is anchored
      to stable surface boundaries and consistent gradient patterns. The patch grid therefore contains more repeatable
      edge/corner configurations, and the point distribution more often yields keypoints whose descriptors remain coherent
      across viewpoint changes.
    <!-- </p>
    <p> -->
      Descriptor failure concentrates in (1) low-texture neighborhoods that collapse to noise after normalization,
      (2) repeated micro-structure where many patches are genuinely similar and therefore ambiguous, and
      (3) specular/refractive regions where appearance is not attached to the surface. Descriptor success is most reliable
      when the neighborhood contains rigid, high-contrast geometry that preserves its gradient structure across views.
    </p>
  </div>
</section>



<!-- ========== B.3: Feature Matching ========== -->
<section class="content gold-glass iteration-belt" id="b3">
  <h2 class="section-heading">B.3 Feature Matching</h2>

  <div class="iteration-belt__intro">
    <p>
      Feature matching can be treated as a test of whether the descriptor representation is sufficiently distinctive and
      sufficiently repeatable to survive a viewpoint change. Each retained corner produces a descriptor vector; for every
      descriptor in Image A, the nearest neighbors in Image B are queried in descriptor space, and a decision rule filters
      ambiguous hypotheses before they become geometric constraints.
    </p>
    <p>
      The diagnostic objective is twofold: (1) verify that the selected keypoints and descriptors for the second image
      (r2) contain stable structure rather than highlight noise, and (2) verify that the accepted matches form a coherent
      pattern across the overlap rather than a dense set of inconsistent crossings.
    </p>
  </div>

  <h3 class="iteration-belt__row-title" style="margin-top: 0.25rem;">Reference features (r2)</h3>

  <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group" aria-label="r2 corners: Harris vs ANMS">
    <figure class="viz-pair__panel">
      <div class="viz-pair__title">r2 Harris (raw)</div>
      <img class="viz-pair__image" src="media/1_corner/r2/corners_harris.png"
           alt="Harris corner detections for r2 (raw candidates)" loading="lazy">
    </figure>

    <figure class="viz-pair__panel">
      <div class="viz-pair__title">r2 ANMS (suppressed)</div>
      <img class="viz-pair__image" src="media/1_corner/r2/corners_anms.png"
           alt="ANMS-selected corners for r2 (spatially distributed subset)" loading="lazy">
    </figure>
  </div>

  <div class="viz-pair" style="--viz-pair-max: 34rem;" role="group" aria-label="r2 descriptors: points and patches">
    <figure class="viz-pair__panel">
      <div class="viz-pair__title">r2 descriptor points</div>
      <img class="viz-pair__image" src="media/2_descriptor/r2/descriptor_points.png"
           alt="Keypoints where descriptors are extracted on r2" loading="lazy">
    </figure>

    <figure class="viz-pair__panel">
      <div class="viz-pair__title">r2 descriptor patches</div>
      <img class="viz-pair__image" src="media/2_descriptor/r2/descriptor_patches.png"
           alt="Grid of normalized descriptor patches for r2" loading="lazy">
    </figure>
  </div>

  <div class="code-snippets" aria-label="Matching rule and parameters">
    <div class="code-snippets__title">Matching rule</div>

    <details class="code-snippet" open>
      <summary>ratio test (Lowe-style)</summary>
      <div class="code-snippet__body">
        <pre class="code-block"><code>For each descriptor in A:
  find the best and second-best matches in B by L2 distance.
  keep the best match only if (d1 / d2) < ratio.

ratio = 0.8
matches kept = 112</code></pre>
      </div>
    </details>
  </div>

  <figure class="viz-pair__panel" style="max-width: 80rem; margin: 1.5rem auto 0;">
    <div class="viz-pair__title">Filtered feature matches (r1 ↔ r2)</div>
    <img class="viz-pair__image" src="media/3_featureMatch/r12/matches.png"
         alt="Visualization of filtered matches between r1 and r2 with correspondence lines" loading="lazy">
  </figure>

  <div class="iteration-belt__outro">
    <p>
      The match visualization encodes a set of correspondence hypotheses: each line asserts that two local neighborhoods,
      one in r1 and one in r2, are similar under the chosen descriptor. Coherence is indicated when many lines connect
      analogous geometric regions and share a consistent global trend (reflecting the dominant camera motion). Failure is
      indicated by a large population of crisscrossing lines that jump between unrelated regions, which typically occurs
      when descriptors are not distinctive (repeated texture) or not repeatable (specular / refractive changes).
    </p>
    <p>
      The ratio test is a practical ambiguity filter. When the nearest and second-nearest candidates are nearly tied, the
      descriptor does not supply strong evidence for a unique match, so the correspondence is rejected. This rejection is
      desirable before geometry: even a small fraction of ambiguous matches can dominate later homography estimation.
    </p>
    <p>
      The red glass pair (r1↔r2) is comparatively matchable because many corner neighborhoods are anchored to stable
      surface boundaries and consistent gradient patterns. In contrast, the green translucent case tends to produce
      view-dependent intensity rearrangements inside patches, so the “same” physical region can yield a different
      descriptor and either fail the ratio test (no confident nearest neighbor) or pass spuriously (nearest neighbor is
      driven by highlight coincidence rather than geometry).
    </p>
  </div>
</section>


  <!-- ========== B.4: RANSAC Homography ========== -->
  <section class="content gold-glass iteration-belt" id="b5">
    <h2 class="section-heading">B.4 RANSAC for Robust Homography</h2>
    <div class="iteration-belt__intro">
      <p>
      </p>
    </div>
  </section>


  <script src="../../script.js" defer></script>
</body>

</html>