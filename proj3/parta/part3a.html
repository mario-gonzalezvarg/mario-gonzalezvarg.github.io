<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Project 3A – Stitching Photo Mosaics</title>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@300;400;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="../../styles.css" />
  <script>
    window.MathJax = {
      tex: { inlineMath: [['\\(', '\\)']], displayMath: [['\\[', '\\]']] },
      options: { skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'] }
    };
  </script>
  <script async id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

</head>

<body class="top-title">

  <canvas id="sky" aria-hidden="true"></canvas>

  <header class="site-header">
    <div class="content">
      <nav class="top-nav" aria-label="Project navigation">
        <a href="../../index.html" class="nav-logo">Home</a>
      </nav>
    </div>

  </header>

  <div class="content big-title">
    <h1 class="title">Image Warping and Mosaicing</h1>
    <div class="project-switcher" aria-label="Jump to project parts">
      <a href="./part3a.html" class="project-switcher__button project-switcher__button--primary">
        Part A
      </a>
      <a href="../partb/part3b.html" class="project-switcher__button">
        Part B
      </a>
    </div>
  </div>

  <!-- =============================== Overview =============================== -->
  <section class="content gold-glass writing-section" id="overview">
    <h2 class="section-heading">Overview</h2>
    <p>
      Panoramic mosaicing can be generalized as a sequence of constrained transformations that converts multiple partial
      views into a single consistent image. The pipeline separates into correspondence selection, homography estimation,
      geometric warping into a common coordinate system, and photometric blending to suppress visible seams.
    </p>
    <p>
      The evidence for each transformation is confined to repeated conjunctions of local appearances across overlapping
      images. A correspondence asserts that two pixel neighborhoods are distinct appearances of one scene point; a
      homography is accepted when it explains many such assertions while rejecting accidental alignments. The resulting
      mosaic is therefore a stabilized representation: relations that persist across viewpoints are preserved, and
      relations that fail under re-projection are treated as noise.
    </p>
  </section>

  <!-- ========== A.1: Shoot and digitize pictures (20 pts) ========== -->
  <section class="content gold-glass iteration-belt iteration-belt--two-rows" id="a1">
    <h2 class="section-heading">A.1 Shoot Photos</h2>

    <div class="iteration-belt__intro">
      <p>
        Two overlapping sequences are captured under camera rotation about a fixed center of projection. This capture
        condition makes the inter-image motion well-approximated by a single projective transform, providing the raw
        constraints used later to recover a homography.
      </p>
    </div>

    <div class="iteration-belt__header">
      <h3 class="iteration-belt__title">Captured image sequences</h3>
      <button type="button" class="iteration-belt__toggle" aria-pressed="false">Pause</button>
    </div>

    <!-- Row 1: Catalina -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Catalina Island, California</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1693.JPG"
              alt="Catalina Island photo, view 1" loading="lazy">
            <figcaption class="iteration-belt__caption">View 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1694.JPG"
              alt="Catalina Island photo, view 2" loading="lazy">
            <figcaption class="iteration-belt__caption">View 2</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1695.JPG"
              alt="Catalina Island photo, view 3" loading="lazy">
            <figcaption class="iteration-belt__caption">View 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1696.JPG"
              alt="Catalina Island photo, view 4" loading="lazy">
            <figcaption class="iteration-belt__caption">View 4</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1697.JPG"
              alt="Catalina Island photo, view 5" loading="lazy">
            <figcaption class="iteration-belt__caption">View 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1698.JPG"
              alt="Catalina Island photo, view 6" loading="lazy">
            <figcaption class="iteration-belt__caption">View 6</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1699.JPG"
              alt="Catalina Island photo, view 7" loading="lazy">
            <figcaption class="iteration-belt__caption">View 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/catalina/IMG_1700.JPG"
              alt="Catalina Island photo, view 8" loading="lazy">
            <figcaption class="iteration-belt__caption">View 8</figcaption>
          </figure>

        </div>
      </div>
    </div>

    <!-- Row 2: Grand Canyon -->
    <div class="iteration-belt__row">
      <h3 class="iteration-belt__row-title">Grand Canyon, Arizona</h3>
      <div class="iteration-belt__viewport">
        <div class="iteration-belt__track">

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7135.JPG"
              alt="Grand Canyon photo, view 1" loading="lazy">
            <figcaption class="iteration-belt__caption">View 1</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7136.JPG"
              alt="Grand Canyon photo, view 2" loading="lazy">
            <figcaption class="iteration-belt__caption">View 2</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7137.JPG"
              alt="Grand Canyon photo, view 3" loading="lazy">
            <figcaption class="iteration-belt__caption">View 3</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7138.JPG"
              alt="Grand Canyon photo, view 4" loading="lazy">
            <figcaption class="iteration-belt__caption">View 4</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7140.JPG"
              alt="Grand Canyon photo, view 5" loading="lazy">
            <figcaption class="iteration-belt__caption">View 5</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7141.JPG"
              alt="Grand Canyon photo, view 6" loading="lazy">
            <figcaption class="iteration-belt__caption">View 6</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7142.JPG"
              alt="Grand Canyon photo, view 7" loading="lazy">
            <figcaption class="iteration-belt__caption">View 7</figcaption>
          </figure>

          <figure class="iteration-belt__item">
            <img class="iteration-belt__image" src="media/1_shootPhotos/canyon/IMG_7143.JPG"
              alt="Grand Canyon photo, view 8" loading="lazy">
            <figcaption class="iteration-belt__caption">View 8</figcaption>
          </figure>

        </div>
      </div>
    </div>

  </section>

  <!-- ========== A.2: Recover homographies (20 pts) ========== -->
  <section class="content gold-glass iteration-belt" id="a2">
    <h2 class="section-heading">A.2 Recover Homographies</h2>

    <div class="iteration-belt__intro">
      <p>
        Homography estimation can be decomposed into constraint selection and parameter recovery. Each correspondence
        asserts that a point in Image A and a point in Image B are two appearances of the same scene point under a
        change
        in viewpoint. Under the projective camera model, these assertions imply a 3×3 mapping <em>H</em> such that
        <em>p′</em> is proportional to <em>H p</em>.
      </p>

      <p>
        The mapping is recovered by stacking the linear constraints induced by all correspondences into a single system
        and
        solving for <em>H</em> up to scale. The correspondence set is distributed across the overlap so the solution is
        informed by global structure rather than a single local patch.
      </p>
    </div>

    <div class="math-derivation" style="--math-max: 70rem;">
      <div class="math-derivation__title">Constraint stacking as a linear system</div>

      <div class="math-derivation__body">
        <p>Take the homography as</p>
        <div class="math-derivation__eq">
          \[
          H =
          \begin{bmatrix}
          h_1 & h_2 & h_3 \\
          h_4 & h_5 & h_6 \\
          h_7 & h_8 & 1
          \end{bmatrix},
          \quad
          \mathbf{h} =
          \begin{bmatrix}
          h_1 & h_2 & h_3 & h_4 & h_5 & h_6 & h_7 & h_8
          \end{bmatrix}^{\top}.
          \]
        </div>

        <p>
          For each correspondence \((x_i, y_i)\) in <code>view 1</code> and \((x'_i, y'_i)\) in <code>view 5</code>,
          in homogeneous coordinates,
        </p>
        <div class="math-derivation__eq">
          \[
          \begin{bmatrix}
          x'_i \\[2pt] y'_i \\[2pt] 1
          \end{bmatrix}
          \sim
          H
          \begin{bmatrix}
          x_i \\[2pt] y_i \\[2pt] 1
          \end{bmatrix}.
          \]
        </div>

        <p>This gives</p>
        <div class="math-derivation__eq">
          \[
          x'_i = \frac{h_1 x_i + h_2 y_i + h_3}{h_7 x_i + h_8 y_i + 1},
          \quad
          y'_i = \frac{h_4 x_i + h_5 y_i + h_6}{h_7 x_i + h_8 y_i + 1}.
          \]
        </div>

        <p>
          Rearranging to be linear in \(\mathbf{h}\), each point pair contributes two rows to a system
          \(A\mathbf{h}=\mathbf{b}\):
        </p>
        <div class="math-derivation__eq">
          \[
          \begin{bmatrix}
          x_i & y_i & 1 & 0 & 0 & 0 & -x_i x'_i & -y_i x'_i \\
          0 & 0 & 0 & x_i & y_i & 1 & -x_i y'_i & -y_i y'_i
          \end{bmatrix}
          \mathbf{h}
          =
          \begin{bmatrix}
          x'_i \\[2pt] y'_i
          \end{bmatrix}.
          \]
        </div>

        <p>
          Stack these \(2N\) rows from all \(N\) correspondences into a big matrix \(A\) and vector \(\mathbf{b}\), then
          solve
          \(A\mathbf{h}\approx \mathbf{b}\) in least squares to recover \(H\).
        </p>
      </div>
    </div>

    <div class="code-snippets" aria-label="Recovered homography matrix">
      <div class="code-snippets__title">Recovered homography</div>

      <details class="code-snippet" open>
        <summary>H (Catalina View 1 → Catalina View 5)</summary>
        <div class="code-snippet__body">
          <pre class="code-block"><code>[[ 1.77486435e+00  4.04361609e-02 -2.77535848e+03]
              [ 4.42547768e-01  1.61873526e+00 -1.14219166e+03]
              [ 2.37956041e-04  1.77379109e-05  1.00000000e+00]]</code></pre>
        </div>
      </details>
    </div>


    <div class="iteration-belt__outro">
      <p>
        It's crucial to understand that homographies are exact only under restricted imaging conditions. The model
        assumes that the observed
        correspondences
        arise from either a single planar surface or a pure camera rotation about a fixed center; when the scene
        contains
        strong depth variation, parallax causes one global <em>H</em> to align some regions while misaligning others,
        often
        producing double edges and “ghosted” structures near depth discontinuities.
      </p>
    </div>



    <div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
      aria-label="Selected correspondences for homography estimation">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Image A</div>
        <img class="viz-pair__image" src="media/2_homography/imgA.png"
          alt="Image A with selected correspondence points marked" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Image B</div>
        <img class="viz-pair__image" src="media/2_homography/imgB.png"
          alt="Image B with selected correspondence points marked" loading="lazy">
      </figure>
    </div>

    <div class="iteration-belt__outro">
      <p>
        Nnumerical stability also depends on the geometry of the selected points. If correspondences cluster in a small
        area
        or
        lie close to a line, the linear system becomes ill-conditioned and small clicking errors amplify into large
        projective
        distortions, especially in the corners. Better behavior follows from distributing points broadly across the
        overlap
        and including strong 2D structure (corners and junctions) rather than ambiguous texture.
      </p>
    </div>




  </section>

  <section class="content gold-glass iteration-belt" id="a3">
    <h2 class="section-heading">A.3 Warp the Images</h2>

    <div class="iteration-belt__intro">
      <p>
        Image warping can be reduced to an inverse mapping from the output canvas back into the source image. For each
        output
        pixel, the inverse homography predicts a continuous source coordinate, and interpolation supplies a color
        estimate
        without leaving holes in the result.
      </p>
    </div>

    <div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
      aria-label="Rectification correspondences for the frame example">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Source (selected corners)</div>
        <img class="viz-pair__image" src="media/3_warp/frame/frame_points_imgA.png"
          alt="Source photo with four selected corner points on the frame" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Target (ideal rectangle)</div>
        <img class="viz-pair__image" src="media/3_warp/frame/frame_points_imgB.png"
          alt="Target rectangle with four corresponding corner points" loading="lazy">
      </figure>
    </div>


    <div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
      aria-label="Alpha mask comparison by interpolation method">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">NN mask</div>
        <img class="viz-pair__image" src="media/3_warp/frame/warp_nn/redFrame_warped_mask.png"
          alt="Alpha mask for the nearest-neighbor rectification" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Bilinear mask</div>
        <img class="viz-pair__image" src="media/3_warp/frame/warp_bilinear/redFrame_warped_mask.png"
          alt="Alpha mask for the bilinear rectification" loading="lazy">
      </figure>
    </div>

    <div class="iteration-belt__intro">
      <p>
        Nearest-neighbor interpolation selects the closest sampled pixel and therefore preserves speed at the cost of
        jagged
        edges and staircase artifacts. Bilinear interpolation averages the four surrounding samples, which reduces
        aliasing
        along strong edges but increases computation per output pixel.
      </p>
    </div>

    <div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
      aria-label="Rectified output comparison by interpolation method">
      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Nearest neighbor</div>
        <img class="viz-pair__image" src="media/3_warp/frame/warp_nn/redFrame_warped.png"
          alt="Rectified frame using nearest-neighbor interpolation" loading="lazy">
      </figure>

      <figure class="viz-pair__panel">
        <div class="viz-pair__title">Bilinear</div>
        <img class="viz-pair__image" src="media/3_warp/frame/warp_bilinear/redFrame_warped.png"
          alt="Rectified frame using bilinear interpolation" loading="lazy">
      </figure>
    </div>

    <figure class="viz-pair__panel" style="max-width: 60rem; margin: 1.25rem auto 0;">
      <div class="viz-pair__title">Difference map (|bilinear − NN| × 10)</div>
      <img class="viz-pair__image" src="media/3_warp/frame/diff_x10.png"
        alt="Amplified absolute difference between bilinear and nearest-neighbor warped outputs (scaled by 10)"
        loading="lazy">
    </figure>

    <div class="code-snippets" aria-label="Numeric difference between bilinear and nearest neighbor outputs">
      <div class="code-snippets__title">Numeric difference (bilinear vs NN)</div>

      <details class="code-snippet" open>
        <summary>diff statistics</summary>
        <div class="code-snippet__body">
          <pre class="code-block"><code>max abs diff: 255
mean abs diff: 1.8730802495987138
pct nonzero: 0.6836324854811999</code></pre>
        </div>
      </details>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The amplified difference map visualizes where interpolation changes pixel values under the same inverse warp.
        Most
        deviations concentrate along high-contrast boundaries and diagonal edges, where nearest-neighbor introduces
        staircase
        quantization while bilinear mixes neighboring samples and smooths the transition. The interior of large, slowly
        varying regions remains comparatively stable because both samplers draw from similar source values. A maximum
        absolute difference of 255 indicates that some pixels
        disagree strongly (typically at thin edges or near invalid-region boundaries), while the mean absolute
        difference of
        1.87 shows that the average per-channel deviation is small relative to the 8-bit intensity range. The nonzero
        rate
        (about 68%) indicates that many pixels change by at least one intensity level, but most changes are minor and
        are
        therefore easy to miss at normal viewing scale or after browser downsampling.
      </p>
    </div>

    <div class="code-snippets" aria-label="Runtime comparison for warping">
      <div class="code-snippets__title">Runtime comparison</div>

      <details class="code-snippet" open>
        <summary>redFrame → form (inverse warping)</summary>
        <div class="code-snippet__body">
          <pre class="code-block"><code>Nearest neighbor:
  time_warp_s  = 15.629
  time_total_s = 20.828

Bilinear:
  time_warp_s  = 16.519
  time_total_s = 21.954

Δ warp  = +0.889 s  (+5.69%)
Δ total = +1.126 s  (+5.41%)</code></pre>
        </div>
      </details>
    </div>

    <div class="iteration-belt__outro">
      <p>
        The speed difference follows directly from arithmetic density: nearest neighbor performs one fetch per output
        pixel,
        while bilinear performs four fetches and a weighted blend. The quality difference concentrates along
        high-contrast
        edges, where bilinear suppresses blocky discontinuities but can slightly blur fine texture.
      </p>
      <p>
        The remaining failure modes are geometric rather than interpolative. If the output bounds are underestimated,
        valid
        content is clipped; if they are overestimated, large empty regions appear and must be carried by an alpha mask.
        Small
        inconsistencies in point placement also manifest as shear or residual perspective in the rectified result, since
        the
        warp propagates corner error across the entire plane.
      </p>
    </div>

    <!-- ---------- Rectification example 2: Sticker / “pink” ---------- -->
<h3 class="iteration-belt__row-title" style="margin-top: 2.0rem;">Rectification example: Sticker surface</h3>

<p class="iteration-belt__intro" style="margin-top: 0.75rem;">
  A second rectification instance isolates a dense, high-frequency surface (stickers + paint) where interpolation
  differences appear as small, spatially localized changes. The inverse mapping is held fixed; only the interpolation
  operator varies.
</p>

<div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
     aria-label="Rectification correspondences for the sticker example">
  <figure class="viz-pair__panel">
    <div class="viz-pair__title">Source (selected corners)</div>
    <img class="viz-pair__image" src="media/3_warp/pink/points_imgA.png"
         alt="Sticker photo with selected corner points on the planar region" loading="lazy">
  </figure>

  <figure class="viz-pair__panel">
    <div class="viz-pair__title">Target (ideal rectangle)</div>
    <img class="viz-pair__image" src="media/3_warp/pink/points_imgB.png"
         alt="Target rectangle with corresponding corner points" loading="lazy">
  </figure>
</div>

<div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
     aria-label="Rectified output comparison for the sticker example">
  <figure class="viz-pair__panel">
    <div class="viz-pair__title">Nearest neighbor</div>
    <img class="viz-pair__image" src="media/3_warp/pink/nn/pink_warped_rgba.png"
         alt="Sticker rectification using nearest-neighbor interpolation" loading="lazy">
  </figure>

  <figure class="viz-pair__panel">
    <div class="viz-pair__title">Bilinear</div>
    <img class="viz-pair__image" src="media/3_warp/pink/bilinear/pink_warped_rgba.png"
         alt="Sticker rectification using bilinear interpolation" loading="lazy">
  </figure>
</div>

<!-- <div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
     aria-label="Alpha mask comparison for the sticker example">
  <figure class="viz-pair__panel">
    <div class="viz-pair__title">NN mask</div>
    <img class="viz-pair__image" src="media/3_warp/pink/nn/pink_warped_mask.png"
         alt="Alpha mask for nearest-neighbor sticker rectification" loading="lazy">
  </figure>

  <figure class="viz-pair__panel">
    <div class="viz-pair__title">Bilinear mask</div>
    <img class="viz-pair__image" src="media/3_warp/pink/bilinear/pink_warped_mask.png"
         alt="Alpha mask for bilinear sticker rectification" loading="lazy">
  </figure>
</div> -->

<div class="viz-pair" style="--viz-pair-max: 36rem;" role="group"
     aria-label="RGBA outputs and difference visualization for the sticker example">
  <figure class="viz-pair__panel">
    <div class="viz-pair__title">RGBA (bilinear)</div>
    <img class="viz-pair__image" src="media/3_warp/pink/bilinear/pink_warped_rgba.png"
         alt="Sticker rectification RGBA output using bilinear interpolation" loading="lazy">
  </figure>

  <figure class="viz-pair__panel">
    <div class="viz-pair__title">|bilinear − NN| × 10 (clipped)</div>
    <img class="viz-pair__image" src="media/3_warp/pink/diff_x10.png"
         alt="Per-pixel difference visualization between bilinear and nearest neighbor, amplified by 10" loading="lazy">
  </figure>
</div>

<div class="code-snippets" aria-label="Sticker rectification runtime comparison">
  <div class="code-snippets__title">Runtime comparison (sticker)</div>

  <details class="code-snippet" open>
    <summary>pink.JPG → form (inverse warping)</summary>
    <div class="code-snippet__body">
      <pre class="code-block"><code>Nearest neighbor:
  time_warp_s  = 50.703
  time_total_s = 59.054

Bilinear:
  time_warp_s  = 47.676
  time_total_s = 56.579

Δ warp  = −3.026 s  (bilinear faster by 5.97%)
Δ total = −2.475 s  (bilinear faster by 4.19%)</code></pre>
    </div>
  </details>
</div>

<div class="iteration-belt__outro">
  <p>
    The amplified difference map shows that most disagreements are confined to edges and small texture transitions: bilinear
    modifies values by distributing weight across neighboring samples, while nearest neighbor commits to one discrete sample.
    At normal viewing scale the outputs remain visually consistent, but bilinear more reliably suppresses staircase artifacts
    along diagonal boundaries.
  </p>

  <p>
    The runtime ordering in this instance favors bilinear despite its higher arithmetic density. This outcome indicates that
    end-to-end cost is dominated by implementation factors beyond the interpolation stencil (indexing strategy, branching, mask
    bookkeeping, and Python overhead), so the speed–quality trade-off should be reported from measured timings rather than
    theoretical per-pixel counts.
  </p>
</div>


    
  </section>

  <!-- ========== A.4: Blend images into a mosaic (20 pts) ========== -->
  <section class="content gold-glass iteration-belt" id="a4">
    <h2 class="section-heading">A.4 Blend into a Mosaic</h2>

    <div class="iteration-belt__intro">
      <p>
        Deliverables: Show source images and results for three mosaics (include blending/masking details).
      </p>
    </div>
  </section>

  <script src="../../script.js" defer></script>
</body>

</html>