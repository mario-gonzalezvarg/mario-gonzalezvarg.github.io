<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 – Project 2 · Convolution and Filtering · Mario Gonzalez</title>

  <!-- Site styles (already in your repo root) -->
  <link rel="stylesheet" href="../styles.css" />

  <!-- MathJax for LaTeX rendering -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['\\(','\\)'], ['$', '$']],
        displayMath: [['\\[','\\]']]
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>

  <style>
    /* Page-local niceties */
    .hero h1 { margin-bottom: .25rem; }
    .hero p.part-note { opacity:.8 }
    figure.media { margin: 1rem auto; }
    figure.media img { width: 100%; height: auto; display:block; }
    figure.media figcaption { text-align:center; font-size:.95rem; opacity:.85; margin-top:.5rem }
    .kpi { display:grid; grid-template-columns: repeat(auto-fit, minmax(220px, 1fr)); gap:10px; margin:.5rem 0 1.25rem; }
    .kpi div { background: var(--card); padding:.75rem 1rem; border-radius:10px; }
    .section h3 { margin-top: 1.25rem; }
    .mono { font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, monospace; }
    .small { font-size: .92rem; }
    .callout { background: var(--card); border-left: 4px solid var(--accent); padding:.9rem 1rem; border-radius:8px; }
    .refs li { margin-bottom: .4rem; }
    .deliverables li { margin-bottom:.35rem; }
  </style>
</head>

<body>
  <!-- Navbar -->
  <header class="nav-band">
    <nav class="nav container" aria-label="Primary">
      <a href="../index.html">Home</a>
      <a href="index.html" class="active" aria-current="page">Project 2</a>
    </nav>
  </header>

  <!-- Hero -->
  <section class="hero">
    <div class="container">
      <h1>Convolution and Filtering</h1>
      <p class="part-note">CS180 · Fall 2025 · Mario Gonzalez</p>
      <a class="btn" href="../index.html">Back to Home <span class="chev" aria-hidden="true">›</span></a>
    </div>
  </section>

  <!-- Abstract -->
  <section class="section" id="abstract">
    <div class="container">
      <h2 class="section-title">Abstract</h2>
      <p>
      This project investigates linear, shift‑invariant filtering as a common substrate for edge detection, detail
      manipulation, and seamless compositing. I implement discrete two‑dimensional convolution from first principles
      (four‑loop and two‑loop variants) and validate functional parity with <code>scipy.signal.convolve2d</code> under
      matched padding semantics. 
      
      Building on finite differences, I examine the derivative‑of‑Gaussian (DoG) formulation to
      suppress noise amplification, contrast its behavior with raw differencing, and verify the expected frequency response.
      I then apply frequency‑selective processing to three applications: unsharp masking (high‑frequency gain), hybrid
      images (low/high spectral fusion following Oliva–Torralba), and multi‑resolution analysis via Gaussian/Laplacian
      stacks, culminating in Burt–Adelson blending for artifact‑reduced compositing. Across parts, I justify design choices,
      report qualitative outcomes with diagnostics (Fourier magnitude and reconstruction checks), and discuss limitations and
      failure modes.
      </p>
    
    </div>
  </section>

   <!-- ====================== PART 1A ====================== -->
  <section id="part1a" class="section">
    <div class="container">
      <h2 class="section-title">1A · Discrete Convolution</h2>

       <p>
  Let \(I\in\mathbb{R}^{H\times W}\) and \(K\in\mathbb{R}^{(2r+1)\times(2c+1)}\). I implement the discrete convolution
  \((I*K)[x,y]=\sum_{u=-r}^{r}\sum_{v=-c}^{c}I[x-u,y-v]\,K[u,v]\) with kernel flipping and “same” zero padding to match
  the course reference implementation. A didactic four‑loop version mirrors the mathematical summation and boundary
  handling exactly; an optimized two‑loop version collapses the inner multiply–accumulate into vectorized row/column
  slices to reduce Python overhead while preserving identical semantics.
</p>

<h3>Validation</h3>
<p>
  I verify numerical equivalence against <code>scipy.signal.convolve2d</code> using absolute/relative tolerances at
  float precision and by spot‑checking DC‑preserving kernels (e.g., normalized box filters). Boundary conditions are
  held fixed (“same + zero”) so that downstream differences can be attributed to algorithmic choices rather than padding
  artifacts. I also include the 9×9 box‑filter result on a self portrait, as required, alongside finite‑difference
  responses for comparison.
</p>

<h3>Notes on efficiency</h3>
<p>
  The two‑loop variant is measurably faster on megapixel inputs due to vectorized inner products, while producing the
  same output as both the four‑loop and SciPy baselines. I report qualitative runtime observations and keep the
  four‑loop reference for correctness regression tests.
</p>


      <div class="card" style="padding:16px"> <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px"> <label><strong>Dataset:</strong> <select id="a-dataset"></select></label> <strong>k = <span id="a-kval">3</span></strong> <input id="a-kIdx" type="range" min="0" max="0" step="1" value="0" style="width:240px" aria-label="kernel size"> <label><input type="radio" name="a-impl" value="fourloops" checked> From scratch</label> <label><input type="radio" name="a-impl" value="scipy"> SciPy</label> </div>

      <figure class="media media--narrow" style="margin:0 auto"> <img id="a-img" alt="1A result"> <figcaption id="a-cap" style="text-align:center; margin-top:8px"></figcaption> </figure> </div>
              <figure class="media">
  <img src="media/part1/box/11_dx.png">
  <figcaption>dx </figcaption>
</figure>

<figure class="media">
  <img src="media/part1/box/11_dy.png">
  <figcaption>dy</figcaption>
</figure>  
    </div>
  </section>

  <!-- ====================== PART 1B ====================== -->
  <section id="part1b" class="section">
    <div class="container">
      <h2 class="section-title">1B – Finite Difference Operator</h2>
<p>
  I estimate first‑order derivatives with forward‑difference stencils \(D_x=[-1,1]\) and \(D_y=D_x^\top\),
  computing \(I_x=I*D_x\), \(I_y=I*D_y\), and the gradient magnitude \(\|\nabla I\|=\sqrt{I_x^2+I_y^2}\).
  Thresholding \(\|\nabla I\|\) yields a binarized edge map. All processing occurs on linear‑intensity grayscale to
  avoid gamma bias, and uses the same “same + zero” padding adopted in 1A for consistent border support.
</p>

<h3>Threshold selection</h3>
<p>
  To trade off noise rejection and edge completeness, I select thresholds by percentile heuristics (≈85–95th percentile
  of \(\|\nabla I\|\)) and report the resulting qualitative differences. This makes the decision scale‑free with respect
  to global intensity while remaining faithful to fine structure in the <em>cameraman</em> image.
</p>



      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><input type="radio" name="b-mode" value="Ix" checked> Ix</label>
          <label><input type="radio" name="b-mode" value="Iy"> Iy</label>
          <label><input type="radio" name="b-mode" value="gradmag"> |∇I|</label>
          <label><input type="radio" name="b-mode" value="edges"> Edges</label>

          <span id="b-thr-wrap" style="display:none; gap:10px; align-items:center;">
            <strong>t = <span id="b-tval">10</span></strong>
            <input id="b-tIdx" type="range" min="0" max="4" step="1" value="0" style="width:220px" aria-label="edge threshold">
          </span>
        </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="b-img" alt="1B result">
          <figcaption id="b-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ====================== PART 1C ====================== -->
  <section id="part1c" class="section">
    <div class="container">
      <h2 class="section-title">1C – Derivative of Gaussian (DoG)</h2>

      <p>
        Noise amplification from plain differencing is mitigated by smoothing with a Gaussian \(G_\sigma\).
        Two equivalent pipelines are compared:
      </p>
      <div class="callout small">
        (i) <em>Smooth–then–difference</em>:
        \(\;I_x = (I * G_\sigma) * D_x,\; I_y = (I * G_\sigma) * D_y.\)<br/>
        (ii) <em>Derivative of Gaussian</em>:
        \(\;I_x = I * \tfrac{\partial G_\sigma}{\partial x},\; I_y = I * \tfrac{\partial G_\sigma}{\partial y}.\)
      </div>

      <h3>Procedure</h3>
      <p>
        The Gaussian kernel uses support \(k = 2\lfloor 3\sigma \rfloor + 1\), capturing over 99% of the mass and
        minimizing truncation bias. For the DoG path, \(\partial_x G_\sigma\) and \(\partial_y G_\sigma\) are formed by
        convolving the Gaussian with the difference stencils and used directly as filters. With matched \(\sigma\) and
        support, \(\{I_x, I_y, \|\nabla I\|\}\) from both paths agree numerically and visually.
      </p>

      <h3>Fourier Perspective</h3>
      <p>
        The Gaussian acts as a low-pass with transfer \(\hat G(\omega)=e^{-\sigma^2\|\omega\|^2/2}\).
        Differencing corresponds to multiplication by \(j\omega\) in the frequency domain. Hence DoG yields
        \(j\omega\,\hat G(\omega)\), attenuating high-frequency noise while preserving edge localization.
      </p>

      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><input type="radio" name="c-impl" value="smoothdiff" checked> Smooth → Diff</label>
          <label><input type="radio" name="c-impl" value="DoG"> DoG (∂G ⊗ I)</label>

          <span style="margin-left:12px"></span>

          <label><input type="radio" name="c-mode" value="Ix" checked> Ix</label>
          <label><input type="radio" name="c-mode" value="Iy"> Iy</label>
          <label><input type="radio" name="c-mode" value="gradmag"> |∇I|</label>
        </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="c-img" alt="1C result">
          <figcaption id="c-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
      </div>

      <p>
        I ended up replacing the raw differences with derivatives of a Gaussian. A normalized Gaussian kernel
        <code>G<sub>σ</sub></code> is constructed using
        <code>ksize ≈ 6σ + 1</code> to capture sufficient support. Two pipelines are compared: (i) smoothing the image
        with <code>G<sub>σ</sub></code> and then applying <code>Dx</code>/<code>Dy</code>; and (ii) forming the DoG
        filters <code>∂G/∂x</code>, <code>∂G/∂y</code> (by convolving <code>G</code> with the difference stencils) and
        applying a single convolution per axis. Both methods yield near-identical <code>Ix</code>, <code>Iy</code>, and
        <code>|∇I|</code> when σ and support are matched, but the DoG route is computationally attractive and conceptually
        cleaner.
      </p>
    </div>
  </section>

  <!-- ====================== PART 2A ====================== -->
  <section id="part2a" class="section">
    <div class="container">
      <h2 class="section-title">2A – Unsharp Masking / Sharpening</h2>

      <p>
  I implement unsharp masking by adding a scaled high‑frequency residue to the input:
  \[\text{blur}=I*G_\sigma,\;\text{high}=I-\text{blur},\;I'=\operatorname{clip}(I+\alpha\,\text{high})\]
  The parameter \(\sigma\) sets the transition between “detail” and “structure,” while \(\alpha\) controls contrast gain
  within that band. A soft threshold on <code>high</code> optionally suppresses sensor noise.
</p>


  

      <h3>Procedure</h3>
      <p>
        All operations are performed in linear intensity; sRGB gamma is applied only for display. A two-pass schedule is
        effective for historic/low-contrast photographs: a fine pass \((\sigma\!\approx\!1\!-\!1.5,\;\alpha\!\approx\!1.2\!-\!1.6)\)
        to restore micro-contrast, followed by a gentle mid-radius pass
        \((\sigma\!\approx\!3\!-\!4,\;\alpha\!\approx\!0.2\!-\!0.4)\) to crispen contours while avoiding halos.
        Clamping is applied last to maintain valid display range.
    </p>
    <p>
  For the Taj Mahal and the additional image of my granpda, I show the blurred, high‑pass, and sharpened results, and vary \(\alpha\)
  to illustrate the sharpening–halo trade‑off. I also blur a sharp image and attempt to restore it, comparing the
  restored image to the original to highlight the information loss incurred by low‑pass filtering.
</p>

      <h3>Observations</h3>
<p>
  Fine‑scale sharpening (\(\sigma\approx 1\!-\!1.5\)) restores micro‑contrast effectively. Larger \(\sigma\) values can
  introduce halos near strong edges; this is mitigated by reducing \(\alpha\), operating in linear intensity, and
  applying clamping only at the end of the pipeline.
</p>

<p>
  <em>Summary:</em> <code>blur = G<sub>σ</sub> ⊗ I</code>, <code>high = I − blur</code>,
  <code>I′ = clip(I + α·high)</code>.
</p>

      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><strong>Dataset:</strong>
            <select id="ua-dataset">
              <option value="taj" selected>Taj</option>
              <option value="Grandpa">Grandpa</option>
            </select>
          </label>

          <label><input type="radio" name="ua-view" value="src" checked> Source</label>
          <label><input type="radio" name="ua-view" value="blur"> Blurred (low-pass)</label>
          <label><input type="radio" name="ua-view" value="high"> High-pass</label>
          <label><input type="radio" name="ua-view" value="sharp"> Sharpened</label>
        </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="ua-img" alt="2A result">
          <figcaption id="ua-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
      </div>

      <p>
        Unsharp masking: <code>blur = G<sub>σ</sub> ⊗ I</code>, <code>high = I − blur</code>, <code>I′ = clip(I + α·high)</code>.
      </p>
    </div>
  </section>

  <!-- ====================== PART 2B ====================== -->
  <section id="part2b" class="section">
    <div class="container">
      <h2 class="section-title">2B – Hybrid Images</h2>

      <p>
        Hybrid images juxtapose low-frequency structure from one source with high-frequency detail from another:
        \[
          A_{\text{low}} = A * G_{\sigma_\ell},\qquad
          B_{\text{high}} = B - (B * G_{\sigma_h}),\qquad
          H = A_{\text{low}} + \beta\,B_{\text{high}}.
        \]
        Perception depends on viewing distance: close inspection reveals the high-frequency subject; at a distance, the
        low-frequency subject dominates.
      </p>

      <h3>Procedure</h3>
      <p>
        Spatial alignment is performed with the provided click-based utility (two corresponding points per image) that
        recenters, rescales, and rotates one image to match the other, then crops to a shared field of view.
        High-frequency content is injected in luminance to prevent chromatic fringes; the gray high-band is replicated
        across RGB. Energy is balanced by setting \(\beta\) so that \(\operatorname{std}(\beta B_{\text{high}})\) equals
        a conservative fraction of \(\operatorname{std}(A_{\text{low}})\) measured within a central window to avoid
        border bias.
      </p>

      <h3>Diagnostics</h3>
      <p>
        Log-magnitude Fourier spectra confirm spectral separation: \(A_{\text{low}}\) concentrates energy near the DC
        lobe; \(B_{\text{high}}\) has attenuated DC with bright mid-to-high frequencies. The hybrid spectrum combines
        these patterns without introducing aliasing or band gaps.
      </p>

      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><strong>Set:</strong>
            <select id="hy-set">
              <option value="example" selected>Derek and Nutmeg</option>
              <option value="maga">Jump Scare</option>
              <option value="life">Life Magazine</option>
            </select>
          </label>

          <label><input type="radio" name="hy-view" value="A" checked> Image A</label>
          <label><input type="radio" name="hy-view" value="low"> Low-Pass (A)</label>
          <label><input type="radio" name="hy-view" value="a_fourier"> Fourier Series (A)</label>
          <label><input type="radio" name="hy-view" value="B"> Image B</label>
          <label><input type="radio" name="hy-view" value="high"> High-pass(B)</label>
          <label><input type="radio" name="hy-view" value="b_fourier"> Fourier Series (B)</label>
          <label><input type="radio" name="hy-view" value="hybrid_fourier"> Hybrid Fourier</label>
          <label><input type="radio" name="hy-view" value="hybrid"> Hybrid</label>
        </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="hy-img" alt="2B result">
          <figcaption id="hy-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ====================== PART 2C ====================== -->
  <section id="part2c" class="section">
    <div class="container">
      <h2 class="section-title">2C – Gaussian & Laplacian Stacks</h2>
      <p>
        A fixed-resolution Gaussian stack \(\{G^0,\ldots,G^{L-1}\}\) is constructed by repeated convolution with a
        Gaussian kernel; the Laplacian stack isolates band-pass structure:
        \[
          L^i = G^i - (G^i * G_\sigma),\quad i=0,\ldots,L-2,\qquad
          L^{L-1}=G^{L-1}.
        \]
        Reconstruction verifies correctness:
        \[
          G^0 \;\approx\; \sum_{i=0}^{L-1} L^i.
        \]
      </p>

      <h3>Procedure</h3>
      <p>
        Kernels follow \(k=2\lfloor 3\sigma\rfloor+1\) per level. To visualize signed band responses, each \(L^i\) is
        mapped to \(V^i = 0.5 + 0.5\,(L^i/m_i)\) with \(m_i = \operatorname{percentile}_{99}(|L^i|)\), ensuring that
        both positive and negative lobes remain visible without saturation. Grids show progressive attenuation of detail
        as the level index increases.
      </p>

      <h3>Use in Later Sections</h3>
      <p>
        The Laplacian stack provides a natural handle for frequency-aware operations: blending becomes a convex
        combination of band-limited coefficients (2D), and sharpening can be interpreted as a gain change on low-index
        bands (2A).
      </p>

      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><strong>Image:</strong>
            <select id="st-img">
              <option value="apple" selected>Apple</option>
              <option value="orange">Orange</option>
            </select>
          </label>

          <label><input type="radio" name="st-type" value="gauss" checked> Gaussian Stack</label>
          <label><input type="radio" name="st-type" value="lap"> Laplacian Stack</label>
        </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="st-view" alt="2C result">
          <figcaption id="st-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
      </div>
    </div>
  </section>

  <!-- ====================== PART 2D ====================== -->
  <section id="part2d" class="section">
    <div class="container">
      <h2 class="section-title">2D – Multiresolution Blending</h2>


      <p>
        Burt–Adelson compositing blends images \(A,B\) under a soft mask \(M\in[0,1]\) by mixing their Laplacian stacks
        with a Gaussianized mask stack:
        \[
          \tilde{L}^i = M^i \odot L_A^i + (1-M^i)\odot L_B^i,\qquad
          R = \sum_{i=0}^{L-1} \tilde{L}^i.
        \]
        A wide pre-feather on \(M\) removes seams at level \(i=0\); deeper levels allow global color and illumination to
        interpolate smoothly.
      </p>

      <h3>Procedure</h3>
      <p>
        The workflow is: (1) prepare \(A\) and \(B\) to a common resolution, (2) obtain a user mask (vertical or freehand),
        (3) pre-feather \(M\) by convolving with a broad Gaussian (tens of pixels) and normalize to \([0,1]\),
        (4) build \(\{L_A^i\}, \{L_B^i\}, \{M^i\}\) with shared \(\sigma\) and depth \(L\), (5) blend per level and
        reconstruct. All operations occur in linear-RGB to preserve energy relationships across bands; conversion to sRGB
        is applied for display assets.
      </p>

      <h3>Design Choices and Failure Modes</h3>
      <p>
        Depth \(L\in[6,10]\) balances runtime and coverage of coarse structures; insufficient depth leaves illumination
        mismatches. A narrow feather on \(M\) causes stair-step artifacts at level 0; a very broad feather may erase
        intended boundaries. Artifacts are reduced by increasing \(L\), aligning photometric statistics, and verifying
        that mask stacks are monotone across scales.
      </p>


      <div class="card" style="padding:16px">
        <div style="display:flex; gap:16px; align-items:center; flex-wrap:wrap; margin-bottom:12px">
          <label><strong>Mask:</strong>
            <select id="blend-mask">
              <option value="vertical" selected>Vertical</option>
              <option value="irregular">Irregular</option>
            </select>
          </label>

          <label><input type="radio" name="blend-view" value="result" checked> Result</label>
          <label><input type="radio" name="blend-view" value="mask_stack"> Mask Stack</label>
          <label><input type="radio" name="blend-view" value="lap_blended"> Laplacian Blended Stack</label>
        </div>
      </div>

        <figure class="media media--narrow" style="margin:0 auto">
          <img id="blend-img" alt="2D result">
          <figcaption id="blend-cap" style="text-align:center; margin-top:8px"></figcaption>
        </figure>
        <div class="callout small">
        <strong>Implementation notes.</strong> Gaussian stack kernel sizes follow \(k=2\lfloor 3\sigma\rfloor+1\).
        Depth \(L\) is increased when large-scale replacement (e.g., sky/landmark) is required. Mask feather
        \(\sigma_M \approx \tfrac{\text{feather px}}{6}\) is a reliable heuristic.
      </div>
    </div>
  </section>
  

  <!-- ====================== Shared JS helpers ====================== -->
  <script>
  (function(){
    const EXTS = ['png','jpg','jpeg'];
    const $ = s => document.querySelector(s);

    function tryLoad(imgEl, paths, i=0){
      if(i >= paths.length){ imgEl.removeAttribute('src'); return; }
      imgEl.onerror = () => tryLoad(imgEl, paths, i+1);
      imgEl.src = paths[i];
    }
    function onRadios(name, cb){
      document.querySelectorAll(`input[name="${name}"]`).forEach(r => r.addEventListener('change', cb));
    }
    window.UI = {EXTS, $, tryLoad, onRadios};
  })();
  </script>

  <!-- ====================== 1A viewer ====================== -->
  <script>
  (function () {
    const {EXTS, $, tryLoad, onRadios} = UI;
    const CONFIG = {
      base: 'media/part1',
      datasets: [{ id: 'box', label: 'Box Filter', ks: [3,5,9,15] }]
    };

    const dsSel = $('#a-dataset'), kIdx = $('#a-kIdx'), kval = $('#a-kval'),
          img = $('#a-img'), cap = $('#a-cap');

    CONFIG.datasets.forEach(d => {
      const o = document.createElement('option'); o.value = d.id; o.textContent = d.label;
      dsSel.appendChild(o);
    });

    const curDS = () => CONFIG.datasets.find(d => d.id === dsSel.value);
    const curImpl = () => document.querySelector('input[name="a-impl"]:checked').value;

    function setSlider(ds){
      kIdx.min = 0; kIdx.max = ds.ks.length - 1;
      if(+kIdx.value > +kIdx.max) kIdx.value = 0;
    }

    function update(){
      const ds = curDS(), k = ds.ks[+kIdx.value], impl = curImpl();
      kval.textContent = k;
      cap.textContent = `${ds.label} — ${impl==='fourloops'?'From scratch':'SciPy'} (k=${k})`;
      const paths = EXTS.map(ext => `${CONFIG.base}/${ds.id}/${ds.id}_${impl}_k${k}.${ext}`);
      tryLoad(img, paths);
    }

    dsSel.addEventListener('change', () => { setSlider(curDS()); update(); });
    kIdx.addEventListener('input', update);
    onRadios('a-impl', update);

    setSlider(curDS()); update();
  })();
  </script>

  <!-- ====================== 1B viewer ====================== -->
  <script>
  (function () {
    const {EXTS, $, tryLoad, onRadios} = UI;
    const BASE = 'media/part1_2';
    const THRESH = [10,15,20,25,30];

    const mode = () => document.querySelector('input[name="b-mode"]:checked').value;
    const tIdx = $('#b-tIdx'), tVal = $('#b-tval'), thrWrap = $('#b-thr-wrap'),
          img = $('#b-img'), cap = $('#b-cap');

    function candidates(){
      const m = mode();
      if(m==='edges'){
        const t = THRESH[+tIdx.value];
        tVal.textContent = t;
        return EXTS.map(ext => `${BASE}/p1_2_edges_t${t}.${ext}`);
      }
      const file = m==='Ix' ? 'p1_2_Ix' : m==='Iy' ? 'p1_2_Iy' : 'p1_2_gradmag';
      return EXTS.map(ext => `${BASE}/${file}.${ext}`);
    }

    function update(){
      thrWrap.style.display = (mode()==='edges') ? 'inline-flex' : 'none';
      const label = (mode()==='gradmag') ? '|∇I|' : mode();
      cap.textContent = `Finite difference — ${label}` + (mode()==='edges' ? ` (t=${THRESH[+tIdx.value]})` : '');
      tryLoad(img, candidates());
    }

    onRadios('b-mode', update);
    tIdx.addEventListener('input', update);
    update();
  })();
  </script>

  <!-- ====================== 1C viewer ====================== -->
  <script>
  (function () {
    const {EXTS, $, tryLoad, onRadios} = UI;
    const BASE = 'media/part1_3';

    const impl = () => document.querySelector('input[name="c-impl"]:checked').value;
    const mode = () => document.querySelector('input[name="c-mode"]:checked').value;
    const img  = $('#c-img'), cap = $('#c-cap');

    function update() {
      const m = mode();
      const i = impl() === 'smoothdiff' ? 'Smooth → Diff' : 'DoG';
      cap.textContent = `1C — ${i}, ${m === 'gradmag' ? '|∇I|' : m}`;
      const file = `p1_3_${m}_${impl()}`;
      tryLoad(img, EXTS.map(ext => `${BASE}/${file}.${ext}`));
    }

    onRadios('c-impl', update);
    onRadios('c-mode', update);
    update();
  })();
  </script>

  <!-- ====================== Config for Part 2D datasets ====================== -->
  <script id="blend-config" type="application/json">
  {
    "base": "media/part2_4",
    "exts": ["png","jpg","jpeg"],
    "datasets": [
      {
        "id": "oraple",
        "label": "Oraple ",
        "stems": {
          "result": "{id}_{mask}",
          "mask_stack": "mask_stack_{mask}",
          "lap_blended": "lap_blended_{mask}"
        }
      },
      {
        "id": "sbrainer",
        "label": "Santa Barbara ⊕ Rainer (irregular mask)",
        "stems": {
          "result": "sbrainer",
          "mask_stack": "stacks_rainer_sb_rainer_mask_L10_k17_s8.0_f65_lin_Gmask_grid",
          "lap_blended": "stacks_rainer_sb_rainer_mask_L10_k17_s8.0_f65_lin_Ls_grid"
        }
      },
      {

      "id": "bell_clouds",
      "label": "Campanile ⊕ Nighttime Clouds",
      "stems": {
        "result": "bell_clouds",
        "mask_stack": "stacks_clouds_bell_night_cloud_mask_L6_k17_s16.0_f65_lin_Gmask_grid",
        "lap_blended": "stacks_clouds_bell_night_cloud_mask_L6_k17_s16.0_f65_lin_Ls_grid"
      }
    }
    ]
  }
  </script>

  <!-- === Single driver for ALL Part 2 viewers (2A/2B/2C/2D) === -->
  <script>
  (function(){
    const EXTS = (window.UI && UI.EXTS) || ['png','jpg','jpeg'];
    const $    = (window.UI && UI.$)    || (s => document.querySelector(s));
    const tryLoad = (window.UI && UI.tryLoad) || function(imgEl, paths, i=0){
      if(i>=paths.length){ imgEl.removeAttribute('src'); return; }
      imgEl.onerror = () => tryLoad(imgEl, paths, i+1);
      imgEl.src = paths[i];
    };

    function makePart2Viewer({base, imgSel, capSel, watch, resolve, exts=EXTS}) {
      const img = $(imgSel), cap = $(capSel);

      function readState() {
        const s = {};
        for (const w of watch) {
          if (w.kind === 'radio') {
            const el = document.querySelector(`input[name="${w.name}"]:checked`);
            s[w.as] = el ? el.value : undefined;
          } else if (w.kind === 'select') {
            const el = document.getElementById(w.id);
            s[w.as] = el ? el.value : undefined;
          }
        }
        return s;
      }

      function update() {
        const state = readState();
        const { stem, stems, label } = resolve(state) || {};
        const list = stems || (stem ? [stem] : []);
        if (label) cap.textContent = label;
        if (!list.length) { img.removeAttribute('src'); return; }
        const paths = [];
        for (const s of list) for (const ext of exts) paths.push(`${base}/${s}.${ext}`);
        tryLoad(img, paths);
      }

      for (const w of watch) {
        if (w.kind === 'radio') {
          document.querySelectorAll(`input[name="${w.name}"]`).forEach(r => r.addEventListener('change', update));
        } else if (w.kind === 'select') {
          const el = document.getElementById(w.id);
          if (el) el.addEventListener('change', update);
        }
      }
      update();
      return update;
    }

    // ---------- 2A ----------
    makePart2Viewer({
      base: 'media/part2_1',
      imgSel: '#ua-img',
      capSel: '#ua-cap',
      watch: [
        {kind:'select', id:'ua-dataset', as:'ds'},
        {kind:'radio',  name:'ua-view',  as:'view'}
      ],
      resolve: ({ds, view}) => {
        const nice = {src:'Source', blur:'Blurred (LPF)', high:'High-pass', sharp:'Sharpened'}[view] || view;
        const stemBy = {
          taj:  {src:'taj', blur:'taj_blur', high:'taj_high', sharp:'taj_sharp'},
          Grandpa: {src:'gp', blur:'gp_blurred', high:'gp_high', sharp:'gp_4_final'}
        };
        const stem = stemBy[ds]?.[view] || null;
        return { stem, label: `${ds==='taj'?'Taj':'Grandpa'} • ${nice}` };
      }
    });

    // ---------- 2B ----------
    makePart2Viewer({
      base: 'media/part2_2',
      imgSel: '#hy-img',
      capSel: '#hy-cap',
      watch: [
        {kind:'select', id:'hy-set',   as:'set'},
        {kind:'radio',  name:'hy-view',as:'view'}
      ],
      resolve: ({set, view}) => {
        // Map stems per dataset
        const stemsBySet = {
          example: { A:'A', low:'low', a_fourier:'fft_A',B:'B', high:'high', b_fourier: 'fft_B', hybrid_fourier: 'fft_hybrid', hybrid:'hybrid' },
          maga:    { A:'vance', low:'low_vance', a_fourier: 'fft_A_t', B:'trump', b_fourier: 'fft_B_t', high:'high_trump', hybrid_fourier: 'fft_hybrid_t',hybrid:'tj_hybrid' },
          life: {A: 'life3', low: 'low_life', a_fourier: 'fft_low_life', B: 'life2', b_fourier: 'fft_high_life', high: 'high_life', hybrid_fourier: 'fft_hybrid_life', hybrid: 'hybrid_life'}
        };
        const names = {
          A:'(low-freq detial)', low:'Low-pass', fourier: 'Fourier',
          B:'(high-freq detail)', high:'High-pass(B)', hybrid:'Hybrid'
        };
        const stem = (stemsBySet[set] || stemsBySet.example)[view] || null;
        return { stem, label: `${set==='example'?'Example':'Jump Scare'} • ${names[view]||view}` };
      }
    });

    // ---------- 2C ----------
    makePart2Viewer({
      base: 'media/part2_3',
      imgSel: '#st-view',
      capSel: '#st-cap',
      watch: [
        {kind:'select', id:'st-img',    as:'img'},
        {kind:'radio',  name:'st-type', as:'type'}
      ],
      resolve: ({img, type}) => {
        const name = img==='apple' ? 'Apple' : 'Orange';
        return { stem: `${type}_${img}`, label: `2C — ${type==='gauss'?'Gaussian':'Laplacian'} stack • ${name}` };
      }
    });

    // ---------- 2D ----------
    makePart2Viewer({
      base: (function(){
        const el = document.querySelector('#blend-config');
        if (!el) return 'media/part2_4';
        try { return JSON.parse(el.textContent).base || 'media/part2_4'; }
        catch (_) { return 'media/part2_4'; }
      })(),
      imgSel: '#blend-img',
      capSel: '#blend-cap',
      watch: [
        {kind:'select', id:'blend-ds',  as:'ds'},
        {kind:'select', id:'blend-mask',as:'mask'},
        {kind:'radio',  name:'blend-view', as:'view'}
      ],
      resolve: ({ds, mask, view}) => {
        const el = document.querySelector('#blend-config');
        let CFG = null;
        if (el) { try { CFG = JSON.parse(el.textContent); } catch(_){} }
        const datasets = CFG?.datasets || [{id:'oraple', label:'Oraple', stems:{
          result:'{id}_{mask}', mask_stack:'mask_stack_{mask}', lap_blended:'lap_blended_{mask}'
        }}];

        // Ensure a dataset selector exists; create if missing
        let dsSel = document.querySelector('#blend-ds');
        if (!dsSel) {
          const controls = document.querySelector('#blend-mask').closest('div');
          const lab = document.createElement('label');
          lab.innerHTML = '<strong>Pair:</strong> <select id="blend-ds"></select>';
          controls.insertBefore(lab, controls.firstChild);
          dsSel = lab.querySelector('select');
          dsSel.innerHTML = datasets.map(d=>`<option value="${d.id}">${d.label||d.id}</option>`).join('');
          dsSel.addEventListener('change', () => document.querySelector('input[name="blend-view"]:checked').dispatchEvent(new Event('change')));
        }

        const active = datasets.find(d => d.id === (ds || dsSel.value)) || datasets[0];
        if (dsSel && dsSel.value !== active.id) dsSel.value = active.id;

        const tpl = active.stems?.[view];
        const rel = tpl ? tpl.replace(/\{(\w+)\}/g, (_,k)=>({id:active.id,mask}[k]??'')) : `${active.id}_${mask}`;
        const vname = view==='result' ? 'Result' : (view==='mask_stack' ? 'Mask stack' : 'Laplacian blended stack');
        const mname = mask==='vertical' ? 'vertical' : 'Irregular';
        return { stem: rel, label: `${active.label||active.id}` };
      }
    });

  })();
  </script>
</body>
</html>
